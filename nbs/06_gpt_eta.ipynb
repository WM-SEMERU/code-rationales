{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ATE evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counting rational tokens and classify them by semantic/ non-semantinc for either programming and natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_rationales.loader import download_grammars\n",
    "from tree_sitter import Language, Parser\n",
    "import code_rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_default():\n",
    "    return {\n",
    "        'model_name' : '/workspaces/code-rationales/data/codeparrot-small/checkpoints/checkpoint-29000', \n",
    "        'cache_dir': '/workspaces/code-rationales/datax/df_cache_dir',\n",
    "        'delimiter_sequence': '' ### BE VERY CAREFULL HERE ALWAYS VERIFY -> VERY IMPORTANT\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = param_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]   Unzipping help/tagsets.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomies definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Programming Language Taxonomy\n",
    "def pl_taxonomy_python() -> dict:\n",
    "    return {\n",
    "  \"punctuation\": ['{', '}', '[', ']', '(', ')','\\\"', ',', '.', '...', ';', ':'], \n",
    "  \"exceptions\": ['raise_statement','catch', 'try', 'finally', 'throw', 'throws', 'except'],\n",
    "  \"oop\": ['def','class','instanceof','interface','private','protected','public','abstract','extends','package','this','implements','import','new','super'],\n",
    "  \"asserts\": ['assert'],\n",
    "  \"types\": ['tuple','set','list','pair','subscript','type','none','dictionary','integer','native','static','synchronized','transient','volatile','void','final','enum','byte','char','float','boolean','double','int','long','short','strictfp'],\n",
    "  \"conditionals\": ['else', 'if', 'switch', 'case', 'default'],\n",
    "  \"loops\": ['break', 'do', 'for', 'while', 'continue'],\n",
    "  \"operators\": ['as','yield','is','@','in','and','or','not','**','slice','%','+','<','>','=','+','-','*','/','%','++','--','!','==','!=','>=','<=','&&','||','?',':','~','<<','>>','>>>','&','^','|','//'],\n",
    "  \"indentation\": ['\\n','\\t'],\n",
    "  \"bool\": ['true', 'false'], \n",
    "  \"functional\":['lambda','lambda_parameters'],\n",
    "  \"with\" : ['with','with_item','with_statement','with_clause'], \n",
    "  \"return\" :['return'],\n",
    "  \"structural\" : ['attribute', 'argument_list','parenthesized_expression','pattern_list','class_definition','function_definition','block'],\n",
    "  \"statements\" : ['return_statement','break_statement','assignment','while_statement','expression_statement','assert_statement'],\n",
    "  \"expression\": ['call','exec','async','ellipsis','unary_operator','binary_operator','as_pattern_target','boolean_operator','as_pattern','comparison_operator','conditional_expression','named_expression','not_operator','primary_expression','as_pattern'],\n",
    "  \"errors\": [\"ERROR\"],\n",
    "  \"identifier\":[\"identifier\"],  \n",
    "  \"comment\":[\"comment\"],\n",
    "  \"string\": ['string','interpolation','string_content','string_end','string_start','escape_sequence'], \n",
    "  \"unknown\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nl_pos_taxonomy() -> dict: return {\n",
    "    \"nl_verb\" : ['VBN', 'VBG', 'VBZ', 'VBP', 'VBD', 'VB'],\n",
    "    \"nl_noun\" : ['NN', 'NNPS', 'NNS', 'NNP'],\n",
    "    \"nl_pronoun\" : ['WP', 'PRP', 'PRP$', 'WP','WP$'], \n",
    "    \"nl_adverb\" : ['RBS','RBR', 'RB', 'WRB'], \n",
    "    \"nl_adjetive\" : ['JJR', 'JJS', 'JJ'], \n",
    "    \"nl_determier\" : ['DT','WDT','PDT'], \n",
    "    \"nl_preposition\" : ['IN', 'TO'],\n",
    "    \"nl_particle\" : ['RP'],\n",
    "    \"nl_modal\" : ['MD'],\n",
    "    \"nl_conjunction\" : ['CC'],\n",
    "    \"nl_cardinal\" : ['CD'],\n",
    "    \"nl_list\": ['LS'],\n",
    "    \"nl_other\" : ['FW', 'EX', 'SYM' , 'UH', 'POS', \"''\", '--',':', '(', ')', '.', ',', '``', '$']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_non_semantic_groups() -> dict:return{\n",
    "    \"nl_semantic\": ['nl_verb','nl_noun','nl_pronoun'],\n",
    "    \"pl_semantic\": ['types','exceptions','oop','conditionals','loops','bool','with','structural','asserts','statements'],\n",
    "    \"nl_non_semantic\": ['nl_adverb','nl_adjetive','nl_determier','nl_preposition','nl_particle','nl_modal','nl_conjunction','nl_cardinal','nl_list'],\n",
    "    \"pl_non_semantic\": ['punctuation','expression','operators','indentation','return','functional'],\n",
    "    \"unknown\": ['unknown', 'nl_other', '']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_groups() -> dict:\n",
    "    return {\n",
    "        'sc_semantic': ['exceptions', 'oop', 'asserts', 'types', 'conditionals', 'loops', 'bool', 'structural', 'statements', 'with'], \n",
    "        'sc_nl': ['identifier', 'comment', 'string'],\n",
    "        'sc_not_semantic': ['punctuation', 'operators', 'indentation', 'functional', 'return', 'expression'], ## TODO why unkown is here? \n",
    "        'sc_errors' : ['errors'], \n",
    "        'nl_semantic': ['nl_verb', 'nl_noun', 'nl_pronoun', 'nl_adjetive'],\n",
    "        'nl_not_semantic' : ['nl_adverb', 'nl_determier', 'nl_preposition', 'nl_particle', 'nl_modal', 'nl_conjunction', 'nl_cardinal', 'nl_list', 'nl_other'],\n",
    "        'unknown': ['unknown',''] ## NOTE DRC: I added this\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AST management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_node_types(\n",
    "    nested_node_types: dict  # node_types from tree-sitter\n",
    ") -> list: # list of node types\n",
    "    def iterate_and_unroll_dict(nested_node_types: dict, all_node_types: set):\n",
    "        for key, value in nested_node_types.items():\n",
    "            if key == 'type' and type(value) == str:\n",
    "                all_node_types.add(value)\n",
    "            if type(value) == dict:\n",
    "                iterate_and_unroll_dict(value, all_node_types)\n",
    "            if type(value) == list:\n",
    "                for element in value:\n",
    "                    iterate_and_unroll_dict(element, all_node_types) \n",
    "    all_node_types = set()\n",
    "    for dictionary in nested_node_types:\n",
    "        iterate_and_unroll_dict(dictionary, all_node_types)\n",
    "    all_node_types.add('ERROR')\n",
    "    return list(all_node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parser(lang: str):\n",
    "    # Grab the node types from the tree-sitter language\n",
    "    language = Language(f\"{code_rationales.__path__[0]}/grammars/tree-sitter-languages.so\", lang)\n",
    "    node_path = f\"{code_rationales.__path__[0]}/grammars/tree-sitter-{lang}/src/node-types.json\"\n",
    "    with open(node_path) as f:\n",
    "            node_types = json.load(f)\n",
    "    node_types = unroll_node_types(node_types)\n",
    "    # Create a parser for the language\n",
    "    parser = Parser()\n",
    "    parser.set_language(language)\n",
    "    return parser, node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(\n",
    "    node,       # tree-sitter node\n",
    ") -> None:\n",
    "    \"\"\"Traverse in a recursive way, a tree-sitter node and append results to a list.\"\"\"\n",
    "    results = []\n",
    "    def traverse_tree(node, results):\n",
    "        if node.type == 'string':\n",
    "            results.append(node)\n",
    "            return\n",
    "        for n in node.children:\n",
    "            traverse_tree(n, results)\n",
    "        if not node.children:\n",
    "            results.append(node)\n",
    "    traverse_tree(node, results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_offset(\n",
    "    point,              #point to convert\n",
    "    lines: list         #list of lines in the source code\n",
    "    ):\n",
    "        \"\"\"Convert the point to an offset\"\"\"\n",
    "        row, column = point\n",
    "        chars_in_rows = sum(map(len, lines[:row])) + row\n",
    "        chars_in_columns = len(lines[row][:column])\n",
    "        offset = chars_in_rows + chars_in_columns\n",
    "        return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_span(node, lines):\n",
    "    \"\"\"Get the span position of the node in the code string\"\"\"\n",
    "    start_span = convert_to_offset(node.start_point, lines)\n",
    "    end_span = convert_to_offset(node.end_point, lines)\n",
    "    return start_span, end_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_token_span_in_node_span(tok_span, token: str, node_span, node_text: str):\n",
    "    return (node_span[0] <= tok_span[0] and tok_span[1] <= node_span[1]) or \\\n",
    "            (node_span[0]-1 <= tok_span[0] and tok_span[1] <= node_span[1] and node_text in token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_type(\n",
    "    tok_span: tuple, # (start, end) position of a token in tokenizer\n",
    "    token: str,   # token value\n",
    "    nodes: list,     # list of tree-sitter nodes\n",
    "    lines: list,     # list of lines in the code\n",
    ") -> tuple: # (parent_type, token_type) of the token\n",
    "    \"\"\"Get the parent AST type and token AST type of a token.\"\"\"\n",
    "    for i, node in enumerate(nodes):\n",
    "        if is_token_span_in_node_span(tok_span, token, get_node_span(node, lines), node.text.decode('utf-8')):\n",
    "            return nodes[i].parent.type, nodes[i].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_nodes(\n",
    "    tok_span: tuple, # (start, end) position of a token in tokenizer\n",
    "    token: str,      #actual token\n",
    "    node,            # tree-sitter node\n",
    "    lines: list,     # list of lines in the code\n",
    ") -> list: \n",
    "    \"\"\"Get all AST types for the given token span\"\"\"\n",
    "    results = []\n",
    "    def traverse_and_get_types(tok_span, node, lines, results) -> None:\n",
    "        node_span = get_node_span(node, lines)\n",
    "        if is_token_span_in_node_span(tok_span, token, node_span, node.text.decode('utf-8')):\n",
    "            results.append(node)\n",
    "        for n in node.children:\n",
    "            traverse_and_get_types(tok_span, n, lines, results)\n",
    "    traverse_and_get_types(tok_span, node, lines, results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_by_type(\n",
    "    node, \n",
    "    node_types: list\n",
    ") -> list :\n",
    "    def traverse_and_search(node, node_types, results):\n",
    "        if node.type in node_types:\n",
    "            results.append(node)\n",
    "        for n in node.children:\n",
    "            traverse_and_search(n, node_types ,results)\n",
    "    results = []\n",
    "    traverse_and_search(node, node_types, results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_results(global_results):\n",
    "    def clean_dictonary(result_dict):\n",
    "        clean_dict = result_dict.copy()\n",
    "        for key, value in result_dict.items():\n",
    "            if not value or not value['values']: \n",
    "                clean_dict.pop(key)\n",
    "        return clean_dict\n",
    "    for key, value in global_results.items():\n",
    "        global_results[key] = clean_dictonary(value)\n",
    "    return global_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_category_by_token(taxonomy_dict: dict, token_type: str):\n",
    "    for key, value in taxonomy_dict.items():\n",
    "        if token_type in value:\n",
    "            return key\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_taxonomy(taxonomy_dict: dict, result_dict: dict):\n",
    "    result_dict = result_dict.copy()\n",
    "    mappings = {token: {category : {'values': [], 'rationales': []} for category in taxonomy_dict.keys()} for token in result_dict.keys()}\n",
    "    for target_token, value in result_dict.items():\n",
    "        for source_token, props in value.items():\n",
    "            mappings[target_token][search_category_by_token(taxonomy_dict, source_token)]['values'].append(props['values'])\n",
    "            mappings[target_token][search_category_by_token(taxonomy_dict, source_token)]['rationales'].append(props['rationales'])\n",
    "    return clean_results(mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_local_results_to_taxonomy(taxonomy_dict:dict, local_results: dict):\n",
    "    return dict(zip(local_results.keys(), map(lambda aggegrations: map_to_taxonomy(taxonomy_dict, aggegrations), local_results.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Sampling Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sampled_generation(\n",
    "        df_sampled_code, \n",
    "        model,\n",
    "        tokenizer,\n",
    "        number_samples_generation = 1,\n",
    "        max_gen_tok = 100, \n",
    "        top_k = 0\n",
    "    ):\n",
    "    dict_generated_code = {i: [] for i in range(number_samples_generation)}\n",
    "    for idx_prompt, prompt in enumerate(df_sampled_code['prompt']):\n",
    "        input = tokenizer([prompt], return_tensors=\"pt\")\n",
    "        input.to(model.device)\n",
    "        outputs = model.generate(**input, do_sample=True,\n",
    "                                 max_length=len(df_sampled_code['input_ids'][idx_prompt]), ##Force rationalization\n",
    "                                 top_k=top_k, \n",
    "                                 num_return_sequences=number_samples_generation, \n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "        for index, output in enumerate(outputs):\n",
    "            dict_generated_code[index].append(output.tolist())\n",
    "    df_temp = pd.DataFrame().from_dict(data=dict_generated_code) # DataFrame from Generation\n",
    "    df_temp = pd.concat([df_sampled_code.reset_index(), df_temp ], axis=1) #Index before concating\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the model is not fine-tuned or compatible, it will rise an error\n",
    "#This function works for one tensor of source token and one tensor of target tokens\n",
    "def rationalize_model(model, tokenizer, input_ids, max_token_size: int, verbose=True):\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    all_rationales, log = rationalize_lm(\n",
    "        model = model,\n",
    "        input_ids = input_ids[:max_token_size],\n",
    "        tokenizer = tokenizer,\n",
    "        verbose = verbose,\n",
    "        max_steps=1024 #Max number of steps for greedy rationalization\n",
    "    )\n",
    "    return all_rationales, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_rational(\n",
    "    model,\n",
    "    tokenizer, \n",
    "    arr_target_tokens, \n",
    "    seq_id, #mapping sequence id\n",
    "    max_token_size,\n",
    "    verbose=True\n",
    "):\n",
    "    arr_log = []\n",
    "    for index, val in enumerate(arr_target_tokens):\n",
    "        all_rationales, log = rationalize_model(\n",
    "            model=model, \n",
    "            tokenizer=tokenizer, \n",
    "            input_ids=val,\n",
    "            max_token_size=max_token_size,\n",
    "            verbose=False\n",
    "        )\n",
    "        arr_log.append(log)\n",
    "    arr_code_rationales = [ log['rationalization'] for log in arr_log ] #extracting just rationalizations\n",
    "    arr_from_sentence = [ list(np.full( len(val), seq_id[arr_i] )) #arr_i maps to the real sequence id\n",
    "                            for arr_i, val in enumerate(arr_code_rationales)]\n",
    "    arr_code_rationales = sum( arr_code_rationales, [] ) #flatting\n",
    "    arr_from_sentence = sum( arr_from_sentence, [] ) #flatting\n",
    "    return arr_code_rationales, arr_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_rationales( arr_code_rationales, arr_from_sentence ):\n",
    "    #Creating pandas_1 {p_rationale}\n",
    "    rational = lambda list_log,typeset: [ (dict_tok['added_token_text'],round(dict_tok['true_token_prob'],6)) for dict_tok in list_log if dict_tok['from']==typeset]\n",
    "    log = lambda log_row: [(log_dict['added_token_text'],log_dict['true_token_prob']) for log_dict in log_row] #Typeset\n",
    "\n",
    "    log_position = lambda log_row: [log_dict['added_token_position'] for log_dict in log_row] #Position of the Rationale\n",
    "    log_prediction = lambda log_row: [log_dict['true_token_prob'] for log_dict in log_row] #Rationale Prob\n",
    "\n",
    "    p_rationale = pd.DataFrame()\n",
    "\n",
    "    p_rationale['goal_token'] = [dict_token['goal_word'] for dict_token in arr_code_rationales]\n",
    "    p_rationale['from_seq_id'] = arr_from_sentence\n",
    "\n",
    "    p_rationale['typesets_tgt'] = [ log(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    \n",
    "    p_rationale['rationale_pos_tgt'] = [ log_position(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    p_rationale['rationale_prob_tgt'] = [ log_prediction(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "\n",
    "\n",
    "    return p_rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running Rationalization\n",
    "def run_code_rational( \n",
    "        df_generated_input,\n",
    "        tensor_size, #Control the size of the experiment, \n",
    "        model,\n",
    "        tokenizer,\n",
    "        experiment = '5',\n",
    "        batch_size = 100, \n",
    "        max_token_size = 44,\n",
    "        verbose = True \n",
    "    ):\n",
    "\n",
    "    arr_rationals = []\n",
    "    arr_from_seq = []\n",
    "\n",
    "    for i in range( 0 , tensor_size , batch_size ):\n",
    "        print('************************' + str(i) + '************************')\n",
    "        t_generated_input = df_generated_input[experiment].values[i:i+batch_size]\n",
    "        t_generated_input = [ torch.tensor(s).to(model.device) for s in t_generated_input]\n",
    "\n",
    "        t_arr_rationals,t_arr_from_seq = run_multiple_rational(\n",
    "            model = model,\n",
    "            tokenizer = tokenizer,\n",
    "            arr_target_tokens =  t_generated_input, \n",
    "            seq_id = list(range(i,i+batch_size)),\n",
    "            max_token_size = len(t_generated_input[0]),\n",
    "            verbose = verbose\n",
    "        )\n",
    "\n",
    "        arr_rationals = arr_rationals + t_arr_rationals\n",
    "        arr_from_seq = arr_from_seq + t_arr_from_seq\n",
    "\n",
    "        torch.cuda.empty_cache() #Cleaning Cache\n",
    "        \n",
    "    print(\"Experiment Finished: \" + str(experiment))\n",
    "    return pandas_rationales( arr_rationals, arr_from_seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_rational_all_set(exp, df_generated_input, model, tokenizer, tensor_n = 100, BATCH = 10): #When Tensor_n and batch differs then 'from_seq_id' is lost\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    EXP = exp\n",
    "    test_arr_rationals = run_code_rational( \n",
    "            df_generated_input,\n",
    "            tensor_n,\n",
    "            model, \n",
    "            tokenizer,\n",
    "            experiment = EXP,\n",
    "            batch_size = BATCH,\n",
    "            verbose = False \n",
    "        )\n",
    "    #Saving process\n",
    "    return test_arr_rationals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rationales Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_right_span = lambda start_idx, end_idx, df : len(''.join(map(str, df.loc[start_idx:end_idx, 'goal_token'].tolist())))\n",
    "calculate_span = lambda right_span, token : (right_span-len(str(token)), right_span)\n",
    "delete_leading_spaces = lambda string: re.sub(r'^\\s+', '', string)\n",
    "delete_leading_breaks = lambda string: re.sub(r'^\\n+', '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_first_token_row(df):\n",
    "    df.loc[-1] = [df['typesets_tgt'][0][0][0], df['from_seq_id'][0], None, None, None, df['exp'][0]]\n",
    "    df.index = df.index + 1\n",
    "    df = df.sort_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_auxiliary_columns_to_experiment_result(df, delimiter_sequence: str):\n",
    "    df.insert(0, 'rational_pos', [i for i in range(len(df))])\n",
    "    initial_token = df['goal_token'][0]\n",
    "    ### TOKEN TYPE COLUMN\n",
    "    token_type_column = ['src'] * len(df)\n",
    "    sequence = initial_token\n",
    "    for idx, goal_token in enumerate(df['goal_token']):\n",
    "        if delimiter_sequence not in sequence:\n",
    "            token_type_column[idx] = 'nl'\n",
    "            sequence+=goal_token\n",
    "    df['token_type'] = token_type_column\n",
    "    src_initial_token_idx = df[df['token_type'] == 'src'].first_valid_index()\n",
    "    df['span'] = [None] * len(df[:src_initial_token_idx]) + [calculate_span(calculate_right_span(src_initial_token_idx, index, df), token) for index, token in df[src_initial_token_idx:]['goal_token'].items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nl_tags_in_experiment_result(df, nl_ast_types, nl_pos_types, parser):\n",
    "    #initial_token = df['typesets_tgt'][0][0][0] if df[df['token_type'] == 'src'].first_valid_index() == 0 else ''\n",
    "    ##### POS TAGS FOR NL PART\n",
    "    target_nl = ''.join(df[df['token_type'] == 'nl']['goal_token'].map(lambda value: str(value)))\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(target_nl))\n",
    "    for idx in range(df[df['token_type']== 'src'].first_valid_index()):\n",
    "        nl_tags = list(map(lambda tag: tag[1] if tag[1] in nl_pos_types else None, filter(lambda tag: tag[0] in str(df['goal_token'][idx]), pos_tags)))\n",
    "        if nl_tags: df.at[idx, 'tags'] = df['tags'][idx] + [nl_tags[-1]]\n",
    "    ##### POS TAGS FOR CODE PART\n",
    "    target_code = ''.join(df[df['token_type'] == 'src']['goal_token'].map(lambda value: str(value)))\n",
    "    nl_target_nodes = get_nodes_by_type(parser.parse(bytes(target_code, 'utf8')).root_node, nl_ast_types)\n",
    "    for token_idx in range(df[df['token_type'] == 'src'].first_valid_index(), len(df['span'])):\n",
    "                for nl_target_node in nl_target_nodes:\n",
    "                    if is_token_span_in_node_span(df['span'][token_idx], df['goal_token'][token_idx], get_node_span(nl_target_node, target_code.split(\"\\n\")), nl_target_node.text.decode('utf-8')) and \\\n",
    "                            (str(df['goal_token'][token_idx]) in nl_target_node.text.decode('utf-8') or nl_target_node.text.decode('utf-8') in str(df['goal_token'][token_idx])):\n",
    "                            tagged_token_list = list(filter(lambda tagged_token: str(tagged_token[0]).replace(' ','') in str(df['goal_token'][token_idx]).replace(' ','') or str(df['goal_token'][token_idx]).replace(' ','') in str(tagged_token[0]).replace(' ',''), \\\n",
    "                                                        nltk.pos_tag( nltk.word_tokenize(nl_target_node.text.decode('utf-8')))))\n",
    "                            if len(tagged_token_list)>0 and tagged_token_list[0][1] in nl_pos_types and tagged_token_list[0][1] not in df['tags'][token_idx]: df.at[token_idx, 'tags'] = df['tags'][token_idx] + [tagged_token_list[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ast_tags_in_experiment_result(df, parser):\n",
    "    target_code = ''.join(df[df['token_type'] == 'src']['goal_token'].map(lambda value: str(value)))\n",
    "    #target_code = delete_leading_breaks(delete_leading_spaces(target_code))\n",
    "    src_initial_token_idx = df[df['token_type'] == 'src'].first_valid_index()\n",
    "    target_ast = parser.parse(bytes(target_code, 'utf8')).root_node\n",
    "    for token_idx in range(src_initial_token_idx, len(df)):\n",
    "        df.at[token_idx, 'tags'] = df['tags'][token_idx] + list(map(lambda node: node.type, get_token_nodes(df['span'][token_idx], df['goal_token'][token_idx], target_ast, target_code.split(\"\\n\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_rationals(experiment_results: list, nl_ast_types: list, nl_pos_types: list, delimiter_sequence: str, parser):\n",
    "    experiments = {}\n",
    "    for exp_idx, df_experiment in enumerate(experiment_results):\n",
    "        experiment_results = []\n",
    "        experiment_rational_results = [df_experiment[(df_experiment['from_seq_id'] == sample_idx) | \\\n",
    "                                                     (df_experiment['from_seq_id'] == str(sample_idx))].reset_index() \\\n",
    "                                                    for sample_idx in range(len(prompts))]\n",
    "        print('*'*10 +'Tagging rationals for exp: ' +str(exp_idx) + '*'*10)\n",
    "        for experiment_rational_result in experiment_rational_results:\n",
    "            experiment_rational_result = experiment_rational_result.drop('index', axis=1)\n",
    "            experiment_rational_result = add_first_token_row(experiment_rational_result)\n",
    "            add_auxiliary_columns_to_experiment_result(experiment_rational_result, delimiter_sequence)\n",
    "            experiment_rational_result['tags'] = [[]]*len(experiment_rational_result)\n",
    "            fill_nl_tags_in_experiment_result(experiment_rational_result, nl_ast_types, nl_pos_types, parser)\n",
    "            fill_ast_tags_in_experiment_result(experiment_rational_result, parser)\n",
    "            experiment_results.append(experiment_rational_result)\n",
    "        experiments[exp_idx] = experiment_results\n",
    "    return experiments\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rationales Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rationals(global_tagged_results: dict, ast_node_types: list, nl_pos_types: list, number_samples: int):\n",
    "    aggregation_results = {sample_id: None  for sample_id in range(number_samples)}\n",
    "    for exp_idx, experiment_results in global_tagged_results.items():\n",
    "        print('*'*10 +'Aggregrating rationals for exp: ' +str(exp_idx) + '*'*10)\n",
    "        for experiment_result in experiment_results:\n",
    "            ### GET INFORMATION OF FIRST TOKEN\n",
    "            #sample_results = {str(pos+1)+'['+str(token)+']' : {node_type : {'values': [], 'rationales': []} for node_type in ast_node_types + nl_pos_types} for pos, token in enumerate(experiment_result['goal_token'].tolist())}\n",
    "            sample_results = {str(token_pos)+'['+str(experiment_result['goal_token'][token_pos])+']' : {node_type : {'values': [], 'rationales': []} for node_type in ast_node_types + nl_pos_types} for token_pos in range(1, len(experiment_result['rational_pos']))}\n",
    "            for target_idx, target_token in enumerate(experiment_result['goal_token'].tolist()): \n",
    "                if target_idx > 0: # INITIAL TOKEN IS IGNORED\n",
    "                    for rational_idx, rational_pos in enumerate(experiment_result['rationale_pos_tgt'][target_idx]):\n",
    "                        for rational_tag in experiment_result['tags'][rational_pos]: \n",
    "                            if rational_tag:\n",
    "                                try:\n",
    "                                    sample_results[str(target_idx)+'['+str(target_token)+']'][rational_tag]['values'].append(experiment_result['rationale_prob_tgt'][target_idx][rational_idx])\n",
    "                                    sample_results[str(target_idx)+'['+str(target_token)+']'][rational_tag]['rationales'].append(str(rational_pos)+'['+str(experiment_result['goal_token'][rational_pos])+']')\n",
    "                                except Exception as e:\n",
    "                                    print('An Error Occurred')\n",
    "            aggregation_results[experiment_result['from_seq_id'].unique()[0]] = clean_results(sample_results)\n",
    "    return aggregation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------- Reading form previous tagged processed files ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_default():\n",
    "    return {\n",
    "        'dataset' : 'code_completion_random_cut_5k_30_512_tokens',\n",
    "        #'dataset' : 'code_completion_docstring_random_cut_3.8k_30_150_tokens',\n",
    "        #'dataset' : 'code_completion_docstring_signature_3.8k_30_150_tokens',\n",
    "        #'dataset' : 'code_completion_docstring_5k_30_150_tokens',\n",
    "        'rational_results': '/workspaces/code-rationales/data/rationales/gpt',\n",
    "        'tagged_rationales': '/workspaces/code-rationales/data/tagged_rationales',\n",
    "        'delimiter_sequence': '', ## VERY IMPOETANT\n",
    "        'num_samples' : 100, \n",
    "        'size_samples' : 44,\n",
    "        'num_experiments': 30,\n",
    "        'model_name' : '/workspaces/code-rationales/data/codeparrot-small/checkpoints/checkpoint-29000', \n",
    "        'cache_dir': '/workspaces/code-rationales/datax/df_cache_dir',\n",
    "        'galeras_path': '/workspaces/code-rationales/semeru-datasets/semeru/galeras/code_rationales/'\n",
    "    }\n",
    "params = param_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tagged = '{}/{}{}{}.csv'.format(params['tagged_rationales'], params['dataset'],'_exp_' , str(0))\n",
    "path_dataset = '{}{}.json'.format(params['galeras_path'],params['dataset'])\n",
    "tagged_results = pd.read_csv(path_tagged)\n",
    "with open(path_dataset) as json_file:\n",
    "    galeras_dataset = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "galeras_dataset = pd.DataFrame.from_dict(galeras_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>fun_name</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>code</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>n_whitespaces</th>\n",
       "      <th>n_words</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>complexity</th>\n",
       "      <th>nloc</th>\n",
       "      <th>token_counts</th>\n",
       "      <th>n_ast_nodes</th>\n",
       "      <th>n_identifiers</th>\n",
       "      <th>signature</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159555</td>\n",
       "      <td>f9437064b3501869f5f56fb9e6d345d81ffeec5e</td>\n",
       "      <td>rasa</td>\n",
       "      <td>tests/core/test_evaluation.py</td>\n",
       "      <td>test_evaluation.py</td>\n",
       "      <td>skip_on_CI</td>\n",
       "      <td>Skip e2e tests on CI: these tests take too lon...</td>\n",
       "      <td>def skip_on_CI() -&gt; bool:\\n    \\n    return os...</td>\n",
       "      <td>https://github.com/RasaHQ/rasa.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>def skip_on_CI() -&gt; bool</td>\n",
       "      <td>def skip_on_CI() -&gt; bool:\\n    \\n    return os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276430</td>\n",
       "      <td>84afc5193d38057e2e2badf9c889ea87d80d8fbf</td>\n",
       "      <td>keras</td>\n",
       "      <td>keras/tests/custom_training_loop_test.py</td>\n",
       "      <td>custom_training_loop_test.py</td>\n",
       "      <td>call</td>\n",
       "      <td>Reformatting the codebase with black.\\n\\nPiper...</td>\n",
       "      <td>def call(self, inputs):\\n        self.add_loss...</td>\n",
       "      <td>https://github.com/keras-team/keras.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>def call(self, inputs)</td>\n",
       "      <td>def call(self, inputs):\\n        self.add_loss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210956</td>\n",
       "      <td>39531637b5675a36409c303db022bfab90939896</td>\n",
       "      <td>PaddleDetection</td>\n",
       "      <td>deploy/python/det_keypoint_unite_infer.py</td>\n",
       "      <td>det_keypoint_unite_infer.py</td>\n",
       "      <td>smoothing_factor</td>\n",
       "      <td>one euro filter and ema smoothing for keypoint...</td>\n",
       "      <td>def smoothing_factor(self, te, fc):\\n        r...</td>\n",
       "      <td>https://github.com/PaddlePaddle/PaddleDetectio...</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>def smoothing_factor(self, te, fc)</td>\n",
       "      <td>def smoothing_factor(self, te, fc):\\n        r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190542</td>\n",
       "      <td>4fc3616712edb19179b17dd270ad6cf63abf99c2</td>\n",
       "      <td>DeOldify</td>\n",
       "      <td>fastai/vision/image.py</td>\n",
       "      <td>image.py</td>\n",
       "      <td>data</td>\n",
       "      <td>Upgrading to support latest Pytorch version</td>\n",
       "      <td>def data(self)-&gt;TensorImage:\\n        \"Return ...</td>\n",
       "      <td>https://github.com/jantic/DeOldify.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>def data(self)-&gt;TensorImage</td>\n",
       "      <td>def data(self)-&gt;TensorImage:\\n        \"Return ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189667</td>\n",
       "      <td>e040bcacd38378386749db18aeba575b93f4ebca</td>\n",
       "      <td>manim</td>\n",
       "      <td>manim/mobject/geometry/arc.py</td>\n",
       "      <td>arc.py</td>\n",
       "      <td>stop_angle</td>\n",
       "      <td>Improved structure of the :mod:`.mobject` modu...</td>\n",
       "      <td>def stop_angle(self):\\n        return angle_of...</td>\n",
       "      <td>https://github.com/ManimCommunity/manim.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>def stop_angle(self)</td>\n",
       "      <td>def stop_angle(self):\\n        return angle_of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                 commit_id             repo  \\\n",
       "0  159555  f9437064b3501869f5f56fb9e6d345d81ffeec5e             rasa   \n",
       "1  276430  84afc5193d38057e2e2badf9c889ea87d80d8fbf            keras   \n",
       "2  210956  39531637b5675a36409c303db022bfab90939896  PaddleDetection   \n",
       "3  190542  4fc3616712edb19179b17dd270ad6cf63abf99c2         DeOldify   \n",
       "4  189667  e040bcacd38378386749db18aeba575b93f4ebca            manim   \n",
       "\n",
       "                                        path                     file_name  \\\n",
       "0              tests/core/test_evaluation.py            test_evaluation.py   \n",
       "1   keras/tests/custom_training_loop_test.py  custom_training_loop_test.py   \n",
       "2  deploy/python/det_keypoint_unite_infer.py   det_keypoint_unite_infer.py   \n",
       "3                     fastai/vision/image.py                      image.py   \n",
       "4              manim/mobject/geometry/arc.py                        arc.py   \n",
       "\n",
       "           fun_name                                     commit_message  \\\n",
       "0        skip_on_CI  Skip e2e tests on CI: these tests take too lon...   \n",
       "1              call  Reformatting the codebase with black.\\n\\nPiper...   \n",
       "2  smoothing_factor  one euro filter and ema smoothing for keypoint...   \n",
       "3              data        Upgrading to support latest Pytorch version   \n",
       "4        stop_angle  Improved structure of the :mod:`.mobject` modu...   \n",
       "\n",
       "                                                code  \\\n",
       "0  def skip_on_CI() -> bool:\\n    \\n    return os...   \n",
       "1  def call(self, inputs):\\n        self.add_loss...   \n",
       "2  def smoothing_factor(self, te, fc):\\n        r...   \n",
       "3  def data(self)->TensorImage:\\n        \"Return ...   \n",
       "4  def stop_angle(self):\\n        return angle_of...   \n",
       "\n",
       "                                                 url language  ...  \\\n",
       "0                 https://github.com/RasaHQ/rasa.git   Python  ...   \n",
       "1            https://github.com/keras-team/keras.git   Python  ...   \n",
       "2  https://github.com/PaddlePaddle/PaddleDetectio...   Python  ...   \n",
       "3             https://github.com/jantic/DeOldify.git   Python  ...   \n",
       "4        https://github.com/ManimCommunity/manim.git   Python  ...   \n",
       "\n",
       "  n_whitespaces  n_words  vocab_size  complexity  nloc  token_counts  \\\n",
       "0            18       12          12           1     3            28   \n",
       "1            21        8           8           1     3            24   \n",
       "2            36       19          16           1     3            28   \n",
       "3            24       11          11           1     3            12   \n",
       "4            14        8           8           1     2            24   \n",
       "\n",
       "   n_ast_nodes  n_identifiers                           signature  \\\n",
       "0           55              5            def skip_on_CI() -> bool   \n",
       "1           38              7              def call(self, inputs)   \n",
       "2           42              7  def smoothing_factor(self, te, fc)   \n",
       "3           22              4         def data(self)->TensorImage   \n",
       "4           39              6                def stop_angle(self)   \n",
       "\n",
       "                                              prompt  \n",
       "0  def skip_on_CI() -> bool:\\n    \\n    return os...  \n",
       "1  def call(self, inputs):\\n        self.add_loss...  \n",
       "2  def smoothing_factor(self, te, fc):\\n        r...  \n",
       "3  def data(self)->TensorImage:\\n        \"Return ...  \n",
       "4  def stop_angle(self):\\n        return angle_of...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galeras_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rational_pos</th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "      <th>exp</th>\n",
       "      <th>token_type</th>\n",
       "      <th>span</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>def</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>['module', 'function_definition', 'def']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>skip</td>\n",
       "      <td>0</td>\n",
       "      <td>[('def', 0.00029721998726017773)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.00029721998726017773]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>['module', 'function_definition']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[(' skip', 0.3496493101119995)]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3496493101119995]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>on</td>\n",
       "      <td>0</td>\n",
       "      <td>[('_', 0.001134732156060636), (' skip', 0.0059...</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>[0.001134732156060636, 0.0059091681614518166, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(9, 11)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[('on', 0.2272750586271286)]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0.2272750586271286]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(11, 12)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>39</td>\n",
       "      <td>('</td>\n",
       "      <td>99</td>\n",
       "      <td>[('override', 0.030208399519324303), (' import...</td>\n",
       "      <td>[38, 14, 33, 35, 2]</td>\n",
       "      <td>[0.030208399519324303, 0.08234483003616333, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(164, 166)</td>\n",
       "      <td>['module', 'function_definition', 'block', 'ER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>40</td>\n",
       "      <td>pip</td>\n",
       "      <td>99</td>\n",
       "      <td>[(\"('\", 0.00017135975940618664), ('pip', 0.240...</td>\n",
       "      <td>[39, 16]</td>\n",
       "      <td>[0.00017135975940618664, 0.24006126821041107]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(166, 169)</td>\n",
       "      <td>['NNS', 'module', 'function_definition', 'bloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>41</td>\n",
       "      <td>',</td>\n",
       "      <td>99</td>\n",
       "      <td>[('pip', 0.024009736254811287), (\"('\", 0.13641...</td>\n",
       "      <td>[40, 39, 38]</td>\n",
       "      <td>[0.024009736254811287, 0.13641567528247833, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(169, 171)</td>\n",
       "      <td>['module', 'function_definition', 'block', 'ER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>42</td>\n",
       "      <td>'</td>\n",
       "      <td>99</td>\n",
       "      <td>[(\"',\", 0.31870272755622864)]</td>\n",
       "      <td>[41]</td>\n",
       "      <td>[0.31870272755622864]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(171, 173)</td>\n",
       "      <td>['module', 'function_definition', 'block', 'ER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>43</td>\n",
       "      <td>auto</td>\n",
       "      <td>99</td>\n",
       "      <td>[(\" '\", 0.0009354767389595509), ('auto', 0.024...</td>\n",
       "      <td>[42, 23]</td>\n",
       "      <td>[0.0009354767389595509, 0.024885080754756927]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(173, 177)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'block...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rational_pos goal_token  from_seq_id  \\\n",
       "0                0        def            0   \n",
       "1                1       skip            0   \n",
       "2                2          _            0   \n",
       "3                3         on            0   \n",
       "4                4          _            0   \n",
       "...            ...        ...          ...   \n",
       "4395            39         ('           99   \n",
       "4396            40        pip           99   \n",
       "4397            41         ',           99   \n",
       "4398            42          '           99   \n",
       "4399            43       auto           99   \n",
       "\n",
       "                                           typesets_tgt    rationale_pos_tgt  \\\n",
       "0                                                   NaN                  NaN   \n",
       "1                     [('def', 0.00029721998726017773)]                  [0]   \n",
       "2                       [(' skip', 0.3496493101119995)]                  [1]   \n",
       "3     [('_', 0.001134732156060636), (' skip', 0.0059...            [2, 1, 0]   \n",
       "4                          [('on', 0.2272750586271286)]                  [3]   \n",
       "...                                                 ...                  ...   \n",
       "4395  [('override', 0.030208399519324303), (' import...  [38, 14, 33, 35, 2]   \n",
       "4396  [(\"('\", 0.00017135975940618664), ('pip', 0.240...             [39, 16]   \n",
       "4397  [('pip', 0.024009736254811287), (\"('\", 0.13641...         [40, 39, 38]   \n",
       "4398                      [(\"',\", 0.31870272755622864)]                 [41]   \n",
       "4399  [(\" '\", 0.0009354767389595509), ('auto', 0.024...             [42, 23]   \n",
       "\n",
       "                                     rationale_prob_tgt  exp token_type  \\\n",
       "0                                                   NaN    0        src   \n",
       "1                              [0.00029721998726017773]    0        src   \n",
       "2                                  [0.3496493101119995]    0        src   \n",
       "3     [0.001134732156060636, 0.0059091681614518166, ...    0        src   \n",
       "4                                  [0.2272750586271286]    0        src   \n",
       "...                                                 ...  ...        ...   \n",
       "4395  [0.030208399519324303, 0.08234483003616333, 0....    0        src   \n",
       "4396      [0.00017135975940618664, 0.24006126821041107]    0        src   \n",
       "4397  [0.024009736254811287, 0.13641567528247833, 0....    0        src   \n",
       "4398                              [0.31870272755622864]    0        src   \n",
       "4399      [0.0009354767389595509, 0.024885080754756927]    0        src   \n",
       "\n",
       "            span                                               tags  \n",
       "0         (0, 3)           ['module', 'function_definition', 'def']  \n",
       "1         (3, 8)                  ['module', 'function_definition']  \n",
       "2         (8, 9)  ['NN', 'module', 'function_definition', 'ident...  \n",
       "3        (9, 11)  ['NN', 'module', 'function_definition', 'ident...  \n",
       "4       (11, 12)  ['NN', 'module', 'function_definition', 'ident...  \n",
       "...          ...                                                ...  \n",
       "4395  (164, 166)  ['module', 'function_definition', 'block', 'ER...  \n",
       "4396  (166, 169)  ['NNS', 'module', 'function_definition', 'bloc...  \n",
       "4397  (169, 171)  ['module', 'function_definition', 'block', 'ER...  \n",
       "4398  (171, 173)  ['module', 'function_definition', 'block', 'ER...  \n",
       "4399  (173, 177)  ['NN', 'module', 'function_definition', 'block...  \n",
       "\n",
       "[4400 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rational_pos</th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "      <th>exp</th>\n",
       "      <th>token_type</th>\n",
       "      <th>span</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>def</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>['module', 'function_definition', 'def']</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>skip</td>\n",
       "      <td>0</td>\n",
       "      <td>[('def', 0.00029721998726017773)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.00029721998726017773]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>['module', 'function_definition']</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[(' skip', 0.3496493101119995)]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3496493101119995]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'ident...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>on</td>\n",
       "      <td>0</td>\n",
       "      <td>[('_', 0.001134732156060636), (' skip', 0.0059...</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>[0.001134732156060636, 0.0059091681614518166, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(9, 11)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'ident...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[('on', 0.2272750586271286)]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0.2272750586271286]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(11, 12)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'ident...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rational_pos goal_token  from_seq_id  \\\n",
       "0             0        def            0   \n",
       "1             1       skip            0   \n",
       "2             2          _            0   \n",
       "3             3         on            0   \n",
       "4             4          _            0   \n",
       "\n",
       "                                        typesets_tgt rationale_pos_tgt  \\\n",
       "0                                                NaN               NaN   \n",
       "1                  [('def', 0.00029721998726017773)]               [0]   \n",
       "2                    [(' skip', 0.3496493101119995)]               [1]   \n",
       "3  [('_', 0.001134732156060636), (' skip', 0.0059...         [2, 1, 0]   \n",
       "4                       [('on', 0.2272750586271286)]               [3]   \n",
       "\n",
       "                                  rationale_prob_tgt  exp token_type  \\\n",
       "0                                                NaN    0        src   \n",
       "1                           [0.00029721998726017773]    0        src   \n",
       "2                               [0.3496493101119995]    0        src   \n",
       "3  [0.001134732156060636, 0.0059091681614518166, ...    0        src   \n",
       "4                               [0.2272750586271286]    0        src   \n",
       "\n",
       "       span                                               tags  tag_count  \n",
       "0    (0, 3)           ['module', 'function_definition', 'def']         40  \n",
       "1    (3, 8)                  ['module', 'function_definition']         33  \n",
       "2    (8, 9)  ['NN', 'module', 'function_definition', 'ident...         53  \n",
       "3   (9, 11)  ['NN', 'module', 'function_definition', 'ident...         53  \n",
       "4  (11, 12)  ['NN', 'module', 'function_definition', 'ident...         53  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_array(input):\n",
    "    pattern = \"(',\\s+')|(\\')\"\n",
    "    x = re.sub(pattern,\" \",input)\n",
    "    return x.split(\" \")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys_by_value(values, target):\n",
    "    keys = []\n",
    "    for key, value in values.items():\n",
    "        if target in value:\n",
    "            keys.append(key)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_classification(tags) -> dict:\n",
    "    sc_dict = pl_taxonomy_python()\n",
    "    nl_dict = nl_pos_taxonomy()\n",
    "    categories = list()\n",
    "    semantic_dic = global_groups()\n",
    "    semantic_non_semantic = list()\n",
    "    for tag in tags:\n",
    "        sc_keys = get_keys_by_value(sc_dict,tag)\n",
    "        nl_keys = get_keys_by_value(nl_dict,tag)\n",
    "        if sc_keys:\n",
    "            categories.extend(sc_keys)\n",
    "        if nl_keys:\n",
    "            categories.extend(nl_keys)\n",
    "        if not sc_keys and not nl_keys:\n",
    "            categories.append('unknown')\n",
    "    for category in categories:\n",
    "        semantic_non_semantic.extend(get_keys_by_value(semantic_dic,category))\n",
    "    frequency_count = Counter(semantic_non_semantic)\n",
    "    result = dict(frequency_count)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_results['tag_array'] = tagged_results['tags'].apply(lambda x: convert_string_to_array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rational_pos</th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "      <th>exp</th>\n",
       "      <th>token_type</th>\n",
       "      <th>span</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>tag_array</th>\n",
       "      <th>tag_semantic_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>def</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>['module', 'function_definition', 'def']</td>\n",
       "      <td>None</td>\n",
       "      <td>[module, function_definition, def]</td>\n",
       "      <td>{'unknown': 1, 'sc_semantic': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>skip</td>\n",
       "      <td>0</td>\n",
       "      <td>[('def', 0.00029721998726017773)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.00029721998726017773]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>['module', 'function_definition']</td>\n",
       "      <td>None</td>\n",
       "      <td>[module, function_definition]</td>\n",
       "      <td>{'unknown': 1, 'sc_semantic': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[(' skip', 0.3496493101119995)]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3496493101119995]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(8, 9)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'ident...</td>\n",
       "      <td>None</td>\n",
       "      <td>[NN, module, function_definition, identifier]</td>\n",
       "      <td>{'nl_semantic': 1, 'unknown': 1, 'sc_semantic'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>on</td>\n",
       "      <td>0</td>\n",
       "      <td>[('_', 0.001134732156060636), (' skip', 0.0059...</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>[0.001134732156060636, 0.0059091681614518166, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(9, 11)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'ident...</td>\n",
       "      <td>None</td>\n",
       "      <td>[NN, module, function_definition, identifier]</td>\n",
       "      <td>{'nl_semantic': 1, 'unknown': 1, 'sc_semantic'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[('on', 0.2272750586271286)]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0.2272750586271286]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(11, 12)</td>\n",
       "      <td>['NN', 'module', 'function_definition', 'ident...</td>\n",
       "      <td>None</td>\n",
       "      <td>[NN, module, function_definition, identifier]</td>\n",
       "      <td>{'nl_semantic': 1, 'unknown': 1, 'sc_semantic'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rational_pos goal_token  from_seq_id  \\\n",
       "0             0        def            0   \n",
       "1             1       skip            0   \n",
       "2             2          _            0   \n",
       "3             3         on            0   \n",
       "4             4          _            0   \n",
       "\n",
       "                                        typesets_tgt rationale_pos_tgt  \\\n",
       "0                                                NaN               NaN   \n",
       "1                  [('def', 0.00029721998726017773)]               [0]   \n",
       "2                    [(' skip', 0.3496493101119995)]               [1]   \n",
       "3  [('_', 0.001134732156060636), (' skip', 0.0059...         [2, 1, 0]   \n",
       "4                       [('on', 0.2272750586271286)]               [3]   \n",
       "\n",
       "                                  rationale_prob_tgt  exp token_type  \\\n",
       "0                                                NaN    0        src   \n",
       "1                           [0.00029721998726017773]    0        src   \n",
       "2                               [0.3496493101119995]    0        src   \n",
       "3  [0.001134732156060636, 0.0059091681614518166, ...    0        src   \n",
       "4                               [0.2272750586271286]    0        src   \n",
       "\n",
       "       span                                               tags tag_count  \\\n",
       "0    (0, 3)           ['module', 'function_definition', 'def']      None   \n",
       "1    (3, 8)                  ['module', 'function_definition']      None   \n",
       "2    (8, 9)  ['NN', 'module', 'function_definition', 'ident...      None   \n",
       "3   (9, 11)  ['NN', 'module', 'function_definition', 'ident...      None   \n",
       "4  (11, 12)  ['NN', 'module', 'function_definition', 'ident...      None   \n",
       "\n",
       "                                       tag_array  \\\n",
       "0             [module, function_definition, def]   \n",
       "1                  [module, function_definition]   \n",
       "2  [NN, module, function_definition, identifier]   \n",
       "3  [NN, module, function_definition, identifier]   \n",
       "4  [NN, module, function_definition, identifier]   \n",
       "\n",
       "                                  tag_semantic_array  \n",
       "0                   {'unknown': 1, 'sc_semantic': 2}  \n",
       "1                   {'unknown': 1, 'sc_semantic': 1}  \n",
       "2  {'nl_semantic': 1, 'unknown': 1, 'sc_semantic'...  \n",
       "3  {'nl_semantic': 1, 'unknown': 1, 'sc_semantic'...  \n",
       "4  {'nl_semantic': 1, 'unknown': 1, 'sc_semantic'...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_results['tag_semantic_array'] = tagged_results['tag_array'].apply(lambda x: tag_classification(x))\n",
    "tagged_results['tag_count'] = tagged_results['tag_array'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_counters(counter_list):\n",
    "    result_counter = Counter()\n",
    "    for counter in counter_list:\n",
    "        result_counter += counter\n",
    "    return result_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggeg_grouped = tagged_results.groupby('from_seq_id')['tag_semantic_array'].apply(sum_counters).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>level_1</th>\n",
       "      <th>tag_semantic_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>sc_semantic</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>nl_semantic</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>sc_nl</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>sc_not_semantic</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>99</td>\n",
       "      <td>nl_semantic</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>99</td>\n",
       "      <td>sc_nl</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>99</td>\n",
       "      <td>sc_not_semantic</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>99</td>\n",
       "      <td>nl_not_semantic</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>99</td>\n",
       "      <td>sc_errors</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     from_seq_id          level_1  tag_semantic_array\n",
       "0              0          unknown                46.0\n",
       "1              0      sc_semantic                94.0\n",
       "2              0      nl_semantic                20.0\n",
       "3              0            sc_nl                21.0\n",
       "4              0  sc_not_semantic                51.0\n",
       "..           ...              ...                 ...\n",
       "695           99      nl_semantic                26.0\n",
       "696           99            sc_nl                26.0\n",
       "697           99  sc_not_semantic                 8.0\n",
       "698           99  nl_not_semantic                 5.0\n",
       "699           99        sc_errors                10.0\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggeg_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_grouped = taggeg_grouped.pivot(index='from_seq_id', columns='level_1', values='tag_semantic_array').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_total_counts = tagged_results.groupby('from_seq_id')['tag_count'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_galeras = galeras_dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([selected_galeras,tagged_grouped, tagged_total_counts.iloc[:,1] ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>fun_name</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>code</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>nl_not_semantic</th>\n",
       "      <th>nl_semantic</th>\n",
       "      <th>sc_errors</th>\n",
       "      <th>sc_nl</th>\n",
       "      <th>sc_not_semantic</th>\n",
       "      <th>sc_semantic</th>\n",
       "      <th>unknown</th>\n",
       "      <th>tag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159555</td>\n",
       "      <td>f9437064b3501869f5f56fb9e6d345d81ffeec5e</td>\n",
       "      <td>rasa</td>\n",
       "      <td>tests/core/test_evaluation.py</td>\n",
       "      <td>test_evaluation.py</td>\n",
       "      <td>skip_on_CI</td>\n",
       "      <td>Skip e2e tests on CI: these tests take too lon...</td>\n",
       "      <td>def skip_on_CI() -&gt; bool:\\n    \\n    return os...</td>\n",
       "      <td>https://github.com/RasaHQ/rasa.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def skip_on_CI() -&gt; bool:\\n    \\n    return os...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276430</td>\n",
       "      <td>84afc5193d38057e2e2badf9c889ea87d80d8fbf</td>\n",
       "      <td>keras</td>\n",
       "      <td>keras/tests/custom_training_loop_test.py</td>\n",
       "      <td>custom_training_loop_test.py</td>\n",
       "      <td>call</td>\n",
       "      <td>Reformatting the codebase with black.\\n\\nPiper...</td>\n",
       "      <td>def call(self, inputs):\\n        self.add_loss...</td>\n",
       "      <td>https://github.com/keras-team/keras.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def call(self, inputs):\\n        self.add_loss...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210956</td>\n",
       "      <td>39531637b5675a36409c303db022bfab90939896</td>\n",
       "      <td>PaddleDetection</td>\n",
       "      <td>deploy/python/det_keypoint_unite_infer.py</td>\n",
       "      <td>det_keypoint_unite_infer.py</td>\n",
       "      <td>smoothing_factor</td>\n",
       "      <td>one euro filter and ema smoothing for keypoint...</td>\n",
       "      <td>def smoothing_factor(self, te, fc):\\n        r...</td>\n",
       "      <td>https://github.com/PaddlePaddle/PaddleDetectio...</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def smoothing_factor(self, te, fc):\\n        r...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190542</td>\n",
       "      <td>4fc3616712edb19179b17dd270ad6cf63abf99c2</td>\n",
       "      <td>DeOldify</td>\n",
       "      <td>fastai/vision/image.py</td>\n",
       "      <td>image.py</td>\n",
       "      <td>data</td>\n",
       "      <td>Upgrading to support latest Pytorch version</td>\n",
       "      <td>def data(self)-&gt;TensorImage:\\n        \"Return ...</td>\n",
       "      <td>https://github.com/jantic/DeOldify.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def data(self)-&gt;TensorImage:\\n        \"Return ...</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189667</td>\n",
       "      <td>e040bcacd38378386749db18aeba575b93f4ebca</td>\n",
       "      <td>manim</td>\n",
       "      <td>manim/mobject/geometry/arc.py</td>\n",
       "      <td>arc.py</td>\n",
       "      <td>stop_angle</td>\n",
       "      <td>Improved structure of the :mod:`.mobject` modu...</td>\n",
       "      <td>def stop_angle(self):\\n        return angle_of...</td>\n",
       "      <td>https://github.com/ManimCommunity/manim.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def stop_angle(self):\\n        return angle_of...</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>158193</td>\n",
       "      <td>b64b41d8c1ac23c43f7a4e3f9f6339d6f0012ab2</td>\n",
       "      <td>d2l-zh</td>\n",
       "      <td>d2l/mxnet.py</td>\n",
       "      <td>mxnet.py</td>\n",
       "      <td>forward</td>\n",
       "      <td>[PaddlePaddle] Merge master into Paddle branch...</td>\n",
       "      <td>def forward(self, X):\\n        # `X` shape: (b...</td>\n",
       "      <td>https://github.com/d2l-ai/d2l-zh.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def forward(self, X):\\n        # `X` shape: (b...</td>\n",
       "      <td>95</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>289189</td>\n",
       "      <td>bbe63bca4733b31b6f6cf29270cdd62765309fdf</td>\n",
       "      <td>core</td>\n",
       "      <td>homeassistant/components/switchbot/sensor.py</td>\n",
       "      <td>sensor.py</td>\n",
       "      <td>native_value</td>\n",
       "      <td>Bump pySwitchbot to 0.20.0 for bleak 0.19 chan...</td>\n",
       "      <td>def native_value(self) -&gt; str | int | None:\\n ...</td>\n",
       "      <td>https://github.com/home-assistant/core.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def native_value(self) -&gt; str | int | None:\\n ...</td>\n",
       "      <td>96</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>189952</td>\n",
       "      <td>ce9acddd41f39929d499b45e52621a2849b8333e</td>\n",
       "      <td>manim</td>\n",
       "      <td>tests/test_graphical_units/test_threed.py</td>\n",
       "      <td>test_threed.py</td>\n",
       "      <td>test_Cone</td>\n",
       "      <td>Improved performance of ``test_threed.py`` (#2...</td>\n",
       "      <td>def test_Cone(scene):\\n    scene.add(Cone(reso...</td>\n",
       "      <td>https://github.com/ManimCommunity/manim.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def test_Cone(scene):\\n    scene.add(Cone(reso...</td>\n",
       "      <td>97</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>161543</td>\n",
       "      <td>c80ad26d872efe19a8b8eca022489c241f10b9e2</td>\n",
       "      <td>rich</td>\n",
       "      <td>benchmarks/benchmarks.py</td>\n",
       "      <td>benchmarks.py</td>\n",
       "      <td>time_render_unicode_heavy</td>\n",
       "      <td>Add initial benchmark suite</td>\n",
       "      <td>def time_render_unicode_heavy(self):\\n        ...</td>\n",
       "      <td>https://github.com/Textualize/rich.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def time_render_unicode_heavy(self):\\n        ...</td>\n",
       "      <td>98</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>200563</td>\n",
       "      <td>2602635f69bd95bfcc2e0cedf56f6de596d7a5a5</td>\n",
       "      <td>sympy</td>\n",
       "      <td>sympy/interactive/session.py</td>\n",
       "      <td>session.py</td>\n",
       "      <td>enable_automatic_int_sympification</td>\n",
       "      <td>Fix auto_int_to_Integer in the qtconsole\\n\\nPr...</td>\n",
       "      <td>def enable_automatic_int_sympification(shell):...</td>\n",
       "      <td>https://github.com/sympy/sympy.git</td>\n",
       "      <td>Python</td>\n",
       "      <td>...</td>\n",
       "      <td>def enable_automatic_int_sympification(shell):...</td>\n",
       "      <td>99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                 commit_id             repo  \\\n",
       "0   159555  f9437064b3501869f5f56fb9e6d345d81ffeec5e             rasa   \n",
       "1   276430  84afc5193d38057e2e2badf9c889ea87d80d8fbf            keras   \n",
       "2   210956  39531637b5675a36409c303db022bfab90939896  PaddleDetection   \n",
       "3   190542  4fc3616712edb19179b17dd270ad6cf63abf99c2         DeOldify   \n",
       "4   189667  e040bcacd38378386749db18aeba575b93f4ebca            manim   \n",
       "..     ...                                       ...              ...   \n",
       "95  158193  b64b41d8c1ac23c43f7a4e3f9f6339d6f0012ab2           d2l-zh   \n",
       "96  289189  bbe63bca4733b31b6f6cf29270cdd62765309fdf             core   \n",
       "97  189952  ce9acddd41f39929d499b45e52621a2849b8333e            manim   \n",
       "98  161543  c80ad26d872efe19a8b8eca022489c241f10b9e2             rich   \n",
       "99  200563  2602635f69bd95bfcc2e0cedf56f6de596d7a5a5            sympy   \n",
       "\n",
       "                                            path  \\\n",
       "0                  tests/core/test_evaluation.py   \n",
       "1       keras/tests/custom_training_loop_test.py   \n",
       "2      deploy/python/det_keypoint_unite_infer.py   \n",
       "3                         fastai/vision/image.py   \n",
       "4                  manim/mobject/geometry/arc.py   \n",
       "..                                           ...   \n",
       "95                                  d2l/mxnet.py   \n",
       "96  homeassistant/components/switchbot/sensor.py   \n",
       "97     tests/test_graphical_units/test_threed.py   \n",
       "98                      benchmarks/benchmarks.py   \n",
       "99                  sympy/interactive/session.py   \n",
       "\n",
       "                       file_name                            fun_name  \\\n",
       "0             test_evaluation.py                          skip_on_CI   \n",
       "1   custom_training_loop_test.py                                call   \n",
       "2    det_keypoint_unite_infer.py                    smoothing_factor   \n",
       "3                       image.py                                data   \n",
       "4                         arc.py                          stop_angle   \n",
       "..                           ...                                 ...   \n",
       "95                      mxnet.py                             forward   \n",
       "96                     sensor.py                        native_value   \n",
       "97                test_threed.py                           test_Cone   \n",
       "98                 benchmarks.py           time_render_unicode_heavy   \n",
       "99                    session.py  enable_automatic_int_sympification   \n",
       "\n",
       "                                       commit_message  \\\n",
       "0   Skip e2e tests on CI: these tests take too lon...   \n",
       "1   Reformatting the codebase with black.\\n\\nPiper...   \n",
       "2   one euro filter and ema smoothing for keypoint...   \n",
       "3         Upgrading to support latest Pytorch version   \n",
       "4   Improved structure of the :mod:`.mobject` modu...   \n",
       "..                                                ...   \n",
       "95  [PaddlePaddle] Merge master into Paddle branch...   \n",
       "96  Bump pySwitchbot to 0.20.0 for bleak 0.19 chan...   \n",
       "97  Improved performance of ``test_threed.py`` (#2...   \n",
       "98                        Add initial benchmark suite   \n",
       "99  Fix auto_int_to_Integer in the qtconsole\\n\\nPr...   \n",
       "\n",
       "                                                 code  \\\n",
       "0   def skip_on_CI() -> bool:\\n    \\n    return os...   \n",
       "1   def call(self, inputs):\\n        self.add_loss...   \n",
       "2   def smoothing_factor(self, te, fc):\\n        r...   \n",
       "3   def data(self)->TensorImage:\\n        \"Return ...   \n",
       "4   def stop_angle(self):\\n        return angle_of...   \n",
       "..                                                ...   \n",
       "95  def forward(self, X):\\n        # `X` shape: (b...   \n",
       "96  def native_value(self) -> str | int | None:\\n ...   \n",
       "97  def test_Cone(scene):\\n    scene.add(Cone(reso...   \n",
       "98  def time_render_unicode_heavy(self):\\n        ...   \n",
       "99  def enable_automatic_int_sympification(shell):...   \n",
       "\n",
       "                                                  url language  ...  \\\n",
       "0                  https://github.com/RasaHQ/rasa.git   Python  ...   \n",
       "1             https://github.com/keras-team/keras.git   Python  ...   \n",
       "2   https://github.com/PaddlePaddle/PaddleDetectio...   Python  ...   \n",
       "3              https://github.com/jantic/DeOldify.git   Python  ...   \n",
       "4         https://github.com/ManimCommunity/manim.git   Python  ...   \n",
       "..                                                ...      ...  ...   \n",
       "95               https://github.com/d2l-ai/d2l-zh.git   Python  ...   \n",
       "96         https://github.com/home-assistant/core.git   Python  ...   \n",
       "97        https://github.com/ManimCommunity/manim.git   Python  ...   \n",
       "98             https://github.com/Textualize/rich.git   Python  ...   \n",
       "99                 https://github.com/sympy/sympy.git   Python  ...   \n",
       "\n",
       "                                               prompt  from_seq_id  \\\n",
       "0   def skip_on_CI() -> bool:\\n    \\n    return os...            0   \n",
       "1   def call(self, inputs):\\n        self.add_loss...            1   \n",
       "2   def smoothing_factor(self, te, fc):\\n        r...            2   \n",
       "3   def data(self)->TensorImage:\\n        \"Return ...            3   \n",
       "4   def stop_angle(self):\\n        return angle_of...            4   \n",
       "..                                                ...          ...   \n",
       "95  def forward(self, X):\\n        # `X` shape: (b...           95   \n",
       "96  def native_value(self) -> str | int | None:\\n ...           96   \n",
       "97  def test_Cone(scene):\\n    scene.add(Cone(reso...           97   \n",
       "98  def time_render_unicode_heavy(self):\\n        ...           98   \n",
       "99  def enable_automatic_int_sympification(shell):...           99   \n",
       "\n",
       "    nl_not_semantic  nl_semantic  sc_errors  sc_nl  sc_not_semantic  \\\n",
       "0               6.0         20.0        9.0   21.0             51.0   \n",
       "1              14.0         22.0       44.0   22.0             76.0   \n",
       "2               9.0         20.0       44.0   20.0             41.0   \n",
       "3               8.0         20.0       19.0   24.0             14.0   \n",
       "4               8.0         23.0        5.0   23.0             63.0   \n",
       "..              ...          ...        ...    ...              ...   \n",
       "95             15.0         20.0       44.0   28.0             14.0   \n",
       "96             10.0         17.0        5.0   17.0             56.0   \n",
       "97              8.0         23.0       22.0   23.0             43.0   \n",
       "98             10.0         27.0        1.0   27.0             64.0   \n",
       "99              5.0         26.0       10.0   26.0              8.0   \n",
       "\n",
       "    sc_semantic  unknown  tag_count  \n",
       "0          94.0     46.0        240  \n",
       "1          47.0     48.0        258  \n",
       "2          63.0     53.0        240  \n",
       "3          61.0     51.0        189  \n",
       "4         139.0     46.0        298  \n",
       "..          ...      ...        ...  \n",
       "95          7.0     48.0        163  \n",
       "96        110.0     48.0        252  \n",
       "97         66.0     69.0        245  \n",
       "98        168.0     46.0        332  \n",
       "99         80.0     75.0        224  \n",
       "\n",
       "[100 rows x 32 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_ast_errors</th>\n",
       "      <th>ast_levels</th>\n",
       "      <th>n_whitespaces</th>\n",
       "      <th>n_words</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>complexity</th>\n",
       "      <th>nloc</th>\n",
       "      <th>token_counts</th>\n",
       "      <th>n_ast_nodes</th>\n",
       "      <th>n_identifiers</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>nl_not_semantic</th>\n",
       "      <th>nl_semantic</th>\n",
       "      <th>sc_errors</th>\n",
       "      <th>sc_nl</th>\n",
       "      <th>sc_not_semantic</th>\n",
       "      <th>sc_semantic</th>\n",
       "      <th>unknown</th>\n",
       "      <th>tag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>182748.120000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>8.460000</td>\n",
       "      <td>19.030000</td>\n",
       "      <td>7.810000</td>\n",
       "      <td>7.580000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>4.870000</td>\n",
       "      <td>26.120000</td>\n",
       "      <td>33.640000</td>\n",
       "      <td>5.120000</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>8.820000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>15.788732</td>\n",
       "      <td>23.370000</td>\n",
       "      <td>29.02000</td>\n",
       "      <td>94.330000</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>233.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>97359.286552</td>\n",
       "      <td>0.261116</td>\n",
       "      <td>1.209558</td>\n",
       "      <td>6.653707</td>\n",
       "      <td>2.762282</td>\n",
       "      <td>2.391821</td>\n",
       "      <td>1.052702</td>\n",
       "      <td>6.559217</td>\n",
       "      <td>35.117201</td>\n",
       "      <td>7.967763</td>\n",
       "      <td>1.320239</td>\n",
       "      <td>29.011492</td>\n",
       "      <td>2.637645</td>\n",
       "      <td>3.874287</td>\n",
       "      <td>14.224642</td>\n",
       "      <td>5.892394</td>\n",
       "      <td>14.49206</td>\n",
       "      <td>35.740664</td>\n",
       "      <td>13.37569</td>\n",
       "      <td>37.334821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>284.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>118701.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.75000</td>\n",
       "      <td>66.750000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>210.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>188258.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>26.50000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>277977.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>74.250000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>35.25000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>57.50000</td>\n",
       "      <td>254.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>334797.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>76.00000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>332.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  n_ast_errors  ast_levels  n_whitespaces     n_words  \\\n",
       "count     100.000000    100.000000  100.000000     100.000000  100.000000   \n",
       "mean   182748.120000      0.050000    8.460000      19.030000    7.810000   \n",
       "std     97359.286552      0.261116    1.209558       6.653707    2.762282   \n",
       "min       284.000000      0.000000    5.000000       5.000000    3.000000   \n",
       "25%    118701.750000      0.000000    8.000000      14.000000    6.000000   \n",
       "50%    188258.500000      0.000000    8.000000      20.000000    7.500000   \n",
       "75%    277977.250000      0.000000    9.000000      23.000000    9.000000   \n",
       "max    334797.000000      2.000000   12.000000      36.000000   19.000000   \n",
       "\n",
       "       vocab_size  complexity        nloc  token_counts  n_ast_nodes  \\\n",
       "count  100.000000  100.000000  100.000000    100.000000   100.000000   \n",
       "mean     7.580000    1.270000    4.870000     26.120000    33.640000   \n",
       "std      2.391821    1.052702    6.559217     35.117201     7.967763   \n",
       "min      3.000000    1.000000    2.000000      8.000000    17.000000   \n",
       "25%      6.000000    1.000000    2.000000     15.000000    28.750000   \n",
       "50%      7.000000    1.000000    3.000000     18.000000    32.500000   \n",
       "75%      9.000000    1.000000    4.000000     24.000000    39.000000   \n",
       "max     16.000000    8.000000   34.000000    274.000000    64.000000   \n",
       "\n",
       "       n_identifiers  from_seq_id  nl_not_semantic  nl_semantic  sc_errors  \\\n",
       "count     100.000000   100.000000       100.000000   100.000000  71.000000   \n",
       "mean        5.120000    49.500000         8.820000    21.200000  15.788732   \n",
       "std         1.320239    29.011492         2.637645     3.874287  14.224642   \n",
       "min         2.000000     0.000000         2.000000    14.000000   1.000000   \n",
       "25%         4.000000    24.750000         7.000000    19.000000   5.500000   \n",
       "50%         5.000000    49.500000         9.000000    21.000000  12.000000   \n",
       "75%         6.000000    74.250000        10.000000    24.000000  18.500000   \n",
       "max         9.000000    99.000000        17.000000    32.000000  62.000000   \n",
       "\n",
       "            sc_nl  sc_not_semantic  sc_semantic    unknown   tag_count  \n",
       "count  100.000000        100.00000   100.000000  100.00000  100.000000  \n",
       "mean    23.370000         29.02000    94.330000   55.00000  233.500000  \n",
       "std      5.892394         14.49206    35.740664   13.37569   37.334821  \n",
       "min     14.000000          6.00000     7.000000    5.00000  140.000000  \n",
       "25%     20.000000         18.75000    66.750000   48.00000  210.750000  \n",
       "50%     23.000000         26.50000    93.500000   50.00000  233.000000  \n",
       "75%     26.000000         35.25000   121.500000   57.50000  254.250000  \n",
       "max     55.000000         76.00000   186.000000   99.00000  332.000000  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
