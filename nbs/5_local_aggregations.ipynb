{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Aggregations Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_default():\n",
    "    return {\n",
    "        'model_name' : '/workspaces/code-rationales/data/codeparrot-small/checkpoints/checkpoint-29000', \n",
    "        'cache_dir': '/workspaces/code-rationales/datax/df_cache_dir',\n",
    "        'delimiter_sequence': 'and signature is'\n",
    "    }\n",
    "prompts = [\n",
    "        \"\"\"\\\"\\\"\\\"Generate Python code that True if this Entry has references from any AppSession.\n",
    "If not, it can be removed from the cache.and signature is\\\"\\\"\\\" \n",
    "def has_refs(self) -> bool:\n",
    "    self.ref, self.context = None\n",
    "else:\n",
    "    try:\n",
    "    from rusty.api.py\n",
    "self.log_on_error = False\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = param_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_rationales.loader import download_grammars\n",
    "from tree_sitter import Language, Parser\n",
    "import code_rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-09-05 19:42:19.664941: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 19:42:19.866537: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import importlib\n",
    "from matplotlib import colors\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/workspaces/code-rationales/sequential-rationales/huggingface')\n",
    "from rationalization import rationalize_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Programming Language Taxonomy\n",
    "def pl_taxonomy_python() -> dict:\n",
    "    return {\n",
    "  \"punctuation\": ['{', '}', '[', ']', '(', ')','\\\"', ',', '.', '...', ';', ':'], \n",
    "  \"exceptions\": ['raise_statement','catch', 'try', 'finally', 'throw', 'throws', 'except'],\n",
    "  \"oop\": ['def','class','instanceof','interface','private','protected','public','abstract','extends','package','this','implements','import','new','super'],\n",
    "  \"asserts\": ['assert'],\n",
    "  \"types\": ['tuple','set','list','pair','subscript','type','none','dictionary','integer','native','static','synchronized','transient','volatile','void','final','enum','byte','char','float','boolean','double','int','long','short','strictfp'],\n",
    "  \"conditionals\": ['else', 'if', 'switch', 'case', 'default'],\n",
    "  \"loops\": ['break', 'do', 'for', 'while', 'continue'],\n",
    "  \"operators\": ['as','yield','is','@','in','and','or','not','**','slice','%','+','<','>','=','+','-','*','/','%','++','--','!','==','!=','>=','<=','&&','||','?',':','~','<<','>>','>>>','&','^','|','//'],\n",
    "  \"indentation\": ['\\n','\\t'],\n",
    "  \"bool\": ['true', 'false'], \n",
    "  \"functional\":['lambda','lambda_parameters'],\n",
    "  \"with\" : ['with','with_item','with_statement','with_clause'], \n",
    "  \"return\" :['return'],\n",
    "  \"structural\" : ['attribute', 'argument_list','parenthesized_expression','pattern_list','class_definition','function_definition','block'],\n",
    "  \"statements\" : ['return_statement','break_statement','assignment','while_statement','expression_statement','assert_statement'],\n",
    "  \"expression\": ['call','exec','async','ellipsis','unary_operator','binary_operator','as_pattern_target','boolean_operator','as_pattern','comparison_operator','conditional_expression','named_expression','not_operator','primary_expression','as_pattern'],\n",
    "  \"errors\": [\"ERROR\"],\n",
    "  \"identifier\":[\"identifier\"],  \n",
    "  \"comment\":[\"comment\"],\n",
    "  \"string\": ['string','interpolation','string_content','string_end','string_start','escape_sequence'], \n",
    "  \"unknown\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nl_pos_taxonomy() -> dict: return {\n",
    "    \"nl_verb\" : ['VBN', 'VBG', 'VBZ', 'VBP', 'VBD', 'VB'],\n",
    "    \"nl_noun\" : ['NN', 'NNPS', 'NNS', 'NNP'],\n",
    "    \"nl_pronoun\" : ['WP', 'PRP', 'PRP$', 'WP','WP$'], \n",
    "    \"nl_adverb\" : ['RBS','RBR', 'RB', 'WRB'], \n",
    "    \"nl_adjetive\" : ['JJR', 'JJS', 'JJ'], \n",
    "    \"nl_determier\" : ['DT','WDT','PDT'], \n",
    "    \"nl_preposition\" : ['IN', 'TO'],\n",
    "    \"nl_particle\" : ['RP'],\n",
    "    \"nl_modal\" : ['MD'],\n",
    "    \"nl_conjunction\" : ['CC'],\n",
    "    \"nl_cardinal\" : ['CD'],\n",
    "    \"nl_list\": ['LS'],\n",
    "    \"nl_other\" : ['FW', 'EX', 'SYM' , 'UH', 'POS', \"''\", '--',':', '(', ')', '.', ',', '``', '$']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AST Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_node_types(\n",
    "    nested_node_types: dict  # node_types from tree-sitter\n",
    ") -> list: # list of node types\n",
    "    def iterate_and_unroll_dict(nested_node_types: dict, all_node_types: set):\n",
    "        for key, value in nested_node_types.items():\n",
    "            if key == 'type' and type(value) == str:\n",
    "                all_node_types.add(value)\n",
    "            if type(value) == dict:\n",
    "                iterate_and_unroll_dict(value, all_node_types)\n",
    "            if type(value) == list:\n",
    "                for element in value:\n",
    "                    iterate_and_unroll_dict(element, all_node_types) \n",
    "    all_node_types = set()\n",
    "    for dictionary in nested_node_types:\n",
    "        iterate_and_unroll_dict(dictionary, all_node_types)\n",
    "    all_node_types.add('ERROR')\n",
    "    return list(all_node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parser(lang: str):\n",
    "    # Grab the node types from the tree-sitter language\n",
    "    language = Language(f\"{code_rationales.__path__[0]}/grammars/tree-sitter-languages.so\", lang)\n",
    "    node_path = f\"{code_rationales.__path__[0]}/grammars/tree-sitter-{lang}/src/node-types.json\"\n",
    "    with open(node_path) as f:\n",
    "            node_types = json.load(f)\n",
    "    node_types = unroll_node_types(node_types)\n",
    "    # Create a parser for the language\n",
    "    parser = Parser()\n",
    "    parser.set_language(language)\n",
    "    return parser, node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(\n",
    "    node,       # tree-sitter node\n",
    ") -> None:\n",
    "    \"\"\"Traverse in a recursive way, a tree-sitter node and append results to a list.\"\"\"\n",
    "    results = []\n",
    "    def traverse_tree(node, results):\n",
    "        if node.type == 'string':\n",
    "            results.append(node)\n",
    "            return\n",
    "        for n in node.children:\n",
    "            traverse_tree(n, results)\n",
    "        if not node.children:\n",
    "            results.append(node)\n",
    "    traverse_tree(node, results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_offset(\n",
    "    point,              #point to convert\n",
    "    lines: list         #list of lines in the source code\n",
    "    ):\n",
    "        \"\"\"Convert the point to an offset\"\"\"\n",
    "        row, column = point\n",
    "        chars_in_rows = sum(map(len, lines[:row])) + row\n",
    "        chars_in_columns = len(lines[row][:column])\n",
    "        offset = chars_in_rows + chars_in_columns\n",
    "        return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_span(node, lines):\n",
    "    \"\"\"Get the span position of the node in the code string\"\"\"\n",
    "    start_span = convert_to_offset(node.start_point, lines)\n",
    "    end_span = convert_to_offset(node.end_point, lines)\n",
    "    return start_span, end_span\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_token_span_in_node_span(tok_span, node_span):\n",
    "    return node_span[0] <= tok_span[0] and tok_span[1] <= node_span[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_type(\n",
    "    tok_span: tuple, # (start, end) position of a token in tokenizer\n",
    "    nodes: list,     # list of tree-sitter nodes\n",
    "    lines: list,     # list of lines in the code\n",
    ") -> tuple: # (parent_type, token_type) of the token\n",
    "    \"\"\"Get the parent AST type and token AST type of a token.\"\"\"\n",
    "    node_spans = [get_node_span(node, lines) for node in nodes]\n",
    "    for i, span in enumerate(node_spans):\n",
    "        if is_token_span_in_node_span(tok_span, span):\n",
    "            return nodes[i].parent.type, nodes[i].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_nodes(\n",
    "    tok_span: tuple, # (start, end) position of a token in tokenizer\n",
    "    node,            # tree-sitter node\n",
    "    lines: list,     # list of lines in the code\n",
    ") -> list: \n",
    "    \"\"\"Get all AST types for the given token span\"\"\"\n",
    "    results = []\n",
    "    def traverse_and_get_types(tok_span, node, lines, results) -> None:\n",
    "        node_span = get_node_span(node, lines)\n",
    "        if is_token_span_in_node_span(tok_span, node_span):\n",
    "            results.append(node)\n",
    "        for n in node.children:\n",
    "            traverse_and_get_types(tok_span, n, lines, results)\n",
    "    traverse_and_get_types(tok_span, node, lines, results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_by_type(\n",
    "    node, \n",
    "    node_types: list\n",
    ") -> list :\n",
    "    def traverse_and_search(node, node_types, results):\n",
    "        if node.type == 'string':\n",
    "            print('as')\n",
    "        if node.type in node_types:\n",
    "            results.append(node)\n",
    "        for n in node.children:\n",
    "            traverse_and_search(n, node_types ,results)\n",
    "    results = []\n",
    "    traverse_and_search(node, node_types, results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomy Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_results(global_results):\n",
    "    def clean_dictonary(result_dict):\n",
    "        clean_dict = result_dict.copy()\n",
    "        for key, value in result_dict.items():\n",
    "            if not value or not value['values']: \n",
    "                clean_dict.pop(key)\n",
    "        return clean_dict\n",
    "    for key, value in global_results.items():\n",
    "        global_results[key] = clean_dictonary(value)\n",
    "    return global_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_category_by_token(taxonomy_dict: dict, token_type: str):\n",
    "    for key, value in taxonomy_dict.items():\n",
    "        if token_type in value:\n",
    "            return key\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_taxonomy(taxonomy_dict: dict, result_dict: dict):\n",
    "    result_dict = result_dict.copy()\n",
    "    mappings = {token: {category : {'values': [], 'rationales': []} for category in taxonomy_dict.keys()} for token in result_dict.keys()}\n",
    "    for target_token, value in result_dict.items():\n",
    "        for source_token, props in value.items():\n",
    "            mappings[target_token][search_category_by_token(taxonomy_dict, source_token)]['values'].append(props['values'])\n",
    "            mappings[target_token][search_category_by_token(taxonomy_dict, source_token)]['rationales'].append(props['rationales'])\n",
    "    return clean_results(mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_local_results_to_taxonomy(taxonomy_dict:dict, local_results: dict):\n",
    "    return dict(zip(local_results.keys(), map(lambda aggegrations: map_to_taxonomy(taxonomy_dict, aggegrations), local_results.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Sampling Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sampled_generation(\n",
    "        df_sampled_code, \n",
    "        model,\n",
    "        tokenizer,\n",
    "        number_samples_generation = 1,\n",
    "        max_gen_tok = 100, \n",
    "        top_k = 0\n",
    "    ):\n",
    "    dict_generated_code = {i: [] for i in range(number_samples_generation)}\n",
    "    for idx_prompt, prompt in enumerate(df_sampled_code['prompt']):\n",
    "        input = tokenizer([prompt], return_tensors=\"pt\")\n",
    "        input.to(model.device)\n",
    "        outputs = model.generate(**input, do_sample=True,\n",
    "                                 max_length=len(df_sampled_code['input_ids'][idx_prompt]), ##Force rationalization\n",
    "                                 top_k=top_k, \n",
    "                                 num_return_sequences=number_samples_generation, \n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "        for index, output in enumerate(outputs):\n",
    "            dict_generated_code[index].append(output.tolist())\n",
    "    df_temp = pd.DataFrame().from_dict(data=dict_generated_code) # DataFrame from Generation\n",
    "    df_temp = pd.concat([df_sampled_code.reset_index(), df_temp ], axis=1) #Index before concating\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the model is not fine-tuned or compatible, it will rise an error\n",
    "#This function works for one tensor of source token and one tensor of target tokens\n",
    "def rationalize_model(model, tokenizer, input_ids, max_token_size: int, verbose=True):\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    all_rationales, log = rationalize_lm(\n",
    "        model = model,\n",
    "        input_ids = input_ids[:max_token_size],\n",
    "        tokenizer = tokenizer,\n",
    "        verbose = verbose,\n",
    "        max_steps=1024 #Max number of steps for greedy rationalization\n",
    "    )\n",
    "    return all_rationales, log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_rational(\n",
    "    model,\n",
    "    tokenizer, \n",
    "    arr_target_tokens, \n",
    "    seq_id, #mapping sequence id\n",
    "    max_token_size,\n",
    "    verbose=True\n",
    "):\n",
    "    arr_log = []\n",
    "    for index, val in enumerate(arr_target_tokens):\n",
    "        all_rationales, log = rationalize_model(\n",
    "            model=model, \n",
    "            tokenizer=tokenizer, \n",
    "            input_ids=val,\n",
    "            max_token_size=max_token_size,\n",
    "            verbose=False\n",
    "        )\n",
    "        arr_log.append(log)\n",
    "    arr_code_rationales = [ log['rationalization'] for log in arr_log ] #extracting just rationalizations\n",
    "    arr_from_sentence = [ list(np.full( len(val), seq_id[arr_i] )) #arr_i maps to the real sequence id\n",
    "                            for arr_i, val in enumerate(arr_code_rationales)]\n",
    "    arr_code_rationales = sum( arr_code_rationales, [] ) #flatting\n",
    "    arr_from_sentence = sum( arr_from_sentence, [] ) #flatting\n",
    "    return arr_code_rationales, arr_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_rationales( arr_code_rationales, arr_from_sentence ):\n",
    "    #Creating pandas_1 {p_rationale}\n",
    "    rational = lambda list_log,typeset: [ (dict_tok['added_token_text'],round(dict_tok['true_token_prob'],6)) for dict_tok in list_log if dict_tok['from']==typeset]\n",
    "    log = lambda log_row: [(log_dict['added_token_text'],log_dict['true_token_prob']) for log_dict in log_row] #Typeset\n",
    "\n",
    "    log_position = lambda log_row: [log_dict['added_token_position'] for log_dict in log_row] #Position of the Rationale\n",
    "    log_prediction = lambda log_row: [log_dict['true_token_prob'] for log_dict in log_row] #Rationale Prob\n",
    "\n",
    "    p_rationale = pd.DataFrame()\n",
    "\n",
    "    p_rationale['goal_token'] = [dict_token['goal_word'] for dict_token in arr_code_rationales]\n",
    "    p_rationale['from_seq_id'] = arr_from_sentence\n",
    "\n",
    "    p_rationale['typesets_tgt'] = [ log(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    \n",
    "    p_rationale['rationale_pos_tgt'] = [ log_position(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    p_rationale['rationale_prob_tgt'] = [ log_prediction(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "\n",
    "\n",
    "    return p_rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running Rationalization\n",
    "def run_code_rational( \n",
    "        df_generated_input,\n",
    "        tensor_size, #Control the size of the experiment, \n",
    "        model,\n",
    "        tokenizer,\n",
    "        experiment = '5',\n",
    "        batch_size = 100, \n",
    "        max_token_size = 44,\n",
    "        verbose = True \n",
    "    ):\n",
    "\n",
    "    arr_rationals = []\n",
    "    arr_from_seq = []\n",
    "\n",
    "    for i in range( 0 , tensor_size , batch_size ):\n",
    "        print('************************' + str(i) + '************************')\n",
    "        t_generated_input = df_generated_input[experiment].values[i:i+batch_size]\n",
    "        t_generated_input = [ torch.tensor(s).to(model.device) for s in t_generated_input]\n",
    "\n",
    "        t_arr_rationals,t_arr_from_seq = run_multiple_rational(\n",
    "            model = model,\n",
    "            tokenizer = tokenizer,\n",
    "            arr_target_tokens =  t_generated_input, \n",
    "            seq_id = list(range(i,i+batch_size)),\n",
    "            max_token_size = len(t_generated_input[0]),\n",
    "            verbose = verbose\n",
    "        )\n",
    "\n",
    "        arr_rationals = arr_rationals + t_arr_rationals\n",
    "        arr_from_seq = arr_from_seq + t_arr_from_seq\n",
    "\n",
    "        torch.cuda.empty_cache() #Cleaning Cache\n",
    "        \n",
    "    print(\"Experiment Finished: \" + str(experiment))\n",
    "    return pandas_rationales( arr_rationals, arr_from_seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_rational_all_set(exp, df_generated_input, model, tokenizer, tensor_n = 100, BATCH = 10): #When Tensor_n and batch differs then 'from_seq_id' is lost\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    EXP = exp\n",
    "    test_arr_rationals = run_code_rational( \n",
    "            df_generated_input,\n",
    "            tensor_n,\n",
    "            model, \n",
    "            tokenizer,\n",
    "            experiment = EXP,\n",
    "            batch_size = BATCH,\n",
    "            verbose = False \n",
    "        )\n",
    "    #Saving process\n",
    "    return test_arr_rationals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rationales Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_right_span = lambda start_idx, end_idx, initial_token, df : len(initial_token + ''.join(map(str, df.loc[start_idx:end_idx, 'goal_token'].tolist())))\n",
    "calculate_span = lambda right_span, token : (right_span-len(str(token)), right_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_auxiliary_columns_to_experiment_result(df, delimiter_sequence: str):\n",
    "    initial_token = df['typesets_tgt'][0][0][0]\n",
    "    ### TOKEN TYPE COLUMN\n",
    "    token_type_column = ['src'] * len(df)\n",
    "    sequence = initial_token\n",
    "    for idx, goal_token in enumerate(df['goal_token']):\n",
    "        if delimiter_sequence not in sequence:\n",
    "            token_type_column[idx] = 'nl'\n",
    "            sequence+=goal_token\n",
    "    df['token_type'] = token_type_column\n",
    "    ### TOKEN SPAN COLUMN - CHECK FOR DATASETS\n",
    "    src_initial_token_idx = df[df['token_type']== 'src'].first_valid_index()\n",
    "    df['span'] = [None] * len(df[:src_initial_token_idx]) + [calculate_span(calculate_right_span(src_initial_token_idx, index, initial_token, df), token) for index, token in df[src_initial_token_idx:]['goal_token'].items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nl_tags_in_experiment_result(df, nl_ast_types, nl_pos_types, parser):\n",
    "    initial_token = df['typesets_tgt'][0][0][0]\n",
    "    ##### POS TAGS FOR NL PART\n",
    "    target_nl = initial_token + ''.join(df[df['token_type'] == 'nl']['goal_token'].map(lambda value: str(value)))\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(target_nl))\n",
    "    for idx in range(df[df['token_type']== 'src'].first_valid_index()):\n",
    "        nl_tags = list(map(lambda tag: tag[1] if tag[1] in nl_pos_types else None, filter(lambda tag: tag[0] in str(df['goal_token'][idx]), pos_tags)))\n",
    "        if nl_tags: df.at[idx, 'tags'] = df['tags'][idx] + [nl_tags[-1]]\n",
    "    ##### POS TAGS FOR CODE PART\n",
    "    target_code = ''.join(df[df['token_type'] == 'src']['goal_token'].map(lambda value: str(value)))\n",
    "    nl_target_nodes = get_nodes_by_type(parser.parse(bytes(target_code, 'utf8')).root_node, nl_ast_types)\n",
    "    for token_idx in range(df[df['token_type'] == 'src'].first_valid_index(), len(df['span'])):\n",
    "                for nl_target_node in nl_target_nodes:\n",
    "                    if is_token_span_in_node_span(df['span'][token_idx], get_node_span(nl_target_node, target_code.split(\"\\n\"))) and \\\n",
    "                            str(df['goal_token'][token_idx]) in nl_target_node.text.decode('utf-8'):\n",
    "                            tagged_token_list = list(filter(lambda tagged_token: tagged_token[0] in str(df['goal_token'][token_idx]), \\\n",
    "                                                        nltk.pos_tag( nltk.word_tokenize(nl_target_node.text.decode('utf-8')))))\n",
    "                            if len(tagged_token_list)>0 and tagged_token_list[0][1] in nl_pos_types and tagged_token_list[0][1] not in df['tags'][token_idx]: df.at[token_idx, 'tags'] = df['tags'][token_idx] + [tagged_token_list[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ast_tags_in_experiment_result(df, parser):\n",
    "    initial_token = df['typesets_tgt'][0][0][0] if df[df['token_type'] == 'src'].first_valid_index() == 0 else ''\n",
    "    target_code = initial_token + ''.join(df[df['token_type'] == 'src']['goal_token'].map(lambda value: str(value)))\n",
    "    src_initial_token_idx = df[df['token_type'] == 'src'].first_valid_index()\n",
    "    target_ast = parser.parse(bytes(target_code, 'utf8')).root_node\n",
    "    for token_idx in range(src_initial_token_idx, len(df)):\n",
    "        df.at[token_idx, 'tags'] = df['tags'][token_idx] + list(map(lambda node: node.type, get_token_nodes(df['span'][token_idx], target_ast, target_code.split(\"\\n\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_rationals(experiment_results: list, nl_ast_types: list, nl_pos_types: list, delimiter_sequence: str, parser):\n",
    "    experiments = {}\n",
    "    for exp_idx, df_experiment in enumerate(experiment_results):\n",
    "        experiment_results = []\n",
    "        experiment_rational_results = [df_experiment[(df_experiment['from_seq_id'] == sample_idx) | \\\n",
    "                                                     (df_experiment['from_seq_id'] == str(sample_idx))].reset_index() \\\n",
    "                                                    for sample_idx in range(len(prompts))]\n",
    "        print('*'*10 +'Tagging rationals for exp: ' +str(exp_idx) + '*'*10)\n",
    "        for experiment_rational_result in experiment_rational_results:\n",
    "            add_auxiliary_columns_to_experiment_result(experiment_rational_result, delimiter_sequence)\n",
    "            experiment_rational_result['tags'] = [[]]*len(experiment_rational_result)\n",
    "            fill_nl_tags_in_experiment_result(experiment_rational_result, nl_ast_types, nl_pos_types, parser)\n",
    "            fill_ast_tags_in_experiment_result(experiment_rational_result, parser)\n",
    "            experiment_results.append(experiment_rational_result)\n",
    "        experiments[exp_idx] = experiment_results\n",
    "    return experiments\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rationales Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rationals(global_tagged_results: dict, ast_node_types: list, nl_pos_types: list, number_samples: int):\n",
    "    aggregation_results = {sample_id: None  for sample_id in range(number_samples)}\n",
    "    for exp_idx, experiment_results in global_tagged_results.items():\n",
    "        print('*'*10 +'Aggregrating rationals for exp: ' +str(exp_idx) + '*'*10)\n",
    "        for experiment_result in experiment_results:\n",
    "            sample_results = {str(pos+1)+'['+str(token)+']' : {node_type : {'values': [], 'rationales': []} for node_type in ast_node_types + nl_pos_types} for pos, token in enumerate(experiment_result['goal_token'].tolist())}\n",
    "            for target_idx, target_token in enumerate(experiment_result['goal_token'].tolist()):\n",
    "                for rational_idx, rational_pos in enumerate(experiment_result['rationale_pos_tgt'][target_idx]):\n",
    "                    if rational_pos > 0: #initial token is ignored IMPORTANT\n",
    "                        for rational_tag in experiment_result['tags'][rational_pos - 1]: \n",
    "                            if rational_tag:\n",
    "                                try:\n",
    "                                    sample_results[str(target_idx+1)+'['+str(target_token)+']'][rational_tag]['values'].append(experiment_result['rationale_prob_tgt'][target_idx][rational_idx])\n",
    "                                    sample_results[str(target_idx+1)+'['+str(target_token)+']'][rational_tag]['rationales'].append(str(rational_pos - 1)+'['+str(experiment_result['goal_token'][rational_pos - 1])+']')\n",
    "                                except Exception as e:\n",
    "                                    print('An Error Occurred')\n",
    "            aggregation_results[experiment_result['from_seq_id'].unique()[0]] = clean_results(sample_results)\n",
    "    return aggregation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOCAL EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define parser\n",
    "parser, node_types = create_parser('python')\n",
    "### Defines pos tags \n",
    "pos_types = list(nltk.data.load('help/tagsets/upenn_tagset.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Tokenizer Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(32768, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(params['model_name'], cache_dir=params['cache_dir'])\n",
    "tokenizer = AutoTokenizer.from_pretrained(params['model_name'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled_code = pd.DataFrame(prompts, columns=['prompt'])\n",
    "df_sampled_code['input_ids'] = tokenizer(df_sampled_code['prompt'].tolist())['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 79, but ``max_length`` is set to 79.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    }
   ],
   "source": [
    "### SAMPLING GENERATION \n",
    "df_generated_input = df_sampled_generation(\n",
    "    df_sampled_code=df_sampled_code, \n",
    "    model=model,\n",
    "    tokenizer=tokenizer, \n",
    "    number_samples_generation=1,\n",
    "    max_gen_tok=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************0************************\n",
      "Experiment Finished: 0\n"
     ]
    }
   ],
   "source": [
    "### GET RATIONALES\n",
    "experiment_results = []\n",
    "for i in df_generated_input.columns[3:]: #Only Generated Sequences \n",
    "    experiment_result = run_code_rational_all_set(df_generated_input=df_generated_input, exp=i, tensor_n=df_generated_input.shape[0],model=model, tokenizer=tokenizer, BATCH=10)\n",
    "    experiment_result['exp'] = i\n",
    "    experiment_results.append(experiment_result)\n",
    "df_experiment_results = pd.concat(experiment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Tagging rationals for exp: 0**********\n"
     ]
    }
   ],
   "source": [
    "###TAG EXPERIMENTS RESULTS - TAKES TIME\n",
    "nl_ast_types = ['comment','identifier','string']\n",
    "tagged_results = tag_rationals([df_experiment_results], nl_ast_types, pos_types, params['delimiter_sequence'], parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "      <th>exp</th>\n",
       "      <th>token_type</th>\n",
       "      <th>span</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Generate</td>\n",
       "      <td>0</td>\n",
       "      <td>[(\"\"\", 0.00021326643764041364)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.00021326643764041364]</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[NNP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>[(Generate, 0.0006065950146876276), (\"\"\", 0.00...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.0006065950146876276, 0.0015060030855238438]</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[NNP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>0</td>\n",
       "      <td>[( Python, 0.00798844825476408), (\"\"\", 0.02216...</td>\n",
       "      <td>[2, 0, 1]</td>\n",
       "      <td>[0.00798844825476408, 0.022162150591611862, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>that</td>\n",
       "      <td>0</td>\n",
       "      <td>[( code, 0.0016746035544201732), (\"\"\", 0.02259...</td>\n",
       "      <td>[3, 0, 1, 2]</td>\n",
       "      <td>[0.0016746035544201732, 0.022595535963773727, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[IN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[( that, 0.0001442114298697561), (\"\"\", 0.00013...</td>\n",
       "      <td>[4, 0, 1, 2, 3]</td>\n",
       "      <td>[0.0001442114298697561, 0.00013347486674319953...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[NNP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>if</td>\n",
       "      <td>0</td>\n",
       "      <td>[( True, 0.009045373648405075), (\"\"\", 0.403910...</td>\n",
       "      <td>[5, 0]</td>\n",
       "      <td>[0.009045373648405075, 0.4039102792739868]</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[IN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>this</td>\n",
       "      <td>0</td>\n",
       "      <td>[( if, 0.0024248436093330383), ( that, 0.02887...</td>\n",
       "      <td>[6, 4, 5, 0, 1, 3, 2]</td>\n",
       "      <td>[0.0024248436093330383, 0.028876375406980515, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[VBZ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Entry</td>\n",
       "      <td>0</td>\n",
       "      <td>[( this, 4.844649993174244e-06), (\"\"\", 1.79923...</td>\n",
       "      <td>[7, 0, 1, 5, 6, 4, 2, 3]</td>\n",
       "      <td>[4.844649993174244e-06, 1.79923081304878e-05, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>has</td>\n",
       "      <td>0</td>\n",
       "      <td>[( Entry, 0.00033161439932882786), ( this, 0.0...</td>\n",
       "      <td>[8, 7, 6, 0, 5, 3, 1, 4, 2]</td>\n",
       "      <td>[0.00033161439932882786, 0.010388635098934174,...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[VBZ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>references</td>\n",
       "      <td>0</td>\n",
       "      <td>[( has, 2.149678584828507e-05), ( this, 9.9156...</td>\n",
       "      <td>[9, 7, 8, 3, 6, 2, 1, 0, 4, 5]</td>\n",
       "      <td>[2.149678584828507e-05, 9.915613190969452e-05,...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[NNS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>from</td>\n",
       "      <td>0</td>\n",
       "      <td>[( references, 0.0076303561218082905), ( Pytho...</td>\n",
       "      <td>[10, 2, 1, 0, 3, 8, 4, 6, 9, 7, 5]</td>\n",
       "      <td>[0.0076303561218082905, 0.018063386902213097, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[IN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>any</td>\n",
       "      <td>0</td>\n",
       "      <td>[( from, 0.0012157938908785582), ( references,...</td>\n",
       "      <td>[11, 10, 6, 9, 1, 4, 3, 7, 5, 2, 8, 0]</td>\n",
       "      <td>[0.0012157938908785582, 0.006352233234792948, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[DT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>App</td>\n",
       "      <td>0</td>\n",
       "      <td>[( any, 1.228584187629167e-05), ( Entry, 9.995...</td>\n",
       "      <td>[12, 8, 11, 9, 10, 2, 4, 5, 1, 6, 0, 7, 3]</td>\n",
       "      <td>[1.228584187629167e-05, 9.995483560487628e-05,...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Session</td>\n",
       "      <td>0</td>\n",
       "      <td>[( App, 0.0023875413462519646), (\"\"\", 0.007649...</td>\n",
       "      <td>[13, 0, 4, 7, 6, 5, 2, 3, 8, 12, 10, 9, 11, 1]</td>\n",
       "      <td>[0.0023875413462519646, 0.007649701088666916, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>[(Session, 0.04484212026000023), ( any, 0.2264...</td>\n",
       "      <td>[14, 12]</td>\n",
       "      <td>[0.04484212026000023, 0.22649894654750824]</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>[(., 0.003560348879545927), ( references, 0.24...</td>\n",
       "      <td>[15, 10]</td>\n",
       "      <td>[0.003560348879545927, 0.2461317777633667]</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>If</td>\n",
       "      <td>0</td>\n",
       "      <td>[(\\n, 0.0001329023070866242), (\"\"\", 0.00129347...</td>\n",
       "      <td>[16, 0, 5, 15, 1, 12, 4, 7, 14, 9, 10, 8, 2, 6...</td>\n",
       "      <td>[0.0001329023070866242, 0.0012934700353071094,...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[IN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>not</td>\n",
       "      <td>0</td>\n",
       "      <td>[(If, 0.026244867593050003), ( references, 0.0...</td>\n",
       "      <td>[17, 10, 16]</td>\n",
       "      <td>[0.026244867593050003, 0.08787801861763, 0.286...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[RB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>[( not, 0.0022070561535656452), ( any, 0.03812...</td>\n",
       "      <td>[18, 12, 16, 15]</td>\n",
       "      <td>[0.0022070561535656452, 0.038121215999126434, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>[(,, 0.0007169864838942885), ( that, 0.0126597...</td>\n",
       "      <td>[19, 4, 18]</td>\n",
       "      <td>[0.0007169864838942885, 0.012659711763262749, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[PRP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>can</td>\n",
       "      <td>0</td>\n",
       "      <td>[( it, 0.021687164902687073), (Session, 0.0309...</td>\n",
       "      <td>[20, 14, 4, 12, 13, 7, 19, 16, 0, 2, 1]</td>\n",
       "      <td>[0.021687164902687073, 0.030921876430511475, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[MD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>be</td>\n",
       "      <td>0</td>\n",
       "      <td>[( can, 0.10756052285432816), ( references, 0....</td>\n",
       "      <td>[21, 10]</td>\n",
       "      <td>[0.10756052285432816, 0.42234644293785095]</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[VB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>removed</td>\n",
       "      <td>0</td>\n",
       "      <td>[( be, 0.003323380136862397), (Generate, 0.011...</td>\n",
       "      <td>[22, 1, 3, 7, 9, 21, 18, 19, 11, 15]</td>\n",
       "      <td>[0.003323380136862397, 0.011594302952289581, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[VBN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>from</td>\n",
       "      <td>0</td>\n",
       "      <td>[( removed, 0.009416701272130013), ( from, 0.1...</td>\n",
       "      <td>[23, 11]</td>\n",
       "      <td>[0.009416701272130013, 0.15168987214565277]</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[IN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "      <td>[( from, 0.013912602327764034), ( references, ...</td>\n",
       "      <td>[24, 10]</td>\n",
       "      <td>[0.013912602327764034, 0.29584693908691406]</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[DT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>cache</td>\n",
       "      <td>0</td>\n",
       "      <td>[( the, 0.0010061485227197409), ( from, 0.0019...</td>\n",
       "      <td>[25, 24, 23, 6, 20, 19, 9, 18, 5, 15, 12, 13, ...</td>\n",
       "      <td>[0.0010061485227197409, 0.0019283527508378029,...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>[( cache, 0.18263539671897888)]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[0.18263539671897888]</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>and</td>\n",
       "      <td>0</td>\n",
       "      <td>[(., 7.751554949209094e-05), (If, 0.0001006276...</td>\n",
       "      <td>[27, 17, 15, 14, 1, 7, 19, 2, 12, 6, 4, 3, 9, ...</td>\n",
       "      <td>[7.751554949209094e-05, 0.00010062762885354459...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>signature</td>\n",
       "      <td>0</td>\n",
       "      <td>[(and, 4.114783223485574e-06), ( the, 2.207060...</td>\n",
       "      <td>[28, 25, 3, 14, 26, 0, 1, 15, 19, 5, 7, 16, 6,...</td>\n",
       "      <td>[4.114783223485574e-06, 2.207060060754884e-05,...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>is</td>\n",
       "      <td>0</td>\n",
       "      <td>[( signature, 0.02085556462407112), (If, 0.085...</td>\n",
       "      <td>[29, 17, 16]</td>\n",
       "      <td>[0.02085556462407112, 0.08597404509782791, 0.2...</td>\n",
       "      <td>0</td>\n",
       "      <td>nl</td>\n",
       "      <td>None</td>\n",
       "      <td>[VBZ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>\"\"\"</td>\n",
       "      <td>0</td>\n",
       "      <td>[( is, 2.0915353161399253e-05), (\"\"\", 0.000297...</td>\n",
       "      <td>[30, 0, 1, 12, 20, 3, 4, 7, 25, 2, 8, 9, 21, 1...</td>\n",
       "      <td>[2.0915353161399253e-05, 0.0002972942020278424...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(3, 6)</td>\n",
       "      <td>[module]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[(\"\"\", 0.002029548864811659), ( is, 0.00408967...</td>\n",
       "      <td>[31, 30, 22, 14, 24, 15, 27, 28, 8, 17, 10, 4,...</td>\n",
       "      <td>[0.002029548864811659, 0.004089676775038242, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(6, 7)</td>\n",
       "      <td>[module, function_definition, def]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>[( , 0.0543963760137558), (\"\"\", 0.283918172121...</td>\n",
       "      <td>[32, 31]</td>\n",
       "      <td>[0.0543963760137558, 0.283918172121048]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(7, 8)</td>\n",
       "      <td>[module, function_definition, def]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>def</td>\n",
       "      <td>0</td>\n",
       "      <td>[(\\n, 0.056899163872003555), ( removed, 0.0782...</td>\n",
       "      <td>[33, 23, 6, 5]</td>\n",
       "      <td>[0.056899163872003555, 0.07828091084957123, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(8, 11)</td>\n",
       "      <td>[module, function_definition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>has</td>\n",
       "      <td>0</td>\n",
       "      <td>[(def, 0.0019971844740211964), ( has, 0.010028...</td>\n",
       "      <td>[34, 9, 5, 2, 10, 29, 24, 12, 31, 0, 30, 17, 28]</td>\n",
       "      <td>[0.0019971844740211964, 0.010028641670942307, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(11, 15)</td>\n",
       "      <td>[module, function_definition, identifier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[( has, 0.2394620031118393)]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[0.2394620031118393]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(15, 16)</td>\n",
       "      <td>[module, function_definition, identifier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>refs</td>\n",
       "      <td>0</td>\n",
       "      <td>[(_, 6.298462540144101e-05), ( references, 0.0...</td>\n",
       "      <td>[36, 10, 6, 1, 12, 23]</td>\n",
       "      <td>[6.298462540144101e-05, 0.0014978453982621431,...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(16, 20)</td>\n",
       "      <td>[module, function_definition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>(</td>\n",
       "      <td>0</td>\n",
       "      <td>[(refs, 0.04023171588778496), (def, 0.24068835...</td>\n",
       "      <td>[37, 34]</td>\n",
       "      <td>[0.04023171588778496, 0.24068835377693176]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(20, 21)</td>\n",
       "      <td>[module, function_definition, parameters, iden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>self</td>\n",
       "      <td>0</td>\n",
       "      <td>[((, 0.1287144422531128)]</td>\n",
       "      <td>[38]</td>\n",
       "      <td>[0.1287144422531128]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(21, 25)</td>\n",
       "      <td>[module, function_definition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>)</td>\n",
       "      <td>0</td>\n",
       "      <td>[(self, 0.023757247254252434), ( Python, 0.065...</td>\n",
       "      <td>[39, 2, 29, 21, 27, 0, 32, 38, 6, 26, 25]</td>\n",
       "      <td>[0.023757247254252434, 0.06570661813020706, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(25, 26)</td>\n",
       "      <td>[module, function_definition, -&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index   goal_token  from_seq_id  \\\n",
       "0       0     Generate            0   \n",
       "1       1       Python            0   \n",
       "2       2         code            0   \n",
       "3       3         that            0   \n",
       "4       4         True            0   \n",
       "5       5           if            0   \n",
       "6       6         this            0   \n",
       "7       7        Entry            0   \n",
       "8       8          has            0   \n",
       "9       9   references            0   \n",
       "10     10         from            0   \n",
       "11     11          any            0   \n",
       "12     12          App            0   \n",
       "13     13      Session            0   \n",
       "14     14            .            0   \n",
       "15     15           \\n            0   \n",
       "16     16           If            0   \n",
       "17     17          not            0   \n",
       "18     18            ,            0   \n",
       "19     19           it            0   \n",
       "20     20          can            0   \n",
       "21     21           be            0   \n",
       "22     22      removed            0   \n",
       "23     23         from            0   \n",
       "24     24          the            0   \n",
       "25     25        cache            0   \n",
       "26     26            .            0   \n",
       "27     27          and            0   \n",
       "28     28    signature            0   \n",
       "29     29           is            0   \n",
       "30     30          \"\"\"            0   \n",
       "31     31                         0   \n",
       "32     32           \\n            0   \n",
       "33     33          def            0   \n",
       "34     34          has            0   \n",
       "35     35            _            0   \n",
       "36     36         refs            0   \n",
       "37     37            (            0   \n",
       "38     38         self            0   \n",
       "39     39            )            0   \n",
       "\n",
       "                                         typesets_tgt  \\\n",
       "0                     [(\"\"\", 0.00021326643764041364)]   \n",
       "1   [(Generate, 0.0006065950146876276), (\"\"\", 0.00...   \n",
       "2   [( Python, 0.00798844825476408), (\"\"\", 0.02216...   \n",
       "3   [( code, 0.0016746035544201732), (\"\"\", 0.02259...   \n",
       "4   [( that, 0.0001442114298697561), (\"\"\", 0.00013...   \n",
       "5   [( True, 0.009045373648405075), (\"\"\", 0.403910...   \n",
       "6   [( if, 0.0024248436093330383), ( that, 0.02887...   \n",
       "7   [( this, 4.844649993174244e-06), (\"\"\", 1.79923...   \n",
       "8   [( Entry, 0.00033161439932882786), ( this, 0.0...   \n",
       "9   [( has, 2.149678584828507e-05), ( this, 9.9156...   \n",
       "10  [( references, 0.0076303561218082905), ( Pytho...   \n",
       "11  [( from, 0.0012157938908785582), ( references,...   \n",
       "12  [( any, 1.228584187629167e-05), ( Entry, 9.995...   \n",
       "13  [( App, 0.0023875413462519646), (\"\"\", 0.007649...   \n",
       "14  [(Session, 0.04484212026000023), ( any, 0.2264...   \n",
       "15  [(., 0.003560348879545927), ( references, 0.24...   \n",
       "16  [(\\n, 0.0001329023070866242), (\"\"\", 0.00129347...   \n",
       "17  [(If, 0.026244867593050003), ( references, 0.0...   \n",
       "18  [( not, 0.0022070561535656452), ( any, 0.03812...   \n",
       "19  [(,, 0.0007169864838942885), ( that, 0.0126597...   \n",
       "20  [( it, 0.021687164902687073), (Session, 0.0309...   \n",
       "21  [( can, 0.10756052285432816), ( references, 0....   \n",
       "22  [( be, 0.003323380136862397), (Generate, 0.011...   \n",
       "23  [( removed, 0.009416701272130013), ( from, 0.1...   \n",
       "24  [( from, 0.013912602327764034), ( references, ...   \n",
       "25  [( the, 0.0010061485227197409), ( from, 0.0019...   \n",
       "26                    [( cache, 0.18263539671897888)]   \n",
       "27  [(., 7.751554949209094e-05), (If, 0.0001006276...   \n",
       "28  [(and, 4.114783223485574e-06), ( the, 2.207060...   \n",
       "29  [( signature, 0.02085556462407112), (If, 0.085...   \n",
       "30  [( is, 2.0915353161399253e-05), (\"\"\", 0.000297...   \n",
       "31  [(\"\"\", 0.002029548864811659), ( is, 0.00408967...   \n",
       "32  [( , 0.0543963760137558), (\"\"\", 0.283918172121...   \n",
       "33  [(\\n, 0.056899163872003555), ( removed, 0.0782...   \n",
       "34  [(def, 0.0019971844740211964), ( has, 0.010028...   \n",
       "35                       [( has, 0.2394620031118393)]   \n",
       "36  [(_, 6.298462540144101e-05), ( references, 0.0...   \n",
       "37  [(refs, 0.04023171588778496), (def, 0.24068835...   \n",
       "38                          [((, 0.1287144422531128)]   \n",
       "39  [(self, 0.023757247254252434), ( Python, 0.065...   \n",
       "\n",
       "                                    rationale_pos_tgt  \\\n",
       "0                                                 [0]   \n",
       "1                                              [1, 0]   \n",
       "2                                           [2, 0, 1]   \n",
       "3                                        [3, 0, 1, 2]   \n",
       "4                                     [4, 0, 1, 2, 3]   \n",
       "5                                              [5, 0]   \n",
       "6                               [6, 4, 5, 0, 1, 3, 2]   \n",
       "7                            [7, 0, 1, 5, 6, 4, 2, 3]   \n",
       "8                         [8, 7, 6, 0, 5, 3, 1, 4, 2]   \n",
       "9                      [9, 7, 8, 3, 6, 2, 1, 0, 4, 5]   \n",
       "10                 [10, 2, 1, 0, 3, 8, 4, 6, 9, 7, 5]   \n",
       "11             [11, 10, 6, 9, 1, 4, 3, 7, 5, 2, 8, 0]   \n",
       "12         [12, 8, 11, 9, 10, 2, 4, 5, 1, 6, 0, 7, 3]   \n",
       "13     [13, 0, 4, 7, 6, 5, 2, 3, 8, 12, 10, 9, 11, 1]   \n",
       "14                                           [14, 12]   \n",
       "15                                           [15, 10]   \n",
       "16  [16, 0, 5, 15, 1, 12, 4, 7, 14, 9, 10, 8, 2, 6...   \n",
       "17                                       [17, 10, 16]   \n",
       "18                                   [18, 12, 16, 15]   \n",
       "19                                        [19, 4, 18]   \n",
       "20            [20, 14, 4, 12, 13, 7, 19, 16, 0, 2, 1]   \n",
       "21                                           [21, 10]   \n",
       "22               [22, 1, 3, 7, 9, 21, 18, 19, 11, 15]   \n",
       "23                                           [23, 11]   \n",
       "24                                           [24, 10]   \n",
       "25  [25, 24, 23, 6, 20, 19, 9, 18, 5, 15, 12, 13, ...   \n",
       "26                                               [26]   \n",
       "27  [27, 17, 15, 14, 1, 7, 19, 2, 12, 6, 4, 3, 9, ...   \n",
       "28  [28, 25, 3, 14, 26, 0, 1, 15, 19, 5, 7, 16, 6,...   \n",
       "29                                       [29, 17, 16]   \n",
       "30  [30, 0, 1, 12, 20, 3, 4, 7, 25, 2, 8, 9, 21, 1...   \n",
       "31  [31, 30, 22, 14, 24, 15, 27, 28, 8, 17, 10, 4,...   \n",
       "32                                           [32, 31]   \n",
       "33                                     [33, 23, 6, 5]   \n",
       "34   [34, 9, 5, 2, 10, 29, 24, 12, 31, 0, 30, 17, 28]   \n",
       "35                                               [35]   \n",
       "36                             [36, 10, 6, 1, 12, 23]   \n",
       "37                                           [37, 34]   \n",
       "38                                               [38]   \n",
       "39          [39, 2, 29, 21, 27, 0, 32, 38, 6, 26, 25]   \n",
       "\n",
       "                                   rationale_prob_tgt  exp token_type  \\\n",
       "0                            [0.00021326643764041364]    0         nl   \n",
       "1      [0.0006065950146876276, 0.0015060030855238438]    0         nl   \n",
       "2   [0.00798844825476408, 0.022162150591611862, 0....    0         nl   \n",
       "3   [0.0016746035544201732, 0.022595535963773727, ...    0         nl   \n",
       "4   [0.0001442114298697561, 0.00013347486674319953...    0         nl   \n",
       "5          [0.009045373648405075, 0.4039102792739868]    0         nl   \n",
       "6   [0.0024248436093330383, 0.028876375406980515, ...    0         nl   \n",
       "7   [4.844649993174244e-06, 1.79923081304878e-05, ...    0         nl   \n",
       "8   [0.00033161439932882786, 0.010388635098934174,...    0         nl   \n",
       "9   [2.149678584828507e-05, 9.915613190969452e-05,...    0         nl   \n",
       "10  [0.0076303561218082905, 0.018063386902213097, ...    0         nl   \n",
       "11  [0.0012157938908785582, 0.006352233234792948, ...    0         nl   \n",
       "12  [1.228584187629167e-05, 9.995483560487628e-05,...    0         nl   \n",
       "13  [0.0023875413462519646, 0.007649701088666916, ...    0         nl   \n",
       "14         [0.04484212026000023, 0.22649894654750824]    0         nl   \n",
       "15         [0.003560348879545927, 0.2461317777633667]    0         nl   \n",
       "16  [0.0001329023070866242, 0.0012934700353071094,...    0         nl   \n",
       "17  [0.026244867593050003, 0.08787801861763, 0.286...    0         nl   \n",
       "18  [0.0022070561535656452, 0.038121215999126434, ...    0         nl   \n",
       "19  [0.0007169864838942885, 0.012659711763262749, ...    0         nl   \n",
       "20  [0.021687164902687073, 0.030921876430511475, 0...    0         nl   \n",
       "21         [0.10756052285432816, 0.42234644293785095]    0         nl   \n",
       "22  [0.003323380136862397, 0.011594302952289581, 0...    0         nl   \n",
       "23        [0.009416701272130013, 0.15168987214565277]    0         nl   \n",
       "24        [0.013912602327764034, 0.29584693908691406]    0         nl   \n",
       "25  [0.0010061485227197409, 0.0019283527508378029,...    0         nl   \n",
       "26                              [0.18263539671897888]    0         nl   \n",
       "27  [7.751554949209094e-05, 0.00010062762885354459...    0         nl   \n",
       "28  [4.114783223485574e-06, 2.207060060754884e-05,...    0         nl   \n",
       "29  [0.02085556462407112, 0.08597404509782791, 0.2...    0         nl   \n",
       "30  [2.0915353161399253e-05, 0.0002972942020278424...    0        src   \n",
       "31  [0.002029548864811659, 0.004089676775038242, 0...    0        src   \n",
       "32            [0.0543963760137558, 0.283918172121048]    0        src   \n",
       "33  [0.056899163872003555, 0.07828091084957123, 0....    0        src   \n",
       "34  [0.0019971844740211964, 0.010028641670942307, ...    0        src   \n",
       "35                               [0.2394620031118393]    0        src   \n",
       "36  [6.298462540144101e-05, 0.0014978453982621431,...    0        src   \n",
       "37         [0.04023171588778496, 0.24068835377693176]    0        src   \n",
       "38                               [0.1287144422531128]    0        src   \n",
       "39  [0.023757247254252434, 0.06570661813020706, 0....    0        src   \n",
       "\n",
       "        span                                               tags  \n",
       "0       None                                              [NNP]  \n",
       "1       None                                              [NNP]  \n",
       "2       None                                               [NN]  \n",
       "3       None                                               [IN]  \n",
       "4       None                                              [NNP]  \n",
       "5       None                                               [IN]  \n",
       "6       None                                              [VBZ]  \n",
       "7       None                                               [NN]  \n",
       "8       None                                              [VBZ]  \n",
       "9       None                                              [NNS]  \n",
       "10      None                                               [IN]  \n",
       "11      None                                               [DT]  \n",
       "12      None                                                 []  \n",
       "13      None                                                 []  \n",
       "14      None                                                [.]  \n",
       "15      None                                                 []  \n",
       "16      None                                               [IN]  \n",
       "17      None                                               [RB]  \n",
       "18      None                                                [,]  \n",
       "19      None                                              [PRP]  \n",
       "20      None                                               [MD]  \n",
       "21      None                                               [VB]  \n",
       "22      None                                              [VBN]  \n",
       "23      None                                               [IN]  \n",
       "24      None                                               [DT]  \n",
       "25      None                                                 []  \n",
       "26      None                                                [.]  \n",
       "27      None                                                 []  \n",
       "28      None                                               [NN]  \n",
       "29      None                                              [VBZ]  \n",
       "30    (3, 6)                                           [module]  \n",
       "31    (6, 7)                 [module, function_definition, def]  \n",
       "32    (7, 8)                 [module, function_definition, def]  \n",
       "33   (8, 11)                      [module, function_definition]  \n",
       "34  (11, 15)          [module, function_definition, identifier]  \n",
       "35  (15, 16)          [module, function_definition, identifier]  \n",
       "36  (16, 20)                      [module, function_definition]  \n",
       "37  (20, 21)  [module, function_definition, parameters, iden...  \n",
       "38  (21, 25)                      [module, function_definition]  \n",
       "39  (25, 26)                  [module, function_definition, ->]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_results[0][0].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Aggregrating rationals for exp: 0**********\n"
     ]
    }
   ],
   "source": [
    "###AGGREGATE RATIONALS - AST\n",
    "local_ast_aggregated_results = aggregate_rationals(tagged_results, node_types, pos_types, len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "###AGGREGATE RATIONALS - TAXONOMY\n",
    "taxonomy = {**pl_taxonomy_python(), **nl_pos_taxonomy()}\n",
    "local_taxonomy_aggregated_results = map_local_results_to_taxonomy(taxonomy, local_ast_aggregated_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize - AST Aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1[Generate]', '2[ Python]', '3[ code]', '4[ that]', '5[ True]', '6[ if]', '7[ this]', '8[ Entry]', '9[ has]', '10[ references]', '11[ from]', '12[ any]', '13[ App]', '14[Session]', '15[.]', '16[\\n]', '17[If]', '18[ not]', '19[,]', '20[ it]', '21[ can]', '22[ be]', '23[ removed]', '24[ from]', '25[ the]', '26[ cache]', '27[.]', '28[and]', '29[ signature]', '30[ is]', '31[\"\"\"]', '32[ ]', '33[\\n]', '34[def]', '35[ has]', '36[_]', '37[refs]', '38[(]', '39[self]', '40[)]', '41[ ->]', '42[ bool]', '43[:]', '44[\\n   ]', '45[ self]', '46[.]', '47[ref]', '48[,]', '49[ self]', '50[.]', '51[context]', '52[ =]', '53[ None]', '54[\\n]', '55[else]', '56[:]', '57[\\n   ]', '58[ try]', '59[:]', '60[\\n   ]', '61[ from]', '62[ r]', '63[ust]', '64[y]', '65[.]', '66[api]', '67[.]', '68[py]', '69[\\n]', '70[self]', '71[.]', '72[log]', '73[_]', '74[on]', '75[_]', '76[error]', '77[ =]', '78[ False]', '79[\\n]'])\n",
      "dict_keys(['attribute', 'identifier', 'module', 'function_definition', 'assignment', 'pattern_list', 'block', 'expression_statement', 'IN', 'NNP'])\n",
      "['16[If]']\n"
     ]
    }
   ],
   "source": [
    "#local_ast_aggregated_results[<sample_id>][<pos[token]>] -> aggregated rationales\n",
    "print(local_ast_aggregated_results[0].keys()) #target tokens\n",
    "print(local_ast_aggregated_results[0]['55[else]'].keys()) #rationales\n",
    "print(local_ast_aggregated_results[0]['55[else]']['IN']['rationales']) #rationales values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize - Taxonomy Aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1[Generate]', '2[ Python]', '3[ code]', '4[ that]', '5[ True]', '6[ if]', '7[ this]', '8[ Entry]', '9[ has]', '10[ references]', '11[ from]', '12[ any]', '13[ App]', '14[Session]', '15[.]', '16[\\n]', '17[If]', '18[ not]', '19[,]', '20[ it]', '21[ can]', '22[ be]', '23[ removed]', '24[ from]', '25[ the]', '26[ cache]', '27[.]', '28[and]', '29[ signature]', '30[ is]', '31[\"\"\"]', '32[ ]', '33[\\n]', '34[def]', '35[ has]', '36[_]', '37[refs]', '38[(]', '39[self]', '40[)]', '41[ ->]', '42[ bool]', '43[:]', '44[\\n   ]', '45[ self]', '46[.]', '47[ref]', '48[,]', '49[ self]', '50[.]', '51[context]', '52[ =]', '53[ None]', '54[\\n]', '55[else]', '56[:]', '57[\\n   ]', '58[ try]', '59[:]', '60[\\n   ]', '61[ from]', '62[ r]', '63[ust]', '64[y]', '65[.]', '66[api]', '67[.]', '68[py]', '69[\\n]', '70[self]', '71[.]', '72[log]', '73[_]', '74[on]', '75[_]', '76[error]', '77[ =]', '78[ False]', '79[\\n]'])\n",
      "dict_keys(['structural', 'statements', 'identifier', 'unknown', 'nl_noun', 'nl_preposition'])\n",
      "[['1[ Python]']]\n"
     ]
    }
   ],
   "source": [
    "#local_ast_aggregated_results[<sample_id>][<pos[token]>] -> aggregated rationales\n",
    "print(local_taxonomy_aggregated_results[0].keys()) #target tokens\n",
    "print(local_taxonomy_aggregated_results[0]['55[else]'].keys()) #rationales\n",
    "print(local_taxonomy_aggregated_results[0]['55[else]']['nl_noun']['rationales']) #rationales values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
