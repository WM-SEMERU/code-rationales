{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Empirical netbook to sample bart for method2test benchmark.\n",
    "output-file: bart_sampling_.html\n",
    "title: Large Scale Encoder-Decoder (BART) Sampling\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import torch\n",
    "import importlib\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename=\"../datax/logs/logger_bart_sampling.txt\",\n",
    "    filemode='a',\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "    level=logging.INFO\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_default():\n",
    "    corpus = 'fm' # 'fm_fc_ms_ff' #<-- Scope\n",
    "    data_path = Path('/workspaces/code-rationales/semeru-datasets/athena_test/' + corpus + '/')\n",
    "    data_path_raw = Path(data_path/ 'raw')\n",
    "    return {\n",
    "        'bpe_path' : '/workspaces/code-rationales/scripts/tokenizer/universal_tokenizer/roberta_aug_spaces',\n",
    "        'eval_raw': [data_path_raw / 'eval/input.methods.txt',\n",
    "                        data_path_raw / 'eval/output.tests.txt'],\n",
    "        'test_raw': [data_path_raw / 'test/input.methods.txt', \n",
    "                        data_path_raw / 'test/output.tests.txt'],\n",
    "        'train_raw': [data_path_raw / 'train/input.methods.txt', \n",
    "                        data_path_raw / 'train/output.tests.txt'],\n",
    "        'data_labels' : ['test_raw'],#['eval_raw','test_raw','train_raw'], <----- Just Test\n",
    "        'super_data_checkpoint' : data_path / 'pandas',\n",
    "        'out_processed' : '/datasets/out_processed/',\n",
    "        'model_name_or_path' : '/workspaces/code-rationales/data/bart-fairseq/checkpoint_dir_athena_ms/models/', #Model Path\n",
    "        'checkpoint_file': 'checkpoint_best.pt', #Model\n",
    "        'output_sample' : '/workspaces/code-rationales/data/sampling/bart/',\n",
    "        'corpus': corpus\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint_best.pt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = param_default()\n",
    "params['checkpoint_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/workspaces/code-rationales/semeru-datasets/athena_test/fm/raw/test/input.methods.txt'),\n",
       " PosixPath('/workspaces/code-rationales/semeru-datasets/athena_test/fm/raw/test/output.tests.txt')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['test_raw']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(bpe_path):\n",
    "    return ByteLevelBPETokenizer(str(bpe_path)+'-vocab.json',str(bpe_path)+'-merges.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazy_decode(bpe_java):\n",
    "    return bpe_java.replace(' ','').replace('Ġ',' ').replace('Ċ','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = param_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_java(minified_java):\n",
    "    \"tries to undo Michele's minification. Works decently, although for loops and sets get newlines inserted, and there are no empty lines or comments\"\n",
    "    minified_java = minified_java.replace('{','{\\n').replace('}','}\\n').replace(';',';\\n')\n",
    "    num_indents = 0\n",
    "    pretty_java = ''\n",
    "    for line in minified_java.splitlines():\n",
    "        if line.lstrip().startswith('}'):\n",
    "            num_indents -= 1\n",
    "        pretty_java += num_indents*'    '+line+'\\n'\n",
    "        if line.endswith('{'):\n",
    "            num_indents += 1\n",
    "        if line.endswith('}') and not line.lstrip().startswith('}'):\n",
    "            num_indents -= 1\n",
    "    return pretty_java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/code-rationales/scripts/tokenizer/universal_tokenizer/roberta_aug_spaces'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['bpe_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer(params['bpe_path'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_size_vector( method_vector ):\n",
    "    '''Return the size of the tokens for a give method based on id\n",
    "        Assuming that method_vector is an array of tokens\n",
    "    '''\n",
    "    input_ids = [ len(mtd) for mtd in method_vector ]\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Set Code Preprocessess configured datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_set_code():\n",
    "    df = pd.DataFrame()\n",
    "    for label in params['data_labels']:\n",
    "        for val, path_data in enumerate( params[ label ] ):\n",
    "            new_label= re.split('\\.|\\/',str(path_data))[-3]\n",
    "            df = pd.concat([df, pd.read_csv( path_data, sep=\"\\0\", header=None, names=[new_label])], axis=1) #reading file\n",
    "            df[new_label+'_bpe'] = [ enc.tokens for enc in tokenizer.encode_batch( df[new_label].values ) ] #bpe\n",
    "            df[new_label+'_method_size'] = method_size_vector( df[new_label+'_bpe'].values ) #counting tokens\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data = super_set_code() #[WARNING] Use it when not computed! Otherwise use Loading Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>input_bpe</th>\n",
       "      <th>input_method_size</th>\n",
       "      <th>output</th>\n",
       "      <th>output_bpe</th>\n",
       "      <th>output_method_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public static Date yearStart() { final Gregori...</td>\n",
       "      <td>[public, Ġstatic, ĠDate, Ġyear, Start, (), Ġ{,...</td>\n",
       "      <td>42</td>\n",
       "      <td>@Test public void yearStart() { Date date = Da...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġyear, Start, (), Ġ{...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>public static Date yearEnd() { final Gregorian...</td>\n",
       "      <td>[public, Ġstatic, ĠDate, Ġyear, End, (), Ġ{, Ġ...</td>\n",
       "      <td>65</td>\n",
       "      <td>@Test public void yearEnd() { Date date = Date...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġyear, End, (), Ġ{, ...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public void validate(TokenBinding clientDataTo...</td>\n",
       "      <td>[public, Ġvoid, Ġvalidate, (, Token, B, inding...</td>\n",
       "      <td>170</td>\n",
       "      <td>@Test void validate_invalid_bindingId_test() {...</td>\n",
       "      <td>[@, Test, Ġvoid, Ġvalidate, _, in, valid, _, b...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>public static int getUnsignedShort(ByteBuffer ...</td>\n",
       "      <td>[public, Ġstatic, Ġint, Ġget, Un, signed, Shor...</td>\n",
       "      <td>29</td>\n",
       "      <td>@Test void getUnsignedShort_test1() { byte[] b...</td>\n",
       "      <td>[@, Test, Ġvoid, Ġget, Un, signed, Short, _, t...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public static boolean isWithinUnsignedLong(Big...</td>\n",
       "      <td>[public, Ġstatic, Ġboolean, Ġis, Within, Un, s...</td>\n",
       "      <td>41</td>\n",
       "      <td>@Test void isWithinUnsignedLong_test() { asser...</td>\n",
       "      <td>[@, Test, Ġvoid, Ġis, Within, Un, signed, Long...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  public static Date yearStart() { final Gregori...   \n",
       "1  public static Date yearEnd() { final Gregorian...   \n",
       "2  public void validate(TokenBinding clientDataTo...   \n",
       "3  public static int getUnsignedShort(ByteBuffer ...   \n",
       "4  public static boolean isWithinUnsignedLong(Big...   \n",
       "\n",
       "                                           input_bpe  input_method_size  \\\n",
       "0  [public, Ġstatic, ĠDate, Ġyear, Start, (), Ġ{,...                 42   \n",
       "1  [public, Ġstatic, ĠDate, Ġyear, End, (), Ġ{, Ġ...                 65   \n",
       "2  [public, Ġvoid, Ġvalidate, (, Token, B, inding...                170   \n",
       "3  [public, Ġstatic, Ġint, Ġget, Un, signed, Shor...                 29   \n",
       "4  [public, Ġstatic, Ġboolean, Ġis, Within, Un, s...                 41   \n",
       "\n",
       "                                              output  \\\n",
       "0  @Test public void yearStart() { Date date = Da...   \n",
       "1  @Test public void yearEnd() { Date date = Date...   \n",
       "2  @Test void validate_invalid_bindingId_test() {...   \n",
       "3  @Test void getUnsignedShort_test1() { byte[] b...   \n",
       "4  @Test void isWithinUnsignedLong_test() { asser...   \n",
       "\n",
       "                                          output_bpe  output_method_size  \n",
       "0  [@, Test, Ġpublic, Ġvoid, Ġyear, Start, (), Ġ{...                  61  \n",
       "1  [@, Test, Ġpublic, Ġvoid, Ġyear, End, (), Ġ{, ...                  74  \n",
       "2  [@, Test, Ġvoid, Ġvalidate, _, in, valid, _, b...                 110  \n",
       "3  [@, Test, Ġvoid, Ġget, Un, signed, Short, _, t...                  73  \n",
       "4  [@, Test, Ġvoid, Ġis, Within, Un, signed, Long...                 145  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving each dataset from super_data as checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data.to_parquet(params['super_data_checkpoint'] / 'test_data_input_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Super Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#super_data = pd.read_parquet(params['super_data_checkpoint'] / 'test_data_input_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Super Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   78388.000\n",
       "mean      162.572\n",
       "std       357.421\n",
       "min         4.000\n",
       "25%        38.000\n",
       "50%        80.000\n",
       "75%       173.000\n",
       "max      6016.000\n",
       "Name: input_method_size, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size Statistics of Source Set\n",
    "super_data.input_method_size.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 22:53:04 | INFO | fairseq.file_utils | loading archive file /workspaces/code-rationales/data/bart-fairseq/checkpoint_dir_athena_ms/models/\n",
      "2023-07-23 22:53:05 | INFO | fairseq.tasks.translation | [input.methods] dictionary: 50348 types\n",
      "2023-07-23 22:53:05 | INFO | fairseq.tasks.translation | [output.tests] dictionary: 50348 types\n",
      "2023-07-23 22:53:07 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': '/home/davidna/data/dummy/models/checkpoint_dir/tensorboard', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 2, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12398', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1024, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [8], 'lr': [4.2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/davidna/data/dummy/models/checkpoint_dir/models', 'restore_file': '/home/davidna/data/dummy/models/checkpoint_best_mod.pt.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': True, 'reset_meters': False, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='bart_large', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-06, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0.0, adaptive_softmax_factor=4, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='bart_large', attention_dropout=0.1, azureml_logging=False, base_layers=0, base_shuffle=1, base_sublayers=1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, char_inputs=False, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='cross_entropy', cross_self_attention=False, curriculum=0, data='/workspaces/code-rationales/data/bart-fairseq/checkpoint_dir_athena_ms/models', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, export=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=2, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[4.2e-05], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid='1024', max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_decoder_final_norm=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, profile=False, quant_noise_pq=0.0, quant_noise_pq_block_size=8, quant_noise_scalar=0.0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=True, reset_meters=False, reset_optimizer=True, restore_file='/home/davidna/data/dummy/models/checkpoint_best_mod.pt.pt', save_dir='/home/davidna/data/dummy/models/checkpoint_dir/models', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='input.methods', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='output.tests', task='translation', tensorboard_logdir='/home/davidna/data/dummy/models/checkpoint_dir/tensorboard', threshold_loss_scale=None, tie_adaptive_proj=False, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=10000, weight_decay=0.01, word_dropout_mixture=0.5, word_dropout_type='inverse_length', write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '/workspaces/code-rationales/data/bart-fairseq/checkpoint_dir_athena_ms/models', 'source_lang': 'input.methods', 'target_lang': 'output.tests', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': True, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [4.2e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': -1.0, 'lr': [4.2e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}\n"
     ]
    }
   ],
   "source": [
    "#Loading a pretrain model\n",
    "model = TransformerModel.from_pretrained(\n",
    "  model_name_or_path = params['model_name_or_path'],\n",
    "  checkpoint_file = params['checkpoint_file'],\n",
    "  #data_name_or_path = params['data_preprocessed']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratorHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): BARTModel(\n",
       "      (encoder): TransformerEncoderBase(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50348, 512, padding_idx=1)\n",
       "        (embed_positions): SinusoidalPositionalEmbedding()\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): TransformerDecoderBase(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50348, 512, padding_idx=1)\n",
       "        (embed_positions): SinusoidalPositionalEmbedding()\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (output_projection): Linear(in_features=512, out_features=50348, bias=False)\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Move model to GPU if available and trigger evaluation mode\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model = model.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   72928.000\n",
       "mean      104.267\n",
       "std        90.265\n",
       "min         4.000\n",
       "25%        36.000\n",
       "50%        73.000\n",
       "75%       145.000\n",
       "max       412.000\n",
       "Name: input_method_size, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SET_METHOD_SIZE = 412 #<---- HARDCODED comes from the mean of input method size\n",
    "super_data[super_data.input_method_size <= SET_METHOD_SIZE ].input_method_size.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joining_encode_tokens( arr_tokens, model ):\n",
    "    if len(arr_tokens) > SET_METHOD_SIZE:\n",
    "        arr_tokens = arr_tokens[0:SET_METHOD_SIZE]\n",
    "    focal_code = \" \".join(arr_tokens)\n",
    "    return model.encode( focal_code )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling without replacement\n",
    "#Testing size: 78388\n",
    "#Sampling size with 95% of confidence and 3% Error = 1053 ~ 1000\n",
    "def code_sampling(df_super_data ,  FLAG_SAMPLING = True, SIZE_SAMPLING = 1000, random_state = 3):\n",
    "    \n",
    "    df_sampled_code = super_data[super_data.input_method_size <= SET_METHOD_SIZE ].sample(\n",
    "            n = SIZE_SAMPLING,\n",
    "            replace = False,\n",
    "            random_state = random_state # For reproducibility\n",
    "    )\n",
    "\n",
    "    if FLAG_SAMPLING:\n",
    "        df_sampled_code['input_tokens'] = [ joining_encode_tokens(arr_sample, model=model) for arr_sample in df_sampled_code.input_bpe.values ]\n",
    "    else:\n",
    "        df_sampled_code['input_tokens_pos'] = [ joining_encode_tokens(arr_sample, model=model) for arr_sample in df_super_data.input_bpe.values]\n",
    "    return df_sampled_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled_code = code_sampling(\n",
    "    df_super_data = super_data,\n",
    "    SIZE_SAMPLING = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340     [tensor(15110), tensor(9527), tensor(41552), t...\n",
       "1242     [tensor(1039), tensor(10089), tensor(3850), te...\n",
       "36220    [tensor(15110), tensor(25156), tensor(28696), ...\n",
       "21814    [tensor(15110), tensor(2010), tensor(47613), t...\n",
       "8060     [tensor(37659), tensor(256), tensor(7511), ten...\n",
       "                               ...                        \n",
       "697      [tensor(15110), tensor(221), tensor(4628), ten...\n",
       "70739    [tensor(15110), tensor(25156), tensor(47893), ...\n",
       "158      [tensor(15110), tensor(25156), tensor(13842), ...\n",
       "33352    [tensor(1039), tensor(49116), tensor(285), ten...\n",
       "11193    [tensor(15110), tensor(25156), tensor(26602), ...\n",
       "Name: input_tokens, Length: 100, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled_code['input_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15110,  9527, 41552,   495, 26769,  6761, 15698,   120, 48720,   495,\n",
       "        26769, 14768,  1640,  6156, 26602, 20686, 31723,     6,   507, 26602,\n",
       "        20686, 47322,     6,   507, 49210,   455, 21109, 47779,     6,   507,\n",
       "        49210,  2365,     6,   507, 49210,   371, 38210,    43,  6989,   272,\n",
       "         8645,   293, 38644, 14086, 48847, 25522,   507, 33536,  3653,  5457,\n",
       "          120, 47952, 47006,   507,  6494, 47279,  5799,  5457,  3653,     4,\n",
       "        44814,  1640, 33806, 42703,   322, 22609,  1640, 45589, 41967,  5290,\n",
       "            4,  6460, 23295, 46460,   495, 26769, 14768,  1640, 48095, 31723,\n",
       "            6, 20686, 47322, 48749,   507, 33536, 47806,  1263,  5457,  5799,\n",
       "            4, 48360, 48348,  1640, 47576, 40104,     4,  3632, 23075,  1215,\n",
       "        10370, 11337,  3850,  1215, 14280,  2620,     6,    22, 29225,  8070,\n",
       "          479, 48360, 48348,  1640, 47576, 40104,     4,  3632, 23075,  1215,\n",
       "        35654,  2688,  1691,  1215, 14280,  2620,     6,    22, 29225,  8070,\n",
       "          479, 48360, 48348,  1640, 47576, 40104,     4,  3632, 23075,  1215,\n",
       "          500,  4154, 39007,  1215, 14280,  2620,     6,    22, 29225,  8070,\n",
       "          479, 48360, 48348,  1640, 47576, 40104,     4,  3632, 23075,  1215,\n",
       "          565,  4923,  1215, 14280,  2620,     6,    22, 29225,  8070,   479,\n",
       "        48360, 48348,  1640, 47576, 40104,     4, 40698,  2492,   104, 10002,\n",
       "         1215, 14280,  2620,     6,   455, 21109, 47779,     4,   560, 34222,\n",
       "        49338,   479, 48360, 48348,  1640, 47576, 40104,     4, 10237,  4581,\n",
       "         1215, 39075, 35473,  8625,  1215, 14280,  2620,     6,  2365,     4,\n",
       "          560, 34222, 49338,   479, 48360, 48348,  1640, 47576, 40104,     4,\n",
       "        10237,  4581,  1215,  3732,  5216, 41623,   975,  1215, 14280,  2620,\n",
       "            6,   371, 38210,     4,   560, 34222, 49338,   479, 35468,  1640,\n",
       "        18801, 40118,     4,   591, 44597,  6034,  1215, 49437,   322,  6460,\n",
       "         1640, 47952, 47806,     4,  4684,  4397,  3653,     4, 42742, 47006,\n",
       "          114,  1640, 47952, 47806,     4, 47731,     4,  9335,     4,  6460,\n",
       "        47731, 41555, 43048, 49333,  1263,     4,  6460, 47731, 43048, 48512,\n",
       "          507, 26602,  1579,  5457, 26602,     4, 34609,  1640,  5944,  3063,\n",
       "         1691,  1215,  6390,  1215, 18760,  1215, 45997, 39477,     6,    22,\n",
       "         6460, 20686, 22519, 46481, 20686, 31723,     6, 20686, 47322,  4397,\n",
       "          114,  1640, 45403,     4,   354, 30192, 48582, 49338, 25522, 34772,\n",
       "            4, 44223,  1640, 34222,     4, 34609,  1640, 49244,  1215, 40106,\n",
       "         3048,  1215,   565,  5330,  7205,  8625,  1215,  6222,   534,     6,\n",
       "         1579,     6,  1263,     4,  6460, 47731, 43048, 48749, 35524,  3211,\n",
       "           92,   272,  8645,   293, 38644, 14086, 48847,  1640, 44773,     6,\n",
       "         1263,     4,  6460, 47731, 49291, 35524,   671,  1263,     4,  6460,\n",
       "        49448,  1640,  4651, 43411, 40118, 41552, 36583, 41552,   495, 26769,\n",
       "         6761, 44226, 49215, 49440, 35524,     2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled_code.input_tokens.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>input_bpe</th>\n",
       "      <th>input_method_size</th>\n",
       "      <th>output</th>\n",
       "      <th>output_bpe</th>\n",
       "      <th>output_method_size</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>public List&lt;Dependency&gt; getModuleDependencies(...</td>\n",
       "      <td>[public, ĠList, &lt;, D, epend, ency, &gt;, Ġget, Mo...</td>\n",
       "      <td>385</td>\n",
       "      <td>@Test public void getModuleDependencies() thro...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġget, Module, D, epe...</td>\n",
       "      <td>274</td>\n",
       "      <td>[tensor(15110), tensor(9527), tensor(41552), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>@DELETE @Path(\"/{name}\") public Response delet...</td>\n",
       "      <td>[@, DE, LE, TE, Ġ@, Path, (\", /, {, name, }, \"...</td>\n",
       "      <td>120</td>\n",
       "      <td>@Test public void deleteAProductWithoutDeletio...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġdelete, AP, rodu, c...</td>\n",
       "      <td>179</td>\n",
       "      <td>[tensor(1039), tensor(10089), tensor(3850), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36220</th>\n",
       "      <td>public static &lt;T, U&gt; FlowableSubscriber&lt;T&gt; sub...</td>\n",
       "      <td>[public, Ġstatic, Ġ&lt;, T, ,, ĠU, &gt;, ĠFlow, able...</td>\n",
       "      <td>84</td>\n",
       "      <td>@Test public void testResultFunctionThrows() {...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġtest, Result, Funct...</td>\n",
       "      <td>214</td>\n",
       "      <td>[tensor(15110), tensor(25156), tensor(28696), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21814</th>\n",
       "      <td>public SecurityRoleFunctionEntity getSecurityR...</td>\n",
       "      <td>[public, ĠSecurity, Role, Function, Entity, Ġg...</td>\n",
       "      <td>128</td>\n",
       "      <td>@Test public void testGetSecurityRoleFunctionE...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġtest, Get, Security...</td>\n",
       "      <td>148</td>\n",
       "      <td>[tensor(15110), tensor(2010), tensor(47613), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>protected M loadByQuery(Bson query) { return l...</td>\n",
       "      <td>[protected, ĠM, Ġload, By, Query, (, B, son, Ġ...</td>\n",
       "      <td>21</td>\n",
       "      <td>@Test public void testLoadByQuery() throws Exc...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġtest, Load, By, Que...</td>\n",
       "      <td>130</td>\n",
       "      <td>[tensor(37659), tensor(256), tensor(7511), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input  \\\n",
       "1340   public List<Dependency> getModuleDependencies(...   \n",
       "1242   @DELETE @Path(\"/{name}\") public Response delet...   \n",
       "36220  public static <T, U> FlowableSubscriber<T> sub...   \n",
       "21814  public SecurityRoleFunctionEntity getSecurityR...   \n",
       "8060   protected M loadByQuery(Bson query) { return l...   \n",
       "\n",
       "                                               input_bpe  input_method_size  \\\n",
       "1340   [public, ĠList, <, D, epend, ency, >, Ġget, Mo...                385   \n",
       "1242   [@, DE, LE, TE, Ġ@, Path, (\", /, {, name, }, \"...                120   \n",
       "36220  [public, Ġstatic, Ġ<, T, ,, ĠU, >, ĠFlow, able...                 84   \n",
       "21814  [public, ĠSecurity, Role, Function, Entity, Ġg...                128   \n",
       "8060   [protected, ĠM, Ġload, By, Query, (, B, son, Ġ...                 21   \n",
       "\n",
       "                                                  output  \\\n",
       "1340   @Test public void getModuleDependencies() thro...   \n",
       "1242   @Test public void deleteAProductWithoutDeletio...   \n",
       "36220  @Test public void testResultFunctionThrows() {...   \n",
       "21814  @Test public void testGetSecurityRoleFunctionE...   \n",
       "8060   @Test public void testLoadByQuery() throws Exc...   \n",
       "\n",
       "                                              output_bpe  output_method_size  \\\n",
       "1340   [@, Test, Ġpublic, Ġvoid, Ġget, Module, D, epe...                 274   \n",
       "1242   [@, Test, Ġpublic, Ġvoid, Ġdelete, AP, rodu, c...                 179   \n",
       "36220  [@, Test, Ġpublic, Ġvoid, Ġtest, Result, Funct...                 214   \n",
       "21814  [@, Test, Ġpublic, Ġvoid, Ġtest, Get, Security...                 148   \n",
       "8060   [@, Test, Ġpublic, Ġvoid, Ġtest, Load, By, Que...                 130   \n",
       "\n",
       "                                            input_tokens  \n",
       "1340   [tensor(15110), tensor(9527), tensor(41552), t...  \n",
       "1242   [tensor(1039), tensor(10089), tensor(3850), te...  \n",
       "36220  [tensor(15110), tensor(25156), tensor(28696), ...  \n",
       "21814  [tensor(15110), tensor(2010), tensor(47613), t...  \n",
       "8060   [tensor(37659), tensor(256), tensor(7511), ten...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 30 #<---- Hardocoded\n",
    "MAX_GEN_TOK = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sample_generation(\n",
    "    df_sampled_code, \n",
    "    model, \n",
    "    n=1, \n",
    "    ):\n",
    "    generated_input = lambda input,model,n: model.generate( \n",
    "        input,\n",
    "        beam = n, \n",
    "        #maxlen = max_gen_tok, ##This parameter does not exists\n",
    "        #max_length = n, \n",
    "        do_sample = False, \n",
    "        pad_token_id = 50256 ) ## HARDCODED\n",
    "    arr_generated_code = np.array([ generated_input(input, model=model, n=n ) for input in df_sampled_code.input_tokens.values ]).T\n",
    "    \n",
    "    dict_generated_code = { i: [j['tokens'].cpu().data.numpy() for j in samples] for i,samples in enumerate(arr_generated_code) }\n",
    "    dict_generated_code['input_id'] = [ i.cpu().data.numpy() for i in df_sampled_code.input_tokens.values] \n",
    "    #return arr_generated_code\n",
    "    df_temp = pd.DataFrame().from_dict( data=dict_generated_code ) # DataFrame from Generation\n",
    "    df_temp = pd.concat([df_sampled_code.reset_index(), df_temp ], axis=1) #Index before concating\n",
    "    del df_temp['input_tokens']\n",
    "    #return pd.DataFrame().from_dict( data=dict_generated_code )\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO limit the number of tokens generated\n",
    "#WARNING TIME CONSUMING\n",
    "df_generated_input = df_sample_generation( \n",
    "    df_sampled_code = df_sampled_code, \n",
    "    model = model, \n",
    "    n = SAMPLES\n",
    "    )\n",
    "# [ sample_generation(input, model=model) for input in input_tokens[:2] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>input</th>\n",
       "      <th>input_bpe</th>\n",
       "      <th>input_method_size</th>\n",
       "      <th>output</th>\n",
       "      <th>output_bpe</th>\n",
       "      <th>output_method_size</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>input_is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340</td>\n",
       "      <td>public List&lt;Dependency&gt; getModuleDependencies(...</td>\n",
       "      <td>[public, ĠList, &lt;, D, epend, ency, &gt;, Ġget, Mo...</td>\n",
       "      <td>385</td>\n",
       "      <td>@Test public void getModuleDependencies() thro...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġget, Module, D, epe...</td>\n",
       "      <td>274</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 120, 48720, 495, 267...</td>\n",
       "      <td>[15110, 9527, 41552, 495, 26769, 6761, 15698, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1242</td>\n",
       "      <td>@DELETE @Path(\"/{name}\") public Response delet...</td>\n",
       "      <td>[@, DE, LE, TE, Ġ@, Path, (\", /, {, name, }, \"...</td>\n",
       "      <td>120</td>\n",
       "      <td>@Test public void deleteAProductWithoutDeletio...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġdelete, AP, rodu, c...</td>\n",
       "      <td>179</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 46006, 43048, ...</td>\n",
       "      <td>[1039, 10089, 3850, 6433, 787, 42119, 46469, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36220</td>\n",
       "      <td>public static &lt;T, U&gt; FlowableSubscriber&lt;T&gt; sub...</td>\n",
       "      <td>[public, Ġstatic, Ġ&lt;, T, ,, ĠU, &gt;, ĠFlow, able...</td>\n",
       "      <td>84</td>\n",
       "      <td>@Test public void testResultFunctionThrows() {...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġtest, Result, Funct...</td>\n",
       "      <td>214</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 6989, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 6989, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 11222, 43048, 25522,...</td>\n",
       "      <td>[15110, 25156, 28696, 565, 6, 121, 15698, 2362...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21814</td>\n",
       "      <td>public SecurityRoleFunctionEntity getSecurityR...</td>\n",
       "      <td>[public, ĠSecurity, Role, Function, Entity, Ġg...</td>\n",
       "      <td>128</td>\n",
       "      <td>@Test public void testGetSecurityRoleFunctionE...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġtest, Get, Security...</td>\n",
       "      <td>148</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 35671, 7199, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 35671, 7199, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 35671, 7199, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 35671, 7199, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 35671, 7199, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 35671, 7199, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 35671, 7199, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 35671, 7199, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 35671, 7199, ...</td>\n",
       "      <td>[15110, 2010, 47613, 47802, 49448, 120, 36090,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8060</td>\n",
       "      <td>protected M loadByQuery(Bson query) { return l...</td>\n",
       "      <td>[protected, ĠM, Ġload, By, Query, (, B, son, Ġ...</td>\n",
       "      <td>21</td>\n",
       "      <td>@Test public void testLoadByQuery() throws Exc...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġtest, Load, By, Que...</td>\n",
       "      <td>130</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 44840, 26170,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 44840, 26170,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 44840, 26170,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 44840, 26170,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 44840, 26170,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 44840, 26170,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 5654, 45589, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 5654, 45589, ...</td>\n",
       "      <td>[37659, 256, 7511, 2765, 48382, 1640, 387, 147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>697</td>\n",
       "      <td>public PagedSearchIterable&lt;GHContent&gt; findFile...</td>\n",
       "      <td>[public, ĠP, aged, Search, Iter, able, &lt;, GH, ...</td>\n",
       "      <td>205</td>\n",
       "      <td>@Test(dataProvider = \"inputEmptyImages\", expec...</td>\n",
       "      <td>[@, Test, (, data, Provider, Ġ=, Ġ\", input, Em...</td>\n",
       "      <td>180</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 38195, 14824, ...</td>\n",
       "      <td>[15110, 221, 4628, 39954, 49628, 868, 41552, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>70739</td>\n",
       "      <td>public static byte[] parse(byte[] payload) { i...</td>\n",
       "      <td>[public, Ġstatic, Ġbyte, [], Ġparse, (, byte, ...</td>\n",
       "      <td>143</td>\n",
       "      <td>@Test public void testParseMessage2() { byte[]...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġtest, Par, se, Mess...</td>\n",
       "      <td>85</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 13360,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 13360,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 13360,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 13360,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 13360,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 9089, 35529, 5457, ...</td>\n",
       "      <td>[15110, 25156, 47893, 48992, 43756, 1640, 4769...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>158</td>\n",
       "      <td>public static void validate(RegistrationData r...</td>\n",
       "      <td>[public, Ġstatic, Ġvoid, Ġvalidate, (, Registr...</td>\n",
       "      <td>51</td>\n",
       "      <td>@Test void validate_AuthenticationData_with_au...</td>\n",
       "      <td>[@, Test, Ġvoid, Ġvalidate, _, Authent, icatio...</td>\n",
       "      <td>118</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 20320, 32890, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 20320, 32890, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 20320, 32890, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 5654, 45589, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 5654, 45589, ...</td>\n",
       "      <td>[1039, 34603, 1640, 10162, 5457, 36993, 45621,...</td>\n",
       "      <td>[15110, 25156, 13842, 28754, 1640, 45366, 3038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33352</td>\n",
       "      <td>@Override public byte[] getBinary(final int i)...</td>\n",
       "      <td>[@, Override, Ġpublic, Ġbyte, [], Ġget, B, ina...</td>\n",
       "      <td>30</td>\n",
       "      <td>@Test public void testBinary() { final byte[] ...</td>\n",
       "      <td>[@, Test, Ġpublic, Ġvoid, Ġtest, B, inary, (),...</td>\n",
       "      <td>145</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 14181, 387, 15...</td>\n",
       "      <td>[1039, 49116, 285, 47893, 48992, 120, 387, 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>11193</td>\n",
       "      <td>public static String eventTimeToString(double ...</td>\n",
       "      <td>[public, Ġstatic, ĠString, Ġevent, Time, To, S...</td>\n",
       "      <td>28</td>\n",
       "      <td>@Test void testEventTimeToString_Double_MaxUnp...</td>\n",
       "      <td>[@, Test, Ġvoid, Ġtest, Event, Time, To, Strin...</td>\n",
       "      <td>59</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[1039, 34603, 285, 13842, 1296, 44879, 14699, ...</td>\n",
       "      <td>[15110, 25156, 26602, 515, 14699, 3972, 34222,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                              input  \\\n",
       "0    1340  public List<Dependency> getModuleDependencies(...   \n",
       "1    1242  @DELETE @Path(\"/{name}\") public Response delet...   \n",
       "2   36220  public static <T, U> FlowableSubscriber<T> sub...   \n",
       "3   21814  public SecurityRoleFunctionEntity getSecurityR...   \n",
       "4    8060  protected M loadByQuery(Bson query) { return l...   \n",
       "..    ...                                                ...   \n",
       "95    697  public PagedSearchIterable<GHContent> findFile...   \n",
       "96  70739  public static byte[] parse(byte[] payload) { i...   \n",
       "97    158  public static void validate(RegistrationData r...   \n",
       "98  33352  @Override public byte[] getBinary(final int i)...   \n",
       "99  11193  public static String eventTimeToString(double ...   \n",
       "\n",
       "                                            input_bpe  input_method_size  \\\n",
       "0   [public, ĠList, <, D, epend, ency, >, Ġget, Mo...                385   \n",
       "1   [@, DE, LE, TE, Ġ@, Path, (\", /, {, name, }, \"...                120   \n",
       "2   [public, Ġstatic, Ġ<, T, ,, ĠU, >, ĠFlow, able...                 84   \n",
       "3   [public, ĠSecurity, Role, Function, Entity, Ġg...                128   \n",
       "4   [protected, ĠM, Ġload, By, Query, (, B, son, Ġ...                 21   \n",
       "..                                                ...                ...   \n",
       "95  [public, ĠP, aged, Search, Iter, able, <, GH, ...                205   \n",
       "96  [public, Ġstatic, Ġbyte, [], Ġparse, (, byte, ...                143   \n",
       "97  [public, Ġstatic, Ġvoid, Ġvalidate, (, Registr...                 51   \n",
       "98  [@, Override, Ġpublic, Ġbyte, [], Ġget, B, ina...                 30   \n",
       "99  [public, Ġstatic, ĠString, Ġevent, Time, To, S...                 28   \n",
       "\n",
       "                                               output  \\\n",
       "0   @Test public void getModuleDependencies() thro...   \n",
       "1   @Test public void deleteAProductWithoutDeletio...   \n",
       "2   @Test public void testResultFunctionThrows() {...   \n",
       "3   @Test public void testGetSecurityRoleFunctionE...   \n",
       "4   @Test public void testLoadByQuery() throws Exc...   \n",
       "..                                                ...   \n",
       "95  @Test(dataProvider = \"inputEmptyImages\", expec...   \n",
       "96  @Test public void testParseMessage2() { byte[]...   \n",
       "97  @Test void validate_AuthenticationData_with_au...   \n",
       "98  @Test public void testBinary() { final byte[] ...   \n",
       "99  @Test void testEventTimeToString_Double_MaxUnp...   \n",
       "\n",
       "                                           output_bpe  output_method_size  \\\n",
       "0   [@, Test, Ġpublic, Ġvoid, Ġget, Module, D, epe...                 274   \n",
       "1   [@, Test, Ġpublic, Ġvoid, Ġdelete, AP, rodu, c...                 179   \n",
       "2   [@, Test, Ġpublic, Ġvoid, Ġtest, Result, Funct...                 214   \n",
       "3   [@, Test, Ġpublic, Ġvoid, Ġtest, Get, Security...                 148   \n",
       "4   [@, Test, Ġpublic, Ġvoid, Ġtest, Load, By, Que...                 130   \n",
       "..                                                ...                 ...   \n",
       "95  [@, Test, (, data, Provider, Ġ=, Ġ\", input, Em...                 180   \n",
       "96  [@, Test, Ġpublic, Ġvoid, Ġtest, Par, se, Mess...                  85   \n",
       "97  [@, Test, Ġvoid, Ġvalidate, _, Authent, icatio...                 118   \n",
       "98  [@, Test, Ġpublic, Ġvoid, Ġtest, B, inary, (),...                 145   \n",
       "99  [@, Test, Ġvoid, Ġtest, Event, Time, To, Strin...                  59   \n",
       "\n",
       "                                                    0  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...   \n",
       "3   [1039, 34603, 1640, 10162, 5457, 35671, 7199, ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 44840, 26170,...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 5457, 36993, 13360,...   \n",
       "97  [1039, 34603, 285, 13842, 1296, 20320, 32890, ...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                    1  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...   \n",
       "3   [1039, 34603, 1640, 10162, 5457, 35671, 7199, ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 44840, 26170,...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "97  [1039, 34603, 285, 13842, 1296, 20320, 32890, ...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                    2  ...  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...  ...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...  ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...  ...   \n",
       "3   [1039, 34603, 1640, 10162, 5457, 35671, 7199, ...  ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 44840, 26170,...  ...   \n",
       "..                                                ...  ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...  ...   \n",
       "96  [1039, 34603, 1640, 10162, 5457, 36993, 13360,...  ...   \n",
       "97  [1039, 34603, 285, 13842, 1296, 20320, 32890, ...  ...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...  ...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...  ...   \n",
       "\n",
       "                                                   21  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...   \n",
       "3   [1039, 34603, 1640, 10162, 5457, 35671, 7199, ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 44840, 26170,...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 5457, 36993, 13360,...   \n",
       "97  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                   22  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...   \n",
       "3   [1039, 34603, 1640, 10162, 5457, 35671, 7199, ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 44840, 26170,...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 5457, 36993, 13360,...   \n",
       "97  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                   23  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 6989, ...   \n",
       "3   [1039, 34603, 1640, 10162, 5457, 35671, 7199, ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "97  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                   24  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...   \n",
       "3   [1039, 34603, 1640, 10162, 5457, 35671, 7199, ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "97  [1039, 34603, 1640, 10162, 5457, 5654, 45589, ...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                   25  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 6989, ...   \n",
       "3   [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 44840, 26170,...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 5457, 36993, 13360,...   \n",
       "97  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                   26  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...   \n",
       "3   [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "4   [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "97  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                   27  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...   \n",
       "3   [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "4   [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "97  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                   28  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...   \n",
       "3   [1039, 34603, 1640, 10162, 5457, 35671, 7199, ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 5654, 45589, ...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "97  [1039, 34603, 1640, 10162, 5457, 5654, 45589, ...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                                   29  \\\n",
       "0   [1039, 34603, 285, 13842, 120, 48720, 495, 267...   \n",
       "1   [1039, 34603, 285, 13842, 1296, 46006, 43048, ...   \n",
       "2   [1039, 34603, 285, 13842, 11222, 43048, 25522,...   \n",
       "3   [1039, 34603, 1640, 10162, 5457, 35671, 7199, ...   \n",
       "4   [1039, 34603, 1640, 10162, 5457, 5654, 45589, ...   \n",
       "..                                                ...   \n",
       "95  [1039, 34603, 285, 13842, 1296, 38195, 14824, ...   \n",
       "96  [1039, 34603, 1640, 10162, 9089, 35529, 5457, ...   \n",
       "97  [1039, 34603, 1640, 10162, 5457, 36993, 45621,...   \n",
       "98  [1039, 34603, 285, 13842, 1296, 14181, 387, 15...   \n",
       "99  [1039, 34603, 285, 13842, 1296, 44879, 14699, ...   \n",
       "\n",
       "                                             input_is  \n",
       "0   [15110, 9527, 41552, 495, 26769, 6761, 15698, ...  \n",
       "1   [1039, 10089, 3850, 6433, 787, 42119, 46469, 7...  \n",
       "2   [15110, 25156, 28696, 565, 6, 121, 15698, 2362...  \n",
       "3   [15110, 2010, 47613, 47802, 49448, 120, 36090,...  \n",
       "4   [37659, 256, 7511, 2765, 48382, 1640, 387, 147...  \n",
       "..                                                ...  \n",
       "95  [15110, 221, 4628, 39954, 49628, 868, 41552, 1...  \n",
       "96  [15110, 25156, 47893, 48992, 43756, 1640, 4769...  \n",
       "97  [15110, 25156, 13842, 28754, 1640, 45366, 3038...  \n",
       "98  [1039, 49116, 285, 47893, 48992, 120, 387, 155...  \n",
       "99  [15110, 25156, 26602, 515, 14699, 3972, 34222,...  \n",
       "\n",
       "[100 rows x 38 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 38)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics and Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_len_method = [ (np.array([ len(gen_method) for gen_method in df_generated_input[j] ]).mean(),\n",
    "                   np.array([ len(gen_method) for gen_method in df_generated_input[j] ]).std()  )\n",
    "                    for j in range(30) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(123.32, 73.30823691782528),\n",
       " (123.14, 73.62296109231141),\n",
       " (121.06, 73.71171141684339),\n",
       " (120.62, 74.09760859838866),\n",
       " (118.27, 73.92845933738913),\n",
       " (120.2, 75.55249830415934),\n",
       " (118.55, 75.28617070883602),\n",
       " (116.27, 74.82176889114558),\n",
       " (118.58, 76.61098876793068),\n",
       " (116.51, 76.25254028555376),\n",
       " (115.5, 76.24965573692776),\n",
       " (116.08, 76.40545530261566),\n",
       " (115.85, 76.80486638228075),\n",
       " (113.15, 76.11075810948148),\n",
       " (111.23, 76.53324179727396),\n",
       " (112.74, 77.43728042745303),\n",
       " (111.63, 77.17819057220764),\n",
       " (111.32, 78.64513716689672),\n",
       " (110.63, 78.97134353675389),\n",
       " (110.08, 79.34843161651024),\n",
       " (107.62, 78.18462508703357),\n",
       " (106.93, 78.72258316391809),\n",
       " (104.6, 78.86748379401996),\n",
       " (103.11, 78.4015172047072),\n",
       " (100.3, 77.45469643604575),\n",
       " (98.88, 78.54709160751912),\n",
       " (98.46, 78.69350926220027),\n",
       " (95.95, 79.08367404211819),\n",
       " (93.31, 79.15133542777404),\n",
       " (86.36, 78.39853570061115)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_len_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoint of Generation\n",
    "corpus = params['corpus']\n",
    "def checkpoint_generation(df):\n",
    "    df.to_json(params['output_sample']+corpus+'_generated.tests.json',  orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_generation(df_generated_input )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MEMORy DEALLOCATION\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27c2fcb21fdb148cd37ecbed2ef65b6b1f3a0948b222c0bcf7dcf1d6a4c7a458"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('shapley-01': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
