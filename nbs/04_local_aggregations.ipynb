{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: local_aggregations.html\n",
    "title: Local Aggregations Module\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_default():\n",
    "    return {\n",
    "        'model_name' : '/workspaces/code-rationales/data/codeparrot-small/checkpoints/checkpoint-29000', \n",
    "        'cache_dir': '/workspaces/code-rationales/datax/df_cache_dir',\n",
    "        'delimiter_sequence': 'and code starts' ### BE VERY CAREFULL HERE ALWAYS VERIFY -> VERY IMPORTANT\n",
    "    }\n",
    "prompts = [\n",
    "        \"\"\"Generate Pyhton code that Test symlink when the target file is a relative path\n",
    "    Should throw a SaltInvocationError : it shouldn't fix this\n",
    "    (although it is done for this emulation.\n",
    "    If the caller works as with the following exception, that might\n",
    "    cause a performance read from the (i.e., with `ServiceException` and supporting the luck process.\n",
    "\n",
    "    :param block_point_on_error: the procurement that is only related to it.\n",
    "\n",
    "    \\\"\\\"\\\"\n",
    "\n",
    "    @private\n",
    "    def best_open_context(self, reqections: Iterable[Name]:\n",
    "        self.usage(\n",
    "            'rame.once is installed in Python. There is no-optimal...\n",
    "    \\\"\\\"\\\"\n",
    "        if not hasattr(self.collection.name):\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = param_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_rationales.loader import download_grammars\n",
    "from tree_sitter import Language, Parser\n",
    "import code_rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2024-06-05 13:47:55.538896: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 13:47:55.769594: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import importlib\n",
    "from matplotlib import colors\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/workspaces/code-rationales/sequential-rationales/huggingface')\n",
    "from rationalization import rationalize_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_rationales.taxonomies import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AST Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nl_pos_taxonomy() -> dict: return {\n",
    "    \"nl_verb\" : ['VBN', 'VBG', 'VBZ', 'VBP', 'VBD', 'VB'],\n",
    "    \"nl_noun\" : ['NN', 'NNPS', 'NNS', 'NNP'],\n",
    "    \"nl_pronoun\" : ['WP', 'PRP', 'PRP$', 'WP','WP$'], \n",
    "    \"nl_adverb\" : ['RBS','RBR', 'RB', 'WRB'], \n",
    "    \"nl_adjetive\" : ['JJR', 'JJS', 'JJ'], \n",
    "    \"nl_determiner\" : ['DT','WDT','PDT'], \n",
    "    \"nl_preposition\" : ['IN', 'TO'],\n",
    "    \"nl_particle\" : ['RP'],\n",
    "    \"nl_modal\" : ['MD'],\n",
    "    \"nl_conjunction\" : ['CC'],\n",
    "    \"nl_cardinal\" : ['CD'],\n",
    "    \"nl_list\": ['LS'],\n",
    "    \"nl_other\" : ['FW', 'EX', 'SYM' , 'UH', 'POS', \"''\", '--',':', '(', ')', '.', ',', '``', '$']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AST Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_node_types(\n",
    "    nested_node_types: dict  # node_types from tree-sitter\n",
    ") -> list: # list of node types\n",
    "    def iterate_and_unroll_dict(nested_node_types: dict, all_node_types: set):\n",
    "        for key, value in nested_node_types.items():\n",
    "            if key == 'type' and type(value) == str:\n",
    "                all_node_types.add(value)\n",
    "            if type(value) == dict:\n",
    "                iterate_and_unroll_dict(value, all_node_types)\n",
    "            if type(value) == list:\n",
    "                for element in value:\n",
    "                    iterate_and_unroll_dict(element, all_node_types) \n",
    "    all_node_types = set()\n",
    "    for dictionary in nested_node_types:\n",
    "        iterate_and_unroll_dict(dictionary, all_node_types)\n",
    "    all_node_types.add('ERROR')\n",
    "    return list(all_node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parser(lang: str):\n",
    "    # Grab the node types from the tree-sitter language\n",
    "    language = Language(f\"{code_rationales.__path__[0]}/grammars/tree-sitter-languages.so\", lang)\n",
    "    node_path = f\"{code_rationales.__path__[0]}/grammars/tree-sitter-{lang}/src/node-types.json\"\n",
    "    with open(node_path) as f:\n",
    "            node_types = json.load(f)\n",
    "    node_types = unroll_node_types(node_types)\n",
    "    # Create a parser for the language\n",
    "    parser = Parser()\n",
    "    parser.set_language(language)\n",
    "    return parser, node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(\n",
    "    node,       # tree-sitter node\n",
    ") -> None:\n",
    "    \"\"\"Traverse in a recursive way, a tree-sitter node and append results to a list.\"\"\"\n",
    "    results = []\n",
    "    def traverse_tree(node, results):\n",
    "        if node.type == 'string':\n",
    "            results.append(node)\n",
    "            return\n",
    "        for n in node.children:\n",
    "            traverse_tree(n, results)\n",
    "        if not node.children:\n",
    "            results.append(node)\n",
    "    traverse_tree(node, results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_offset(\n",
    "    point,              #point to convert\n",
    "    lines: list         #list of lines in the source code\n",
    "    ):\n",
    "        \"\"\"Convert the point to an offset\"\"\"\n",
    "        row, column = point\n",
    "        chars_in_rows = sum(map(len, lines[:row])) + row\n",
    "        chars_in_columns = len(lines[row][:column])\n",
    "        offset = chars_in_rows + chars_in_columns\n",
    "        return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_span(node, lines):\n",
    "    \"\"\"Get the span position of the node in the code string\"\"\"\n",
    "    start_span = convert_to_offset(node.start_point, lines)\n",
    "    end_span = convert_to_offset(node.end_point, lines)\n",
    "    return start_span, end_span\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PROBLEM IS HERE\n",
    "def is_token_span_in_node_span(tok_span, token: str, node_span, node_text: str):\n",
    "    return (node_span[0] <= tok_span[0] and tok_span[1] <= node_span[1]) or \\\n",
    "            (node_span[0]-1 <= tok_span[0] and tok_span[1] <= node_span[1] and node_text in token) or \\\n",
    "            (tok_span[0] <= node_span[0] and node_span[1] <= tok_span[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_type(\n",
    "    tok_span: tuple, # (start, end) position of a token in tokenizer\n",
    "    token: str,   # token value\n",
    "    nodes: list,     # list of tree-sitter nodes\n",
    "    lines: list,     # list of lines in the code\n",
    ") -> tuple: # (parent_type, token_type) of the token\n",
    "    \"\"\"Get the parent AST type and token AST type of a token.\"\"\"\n",
    "    for i, node in enumerate(nodes):\n",
    "        if is_token_span_in_node_span(tok_span, token, get_node_span(node, lines), node.text.decode('utf-8')):\n",
    "            return nodes[i].parent.type, nodes[i].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_nodes(\n",
    "    tok_span: tuple, # (start, end) position of a token in tokenizer\n",
    "    token: str,      #actual token\n",
    "    lines: list,     # list of lines in the code, \n",
    "    nodes_information: dict # dict with augmented information of each ast node\n",
    ") -> list: \n",
    "    \"\"\"Get all AST types for the given token span\"\"\"\n",
    "    results = []\n",
    "    for node_id, node_info in nodes_information.items():\n",
    "        if is_token_span_in_node_span(tok_span, token, node_info['span'], node_info['node'].text.decode('utf-8')):\n",
    "            results.append(node_info['node'])   \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_height(node):\n",
    "    if not node.children: \n",
    "        return 0\n",
    "    children_heights = []\n",
    "    for child in node.children:\n",
    "        children_heights.append(get_node_height(child))\n",
    "    return max(children_heights) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_by_type(\n",
    "    node, \n",
    "    node_types: list\n",
    ") -> list :\n",
    "    def traverse_and_search(node, node_types, results):\n",
    "        if node.type in node_types:\n",
    "            results.append(node)\n",
    "        for n in node.children:\n",
    "            traverse_and_search(n, node_types ,results)\n",
    "    results = []\n",
    "    traverse_and_search(node, node_types, results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identation Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identation_spans(source_code:str):\n",
    "    pattern = '\\s+(?=\\w)|\\t|\\n'\n",
    "    return [(m.start(0), m.end(0)-1) for m in re.finditer(pattern, source_code)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomy Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_results(global_results):\n",
    "    def clean_dictonary(result_dict):\n",
    "        clean_dict = result_dict.copy()\n",
    "        for key, value in result_dict.items():\n",
    "            if not value or not value['values']: \n",
    "                clean_dict.pop(key)\n",
    "        return clean_dict\n",
    "    for key, value in global_results.items():\n",
    "        global_results[key] = clean_dictonary(value)\n",
    "    return global_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_category_by_token(taxonomy_dict: dict, token_type: str):\n",
    "    for key, value in taxonomy_dict.items():\n",
    "        if token_type in value:\n",
    "            return key\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_taxonomy(sc_taxonomy_dict:dict, nl_taxonomy_dict: dict, result_dict: dict):\n",
    "    result_dict = result_dict.copy()\n",
    "    mappings = {token: {category : {'values': [], 'rationales': []} for category in {**sc_taxonomy_dict, **nl_taxonomy_dict}.keys()} for token in result_dict.keys()}\n",
    "    for target_token, value in result_dict.items():\n",
    "        for source_token, props in value.items():\n",
    "            source_key = search_category_by_token(sc_taxonomy_dict, source_token.split('_|_')[1]) if source_token[:2] == 'sc' else search_category_by_token(nl_taxonomy_dict, source_token.split('_|_')[1])\n",
    "            mappings[target_token][source_key]['values'].append(props['values'])\n",
    "            mappings[target_token][source_key]['rationales'].append(props['rationales'])\n",
    "    return clean_results(mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_local_results_to_taxonomy(sc_taxonomy_dict:dict, nl_taxonomy_dict:dict, local_results: dict):\n",
    "    return dict(zip(local_results.keys(), map(lambda aggegrations: map_to_taxonomy(sc_taxonomy_dict, nl_taxonomy_dict, aggegrations), local_results.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Sampling Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sampled_generation(\n",
    "        df_sampled_code, \n",
    "        model,\n",
    "        tokenizer,\n",
    "        number_samples_generation = 1,\n",
    "        max_gen_tok = 100, \n",
    "        top_k = 0\n",
    "    ):\n",
    "    dict_generated_code = {i: [] for i in range(number_samples_generation)}\n",
    "    for idx_prompt, prompt in enumerate(df_sampled_code['prompt']):\n",
    "        input = tokenizer([prompt], return_tensors=\"pt\")\n",
    "        input.to(model.device)\n",
    "        outputs = model.generate(**input, do_sample=True,\n",
    "                                 max_length=len(df_sampled_code['input_ids'][idx_prompt]), ##Force rationalization\n",
    "                                 top_k=top_k, \n",
    "                                 num_return_sequences=number_samples_generation, \n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "        for index, output in enumerate(outputs):\n",
    "            dict_generated_code[index].append(output.tolist())\n",
    "    df_temp = pd.DataFrame().from_dict(data=dict_generated_code) # DataFrame from Generation\n",
    "    df_temp = pd.concat([df_sampled_code.reset_index(), df_temp ], axis=1) #Index before concating\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the model is not fine-tuned or compatible, it will rise an error\n",
    "#This function works for one tensor of source token and one tensor of target tokens\n",
    "def rationalize_model(model, tokenizer, input_ids, max_token_size: int, verbose=True):\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    all_rationales, log = rationalize_lm(\n",
    "        model = model,\n",
    "        input_ids = input_ids[:max_token_size],\n",
    "        tokenizer = tokenizer,\n",
    "        verbose = verbose,\n",
    "        max_steps=1024 #Max number of steps for greedy rationalization\n",
    "    )\n",
    "    return all_rationales, log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_rational(\n",
    "    model,\n",
    "    tokenizer, \n",
    "    arr_target_tokens, \n",
    "    seq_id, #mapping sequence id\n",
    "    max_token_size,\n",
    "    verbose=True\n",
    "):\n",
    "    arr_log = []\n",
    "    for index, val in enumerate(arr_target_tokens):\n",
    "        all_rationales, log = rationalize_model(\n",
    "            model=model, \n",
    "            tokenizer=tokenizer, \n",
    "            input_ids=val,\n",
    "            max_token_size=max_token_size,\n",
    "            verbose=False\n",
    "        )\n",
    "        arr_log.append(log)\n",
    "    arr_code_rationales = [ log['rationalization'] for log in arr_log ] #extracting just rationalizations\n",
    "    arr_from_sentence = [ list(np.full( len(val), seq_id[arr_i] )) #arr_i maps to the real sequence id\n",
    "                            for arr_i, val in enumerate(arr_code_rationales)]\n",
    "    arr_code_rationales = sum( arr_code_rationales, [] ) #flatting\n",
    "    arr_from_sentence = sum( arr_from_sentence, [] ) #flatting\n",
    "    return arr_code_rationales, arr_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_rationales( arr_code_rationales, arr_from_sentence ):\n",
    "    #Creating pandas_1 {p_rationale}\n",
    "    rational = lambda list_log,typeset: [ (dict_tok['added_token_text'],round(dict_tok['true_token_prob'],6)) for dict_tok in list_log if dict_tok['from']==typeset]\n",
    "    log = lambda log_row: [(log_dict['added_token_text'],log_dict['true_token_prob']) for log_dict in log_row] #Typeset\n",
    "\n",
    "    log_position = lambda log_row: [log_dict['added_token_position'] for log_dict in log_row] #Position of the Rationale\n",
    "    log_prediction = lambda log_row: [log_dict['true_token_prob'] for log_dict in log_row] #Rationale Prob\n",
    "\n",
    "    p_rationale = pd.DataFrame()\n",
    "\n",
    "    p_rationale['goal_token'] = [dict_token['goal_word'] for dict_token in arr_code_rationales]\n",
    "    p_rationale['from_seq_id'] = arr_from_sentence\n",
    "\n",
    "    p_rationale['typesets_tgt'] = [ log(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    \n",
    "    p_rationale['rationale_pos_tgt'] = [ log_position(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    p_rationale['rationale_prob_tgt'] = [ log_prediction(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "\n",
    "\n",
    "    return p_rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running Rationalization\n",
    "def run_code_rational( \n",
    "        df_generated_input,\n",
    "        tensor_size, #Control the size of the experiment, \n",
    "        model,\n",
    "        tokenizer,\n",
    "        experiment = '5',\n",
    "        batch_size = 100, \n",
    "        max_token_size = 44,\n",
    "        verbose = True \n",
    "    ):\n",
    "\n",
    "    arr_rationals = []\n",
    "    arr_from_seq = []\n",
    "\n",
    "    for i in range( 0 , tensor_size , batch_size ):\n",
    "        print('************************' + str(i) + '************************')\n",
    "        t_generated_input = df_generated_input[experiment].values[i:i+batch_size]\n",
    "        t_generated_input = [ torch.tensor(s).to(model.device) for s in t_generated_input]\n",
    "\n",
    "        t_arr_rationals,t_arr_from_seq = run_multiple_rational(\n",
    "            model = model,\n",
    "            tokenizer = tokenizer,\n",
    "            arr_target_tokens =  t_generated_input, \n",
    "            seq_id = list(range(i,i+batch_size)),\n",
    "            max_token_size = len(t_generated_input[0]),\n",
    "            verbose = verbose\n",
    "        )\n",
    "\n",
    "        arr_rationals = arr_rationals + t_arr_rationals\n",
    "        arr_from_seq = arr_from_seq + t_arr_from_seq\n",
    "\n",
    "        torch.cuda.empty_cache() #Cleaning Cache\n",
    "        \n",
    "    print(\"Experiment Finished: \" + str(experiment))\n",
    "    return pandas_rationales( arr_rationals, arr_from_seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_rational_all_set(exp, df_generated_input, model, tokenizer, tensor_n = 100, BATCH = 10): #When Tensor_n and batch differs then 'from_seq_id' is lost\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    EXP = exp\n",
    "    test_arr_rationals = run_code_rational( \n",
    "            df_generated_input,\n",
    "            tensor_n,\n",
    "            model, \n",
    "            tokenizer,\n",
    "            experiment = EXP,\n",
    "            batch_size = BATCH,\n",
    "            verbose = False \n",
    "        )\n",
    "    #Saving process\n",
    "    return test_arr_rationals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rationales Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_right_span = lambda start_idx, end_idx, df : len(''.join(map(str, df.loc[start_idx:end_idx, 'goal_token'].tolist())))\n",
    "calculate_span = lambda right_span, token : (right_span-len(str(token)), right_span)\n",
    "delete_leading_spaces = lambda string: re.sub(r'^\\s+', '', string)\n",
    "delete_leading_breaks = lambda string: re.sub(r'^\\n+', '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_first_token_row(df):\n",
    "    df.loc[-1] = [df['typesets_tgt'][0][0][0], df['from_seq_id'][0], None, None, None, df['exp'][0]]\n",
    "    df.index = df.index + 1\n",
    "    df = df.sort_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_auxiliary_columns_to_experiment_result(df, delimiter_sequence: str):\n",
    "    df.insert(0, 'rational_pos', [i for i in range(len(df))])\n",
    "    initial_token = df['goal_token'][0]\n",
    "    ### TOKEN TYPE COLUMN\n",
    "    token_type_column = ['src'] * len(df)\n",
    "    sequence = initial_token\n",
    "    for idx, goal_token in enumerate(df['goal_token']):\n",
    "        if delimiter_sequence not in sequence:\n",
    "            token_type_column[idx] = 'nl'\n",
    "            sequence+=str(goal_token)\n",
    "    df['token_type'] = token_type_column\n",
    "    src_initial_token_idx = df[df['token_type'] == 'src'].first_valid_index()\n",
    "    df['span'] = [None] * len(df[:src_initial_token_idx]) + [calculate_span(calculate_right_span(src_initial_token_idx, index, df), token) for index, token in df[src_initial_token_idx:]['goal_token'].items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nl_tags_in_experiment_result(df, nl_ast_types, nl_pos_types, parser):\n",
    "    #initial_token = df['typesets_tgt'][0][0][0] if df[df['token_type'] == 'src'].first_valid_index() == 0 else ''\n",
    "    ##### POS TAGS FOR NL PART IN PROMPT\n",
    "    target_nl = ''.join(df[df['token_type'] == 'nl']['goal_token'].map(lambda value: str(value)))\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(target_nl))\n",
    "    first_src_token_index = df[df['token_type']== 'src'].first_valid_index()\n",
    "    nl_stop_index = first_src_token_index if first_src_token_index is not None else len(df)\n",
    "    for idx in range(nl_stop_index):\n",
    "        nl_tags = list(map(lambda tag: tag[1] if tag[1] in nl_pos_types else None, filter(lambda tag: tag[0] in str(df['goal_token'][idx]), pos_tags)))\n",
    "        if nl_tags: df.at[idx, 'tags'] = df['tags'][idx] + [('nl',nl_tags[-1],0)]\n",
    "    ##### POS TAGS FOR CODE PART\n",
    "    target_code = ''.join(df[df['token_type'] == 'src']['goal_token'].map(lambda value: str(value)))\n",
    "    nl_target_nodes = get_nodes_by_type(parser.parse(bytes(target_code, 'utf8')).root_node, nl_ast_types)\n",
    "    if first_src_token_index is not None:\n",
    "        for token_idx in range(first_src_token_index, len(df['span'])):\n",
    "                    for nl_target_node in nl_target_nodes:\n",
    "                        if is_token_span_in_node_span(df['span'][token_idx], df['goal_token'][token_idx], get_node_span(nl_target_node, target_code.split(\"\\n\")), nl_target_node.text.decode('utf-8')) and \\\n",
    "                                (str(df['goal_token'][token_idx]) in nl_target_node.text.decode('utf-8') or nl_target_node.text.decode('utf-8') in str(df['goal_token'][token_idx])):\n",
    "                                tagged_token_list = list(filter(lambda tagged_token: str(tagged_token[0]).replace(' ','') in str(df['goal_token'][token_idx]).replace(' ','') or str(df['goal_token'][token_idx]).replace(' ','') in str(tagged_token[0]).replace(' ',''), \\\n",
    "                                                        nltk.pos_tag( nltk.word_tokenize(nl_target_node.text.decode('utf-8')))))\n",
    "                            if len(tagged_token_list)>0 and tagged_token_list[0][1] in nl_pos_types and tagged_token_list[0][1] not in df['tags'][token_idx]: df.at[token_idx, 'tags'] = df['tags'][token_idx] + [tagged_token_list[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ast_tags_in_experiment_result(df, parser):\n",
    "    target_code = ''.join(df[df['token_type'] == 'src']['goal_token'].map(lambda value: str(value)))\n",
    "    src_initial_token_idx = df[df['token_type'] == 'src'].first_valid_index()\n",
    "    target_ast = parser.parse(bytes(target_code, 'utf8')).root_node\n",
    "    for token_idx in range(src_initial_token_idx, len(df)):\n",
    "        df.at[token_idx, 'tags'] = df['tags'][token_idx] + list(map(lambda node: node.type, get_token_nodes(df['span'][token_idx], df['goal_token'][token_idx], target_ast, target_code.split(\"\\n\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_rationals(experiment_results: list, nl_ast_types: list, nl_pos_types: list, delimiter_sequence: str, parser):\n",
    "    experiments = {}\n",
    "    for exp_idx, df_experiment in enumerate(experiment_results):\n",
    "        experiment_results = []\n",
    "        experiment_rational_results = [df_experiment[(df_experiment['from_seq_id'] == sample_idx) | \\\n",
    "                                                     (df_experiment['from_seq_id'] == str(sample_idx))].reset_index() \\\n",
    "                                                    for sample_idx in range(len(prompts))]\n",
    "        print('*'*10 +'Tagging rationals for exp: ' +str(exp_idx) + '*'*10)\n",
    "        for experiment_rational_result in experiment_rational_results:\n",
    "            experiment_rational_result = experiment_rational_result.drop('index', axis=1)\n",
    "            experiment_rational_result = add_first_token_row(experiment_rational_result)\n",
    "            add_auxiliary_columns_to_experiment_result(experiment_rational_result, delimiter_sequence)\n",
    "            experiment_rational_result['tags'] = [[]]*len(experiment_rational_result)\n",
    "            fill_nl_tags_in_experiment_result(experiment_rational_result, nl_ast_types, nl_pos_types, parser)\n",
    "            fill_ast_tags_in_experiment_result(experiment_rational_result, parser)\n",
    "            experiment_results.append(experiment_rational_result)\n",
    "        experiments[exp_idx] = experiment_results\n",
    "    return experiments\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rationales Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rationals(global_tagged_results: dict, ast_node_types: list, nl_pos_types: list, number_samples: int):\n",
    "    aggregation_results = {sample_id: None  for sample_id in range(number_samples)}\n",
    "    for exp_idx, experiment_results in global_tagged_results.items():\n",
    "        print('*'*10 +'Aggregrating rationals for exp: ' +str(exp_idx) + '*'*10)\n",
    "        for experiment_result in experiment_results:\n",
    "            ### GET INFORMATION OF FIRST TOKEN\n",
    "            #sample_results = {str(pos+1)+'['+str(token)+']' : {node_type : {'values': [], 'rationales': []} for node_type in ast_node_types + nl_pos_types} for pos, token in enumerate(experiment_result['goal_token'].tolist())}\n",
    "            sample_results = {str(token_pos)+'['+str(experiment_result['goal_token'][token_pos])+']' : \n",
    "                              {**{ 'sc'+'_|_'+node_type : {'values': [], 'rationales': []} for node_type in ast_node_types }, **{ 'nl'+'_|_'+node_type: {'values': [], 'rationales': []} for node_type in nl_pos_types }}\n",
    "                              for token_pos in range(1, len(experiment_result['rational_pos']))}\n",
    "            for target_idx, target_token in enumerate(experiment_result['goal_token'].tolist()): \n",
    "                if target_idx > 0: # INITIAL TOKEN IS IGNORED\n",
    "                    for rational_idx, rational_pos in enumerate(experiment_result['rationale_pos_tgt'][target_idx]):\n",
    "                        for rational_tag in experiment_result['tags'][rational_pos]: \n",
    "                            if rational_tag[1]:\n",
    "                                try:\n",
    "                                    sample_results[str(target_idx)+'['+str(target_token)+']'][rational_tag[0]+'_|_'+rational_tag[1]]['values'].append(experiment_result['rationale_prob_tgt'][target_idx][rational_idx])\n",
    "                                    sample_results[str(target_idx)+'['+str(target_token)+']'][rational_tag[0]+'_|_'+rational_tag[1]]['rationales'].append(str(rational_pos)+'['+str(experiment_result['goal_token'][rational_pos])+']')\n",
    "                                except Exception as e:\n",
    "                                    print('An Error Occurred')\n",
    "            aggregation_results[experiment_result['from_seq_id'].unique()[0]] = clean_results(sample_results)\n",
    "    return aggregation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOCAL EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define parser\n",
    "parser, node_types = create_parser('python')\n",
    "node_types += ['identation']\n",
    "### Defines pos tags \n",
    "pos_types = list(nltk.data.load('help/tagsets/upenn_tagset.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS:\n",
      "('list item marker', 'A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005 SP-44007 Second Third Three Two * a b c d first five four one six three two ')\n",
      "Description: list item marker\n",
      "Example: A\n",
      "\n",
      "TO:\n",
      "('\"to\" as preposition or infinitive marker', 'to ')\n",
      "Description: \"to\" as preposition or infinitive marker\n",
      "Example: t\n",
      "\n",
      "VBN:\n",
      "('verb, past participle', 'multihulled dilapidated aerosolized chaired languished panelized used experimented flourished imitated reunifed factored condensed sheared unsettled primed dubbed desired ... ')\n",
      "Description: verb, past participle\n",
      "Example: m\n",
      "\n",
      "'':\n",
      "('closing quotation mark', \"' '' \")\n",
      "Description: closing quotation mark\n",
      "Example: '\n",
      "\n",
      "WP:\n",
      "('WH-pronoun', 'that what whatever whatsoever which who whom whosoever ')\n",
      "Description: WH-pronoun\n",
      "Example: t\n",
      "\n",
      "UH:\n",
      "('interjection', 'Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly man baby diddle hush sonuvabitch ... ')\n",
      "Description: interjection\n",
      "Example: G\n",
      "\n",
      "VBG:\n",
      "('verb, present participle or gerund', \"telegraphing stirring focusing angering judging stalling lactating hankerin' alleging veering capping approaching traveling besieging encrypting interrupting erasing wincing ... \")\n",
      "Description: verb, present participle or gerund\n",
      "Example: t\n",
      "\n",
      "JJ:\n",
      "('adjective or numeral, ordinal', 'third ill-mannered pre-war regrettable oiled calamitous first separable ectoplasmic battery-powered participatory fourth still-to-be-named multilingual multi-disciplinary ... ')\n",
      "Description: adjective or numeral, ordinal\n",
      "Example: t\n",
      "\n",
      "VBZ:\n",
      "('verb, present tense, 3rd person singular', 'bases reconstructs marks mixes displeases seals carps weaves snatches slumps stretches authorizes smolders pictures emerges stockpiles seduces fizzes uses bolsters slaps speaks pleads ... ')\n",
      "Description: verb, present tense, 3rd person singular\n",
      "Example: b\n",
      "\n",
      "--:\n",
      "('dash', '-- ')\n",
      "Description: dash\n",
      "Example: -\n",
      "\n",
      "VBP:\n",
      "('verb, present tense, not 3rd person singular', 'predominate wrap resort sue twist spill cure lengthen brush terminate appear tend stray glisten obtain comprise detest tease attract emphasize mold postpone sever return wag ... ')\n",
      "Description: verb, present tense, not 3rd person singular\n",
      "Example: p\n",
      "\n",
      "NN:\n",
      "('noun, common, singular or mass', 'common-carrier cabbage knuckle-duster Casino afghan shed thermostat investment slide humour falloff slick wind hyena override subhumanity machinist ... ')\n",
      "Description: noun, common, singular or mass\n",
      "Example: c\n",
      "\n",
      "DT:\n",
      "('determiner', 'all an another any both del each either every half la many much nary neither no some such that the them these this those ')\n",
      "Description: determiner\n",
      "Example: a\n",
      "\n",
      "PRP:\n",
      "('pronoun, personal', 'hers herself him himself hisself it itself me myself one oneself ours ourselves ownself self she thee theirs them themselves they thou thy us ')\n",
      "Description: pronoun, personal\n",
      "Example: h\n",
      "\n",
      "::\n",
      "('colon or ellipsis', ': ; ... ')\n",
      "Description: colon or ellipsis\n",
      "Example: :\n",
      "\n",
      "WP$:\n",
      "('WH-pronoun, possessive', 'whose ')\n",
      "Description: WH-pronoun, possessive\n",
      "Example: w\n",
      "\n",
      "NNPS:\n",
      "('noun, proper, plural', 'Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques Apache Apaches Apocrypha ... ')\n",
      "Description: noun, proper, plural\n",
      "Example: A\n",
      "\n",
      "PRP$:\n",
      "('pronoun, possessive', 'her his mine my our ours their thy your ')\n",
      "Description: pronoun, possessive\n",
      "Example: h\n",
      "\n",
      "WDT:\n",
      "('WH-determiner', 'that what whatever which whichever ')\n",
      "Description: WH-determiner\n",
      "Example: t\n",
      "\n",
      "(:\n",
      "('opening parenthesis', '( [ { ')\n",
      "Description: opening parenthesis\n",
      "Example: (\n",
      "\n",
      "):\n",
      "('closing parenthesis', ') ] } ')\n",
      "Description: closing parenthesis\n",
      "Example: )\n",
      "\n",
      ".:\n",
      "('sentence terminator', '. ! ? ')\n",
      "Description: sentence terminator\n",
      "Example: .\n",
      "\n",
      ",:\n",
      "('comma', ', ')\n",
      "Description: comma\n",
      "Example: ,\n",
      "\n",
      "``:\n",
      "('opening quotation mark', '` `` ')\n",
      "Description: opening quotation mark\n",
      "Example: `\n",
      "\n",
      "$:\n",
      "('dollar', '$ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$ ')\n",
      "Description: dollar\n",
      "Example: $\n",
      "\n",
      "RB:\n",
      "('adverb', 'occasionally unabatingly maddeningly adventurously professedly stirringly prominently technologically magisterially predominately swiftly fiscally pitilessly ... ')\n",
      "Description: adverb\n",
      "Example: o\n",
      "\n",
      "RBR:\n",
      "('adverb, comparative', 'further gloomier grander graver greater grimmer harder harsher healthier heavier higher however larger later leaner lengthier less-perfectly lesser lonelier longer louder lower more ... ')\n",
      "Description: adverb, comparative\n",
      "Example: f\n",
      "\n",
      "RBS:\n",
      "('adverb, superlative', 'best biggest bluntest earliest farthest first furthest hardest heartiest highest largest least less most nearest second tightest worst ')\n",
      "Description: adverb, superlative\n",
      "Example: b\n",
      "\n",
      "VBD:\n",
      "('verb, past tense', 'dipped pleaded swiped regummed soaked tidied convened halted registered cushioned exacted snubbed strode aimed adopted belied figgered speculated wore appreciated contemplated ... ')\n",
      "Description: verb, past tense\n",
      "Example: d\n",
      "\n",
      "IN:\n",
      "('preposition or conjunction, subordinating', 'astride among uppon whether out inside pro despite on by throughout below within for towards near behind atop around if like until below next into if beside ... ')\n",
      "Description: preposition or conjunction, subordinating\n",
      "Example: a\n",
      "\n",
      "FW:\n",
      "('foreign word', \"gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte terram fiche oui corporis ... \")\n",
      "Description: foreign word\n",
      "Example: g\n",
      "\n",
      "RP:\n",
      "('particle', 'aboard about across along apart around aside at away back before behind by crop down ever fast for forth from go high i.e. in into just later low more off on open out over per pie raising start teeth that through under unto up up-pp upon whole with you ')\n",
      "Description: particle\n",
      "Example: a\n",
      "\n",
      "JJR:\n",
      "('adjective, comparative', 'bleaker braver breezier briefer brighter brisker broader bumper busier calmer cheaper choosier cleaner clearer closer colder commoner costlier cozier creamier crunchier cuter ... ')\n",
      "Description: adjective, comparative\n",
      "Example: b\n",
      "\n",
      "JJS:\n",
      "('adjective, superlative', 'calmest cheapest choicest classiest cleanest clearest closest commonest corniest costliest crassest creepiest crudest cutest darkest deadliest dearest deepest densest dinkiest ... ')\n",
      "Description: adjective, superlative\n",
      "Example: c\n",
      "\n",
      "PDT:\n",
      "('pre-determiner', 'all both half many quite such sure this ')\n",
      "Description: pre-determiner\n",
      "Example: a\n",
      "\n",
      "MD:\n",
      "('modal auxiliary', \"can cannot could couldn't dare may might must need ought shall should shouldn't will would \")\n",
      "Description: modal auxiliary\n",
      "Example: c\n",
      "\n",
      "VB:\n",
      "('verb, base form', 'ask assemble assess assign assume atone attention avoid bake balkanize bank begin behold believe bend benefit bevel beware bless boil bomb boost brace break bring broil brush build ... ')\n",
      "Description: verb, base form\n",
      "Example: a\n",
      "\n",
      "WRB:\n",
      "('Wh-adverb', 'how however whence whenever where whereby whereever wherein whereof why ')\n",
      "Description: Wh-adverb\n",
      "Example: h\n",
      "\n",
      "NNP:\n",
      "('noun, proper, singular', 'Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA Shannon A.K.C. Meltex Liverpool ... ')\n",
      "Description: noun, proper, singular\n",
      "Example: M\n",
      "\n",
      "EX:\n",
      "('existential there', 'there ')\n",
      "Description: existential there\n",
      "Example: t\n",
      "\n",
      "NNS:\n",
      "('noun, common, plural', 'undergraduates scotches bric-a-brac products bodyguards facets coasts divestitures storehouses designs clubs fragrances averages subjectivists apprehensions muses factory-jobs ... ')\n",
      "Description: noun, common, plural\n",
      "Example: u\n",
      "\n",
      "SYM:\n",
      "('symbol', \"% & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** *** \")\n",
      "Description: symbol\n",
      "Example: %\n",
      "\n",
      "CC:\n",
      "('conjunction, coordinating', \"& 'n and both but either et for less minus neither nor or plus so therefore times v. versus vs. whether yet \")\n",
      "Description: conjunction, coordinating\n",
      "Example: &\n",
      "\n",
      "CD:\n",
      "('numeral, cardinal', \"mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025 fifteen 271,124 dozen quintillion DM2,000 ... \")\n",
      "Description: numeral, cardinal\n",
      "Example: m\n",
      "\n",
      "POS:\n",
      "('genitive marker', \"' 's \")\n",
      "Description: genitive marker\n",
      "Example: '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the UPenn tagset\n",
    "tagset = nltk.data.load('help/tagsets/upenn_tagset.pickle')\n",
    "\n",
    "# Display examples for each tag\n",
    "for tag, details in tagset.items():\n",
    "    print(f\"{tag}:\")\n",
    "    print(details)\n",
    "    print(f\"Description: {details[0]}\")\n",
    "    print(f\"Example: {details[1][0]}\\n\")  # Taking the first example for brevity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Tokenizer Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(32768, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(params['model_name'], cache_dir=params['cache_dir'])\n",
    "tokenizer = AutoTokenizer.from_pretrained(params['model_name'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled_code = pd.DataFrame(prompts, columns=['prompt'])\n",
    "df_sampled_code['input_ids'] = tokenizer(df_sampled_code['prompt'].tolist())['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 19, but ``max_length`` is set to 19.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    }
   ],
   "source": [
    "### SAMPLING GENERATION \n",
    "df_generated_input = df_sampled_generation(\n",
    "    df_sampled_code=df_sampled_code, \n",
    "    model=model,\n",
    "    tokenizer=tokenizer, \n",
    "    number_samples_generation=1,\n",
    "    max_gen_tok=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************0************************\n",
      "Experiment Finished: 0\n"
     ]
    }
   ],
   "source": [
    "### GET RATIONALES\n",
    "experiment_results = []\n",
    "for i in df_generated_input.columns[3:]: #Only Generated Sequences \n",
    "    experiment_result = run_code_rational_all_set(df_generated_input=df_generated_input, exp=i, tensor_n=df_generated_input.shape[0],model=model, tokenizer=tokenizer, BATCH=10)\n",
    "    experiment_result['exp'] = i\n",
    "    experiment_results.append(experiment_result)\n",
    "df_experiment_results = pd.concat(experiment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "      <th>exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multiply</td>\n",
       "      <td>0</td>\n",
       "      <td>[(def, 9.548327398078982e-06)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[9.548327398078982e-06]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[( multiply, 0.18308576941490173)]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.18308576941490173]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>two</td>\n",
       "      <td>0</td>\n",
       "      <td>[(_, 0.00018199862097389996), ( multiply, 0.00...</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>[0.00018199862097389996, 0.0015578435268253088...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[(two, 0.1395016461610794)]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0.1395016461610794]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>numbers</td>\n",
       "      <td>0</td>\n",
       "      <td>[(_, 0.00018957824795506895), ( multiply, 0.00...</td>\n",
       "      <td>[4, 1, 0, 3, 2]</td>\n",
       "      <td>[0.00018957824795506895, 0.0004100390360690653...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(</td>\n",
       "      <td>0</td>\n",
       "      <td>[(numbers, 0.05542754754424095), (def, 0.40192...</td>\n",
       "      <td>[5, 0]</td>\n",
       "      <td>[0.05542754754424095, 0.4019215404987335]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[((, 0.002531559206545353), ( multiply, 0.0245...</td>\n",
       "      <td>[6, 1, 0, 3, 4]</td>\n",
       "      <td>[0.002531559206545353, 0.024547705426812172, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>[(a, 0.03127935156226158), ((, 0.2816878855228...</td>\n",
       "      <td>[7, 6]</td>\n",
       "      <td>[0.03127935156226158, 0.2816878855228424]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>[(,, 0.00025553975137881935), (a, 0.0063189524...</td>\n",
       "      <td>[8, 7, 0, 1, 5, 3, 4, 2, 6]</td>\n",
       "      <td>[0.00025553975137881935, 0.006318952422589064,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>):</td>\n",
       "      <td>0</td>\n",
       "      <td>[(b, 0.0015836571110412478), (def, 0.045113172...</td>\n",
       "      <td>[9, 0, 8]</td>\n",
       "      <td>[0.0015836571110412478, 0.04511317238211632, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>[():, 0.5840400457382202)]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[0.5840400457382202]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>return</td>\n",
       "      <td>0</td>\n",
       "      <td>[(\\n       , 0.046589091420173645), ():, 0.068...</td>\n",
       "      <td>[11, 10, 0, 9]</td>\n",
       "      <td>[0.046589091420173645, 0.06804584711790085, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pow</td>\n",
       "      <td>0</td>\n",
       "      <td>[( return, 6.815839151386172e-05), ( multiply,...</td>\n",
       "      <td>[12, 1, 0, 7, 11, 6, 8, 5, 9, 10, 3, 4, 2]</td>\n",
       "      <td>[6.815839151386172e-05, 0.0015082163736224174,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(</td>\n",
       "      <td>0</td>\n",
       "      <td>[( pow, 0.22912755608558655)]</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[0.22912755608558655]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[((, 0.0022315604146569967), ( pow, 0.03127949...</td>\n",
       "      <td>[14, 13, 7, 1]</td>\n",
       "      <td>[0.0022315604146569967, 0.03127949312329292, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>[(a, 0.018692484125494957), ((, 0.296647161245...</td>\n",
       "      <td>[15, 14]</td>\n",
       "      <td>[0.018692484125494957, 0.29664716124534607]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>[(,, 0.00035618594847619534), (a, 0.0054568531...</td>\n",
       "      <td>[16, 15, 0, 1, 10, 9]</td>\n",
       "      <td>[0.00035618594847619534, 0.005456853192299604,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>)</td>\n",
       "      <td>0</td>\n",
       "      <td>[(b, 0.016638170927762985), (,, 0.078013807535...</td>\n",
       "      <td>[17, 16, 13, 10]</td>\n",
       "      <td>[0.016638170927762985, 0.07801380753517151, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[(), 0.0012392343487590551), (b, 0.00156999146...</td>\n",
       "      <td>[18, 17, 15, 12, 16, 14, 7, 8, 0, 1, 13, 9, 10...</td>\n",
       "      <td>[0.0012392343487590551, 0.0015699914656579494,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   goal_token  from_seq_id                                       typesets_tgt  \\\n",
       "0    multiply            0                     [(def, 9.548327398078982e-06)]   \n",
       "1           _            0                 [( multiply, 0.18308576941490173)]   \n",
       "2         two            0  [(_, 0.00018199862097389996), ( multiply, 0.00...   \n",
       "3           _            0                        [(two, 0.1395016461610794)]   \n",
       "4     numbers            0  [(_, 0.00018957824795506895), ( multiply, 0.00...   \n",
       "5           (            0  [(numbers, 0.05542754754424095), (def, 0.40192...   \n",
       "6           a            0  [((, 0.002531559206545353), ( multiply, 0.0245...   \n",
       "7           ,            0  [(a, 0.03127935156226158), ((, 0.2816878855228...   \n",
       "8           b            0  [(,, 0.00025553975137881935), (a, 0.0063189524...   \n",
       "9          ):            0  [(b, 0.0015836571110412478), (def, 0.045113172...   \n",
       "10  \\n                   0                         [():, 0.5840400457382202)]   \n",
       "11     return            0  [(\\n       , 0.046589091420173645), ():, 0.068...   \n",
       "12        pow            0  [( return, 6.815839151386172e-05), ( multiply,...   \n",
       "13          (            0                      [( pow, 0.22912755608558655)]   \n",
       "14          a            0  [((, 0.0022315604146569967), ( pow, 0.03127949...   \n",
       "15          ,            0  [(a, 0.018692484125494957), ((, 0.296647161245...   \n",
       "16          b            0  [(,, 0.00035618594847619534), (a, 0.0054568531...   \n",
       "17          )            0  [(b, 0.016638170927762985), (,, 0.078013807535...   \n",
       "18                       0  [(), 0.0012392343487590551), (b, 0.00156999146...   \n",
       "\n",
       "                                    rationale_pos_tgt  \\\n",
       "0                                                 [0]   \n",
       "1                                                 [1]   \n",
       "2                                           [2, 1, 0]   \n",
       "3                                                 [3]   \n",
       "4                                     [4, 1, 0, 3, 2]   \n",
       "5                                              [5, 0]   \n",
       "6                                     [6, 1, 0, 3, 4]   \n",
       "7                                              [7, 6]   \n",
       "8                         [8, 7, 0, 1, 5, 3, 4, 2, 6]   \n",
       "9                                           [9, 0, 8]   \n",
       "10                                               [10]   \n",
       "11                                     [11, 10, 0, 9]   \n",
       "12         [12, 1, 0, 7, 11, 6, 8, 5, 9, 10, 3, 4, 2]   \n",
       "13                                               [13]   \n",
       "14                                     [14, 13, 7, 1]   \n",
       "15                                           [15, 14]   \n",
       "16                              [16, 15, 0, 1, 10, 9]   \n",
       "17                                   [17, 16, 13, 10]   \n",
       "18  [18, 17, 15, 12, 16, 14, 7, 8, 0, 1, 13, 9, 10...   \n",
       "\n",
       "                                   rationale_prob_tgt  exp  \n",
       "0                             [9.548327398078982e-06]    0  \n",
       "1                               [0.18308576941490173]    0  \n",
       "2   [0.00018199862097389996, 0.0015578435268253088...    0  \n",
       "3                                [0.1395016461610794]    0  \n",
       "4   [0.00018957824795506895, 0.0004100390360690653...    0  \n",
       "5           [0.05542754754424095, 0.4019215404987335]    0  \n",
       "6   [0.002531559206545353, 0.024547705426812172, 0...    0  \n",
       "7           [0.03127935156226158, 0.2816878855228424]    0  \n",
       "8   [0.00025553975137881935, 0.006318952422589064,...    0  \n",
       "9   [0.0015836571110412478, 0.04511317238211632, 0...    0  \n",
       "10                               [0.5840400457382202]    0  \n",
       "11  [0.046589091420173645, 0.06804584711790085, 0....    0  \n",
       "12  [6.815839151386172e-05, 0.0015082163736224174,...    0  \n",
       "13                              [0.22912755608558655]    0  \n",
       "14  [0.0022315604146569967, 0.03127949312329292, 0...    0  \n",
       "15        [0.018692484125494957, 0.29664716124534607]    0  \n",
       "16  [0.00035618594847619534, 0.005456853192299604,...    0  \n",
       "17  [0.016638170927762985, 0.07801380753517151, 0....    0  \n",
       "18  [0.0012392343487590551, 0.0015699914656579494,...    0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Tagging rationals for exp: 0**********\n"
     ]
    }
   ],
   "source": [
    "###TAG EXPERIMENTS RESULTS - TAKES TIME\n",
    "nl_ast_types = ['comment','identifier','string']\n",
    "tagged_results = tag_rationals([df_experiment_results], nl_ast_types, pos_types, params['delimiter_sequence'], parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rational_pos</th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "      <th>exp</th>\n",
       "      <th>token_type</th>\n",
       "      <th>span</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "      <td>def</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>[module, function_definition, def]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>multiply</td>\n",
       "      <td>0</td>\n",
       "      <td>[(def, 9.548327398078982e-06)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[9.548327398078982e-06]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(3, 12)</td>\n",
       "      <td>[module, function_definition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[( multiply, 0.18308576941490173)]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.18308576941490173]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(12, 13)</td>\n",
       "      <td>[NNS, module, function_definition, identifier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>two</td>\n",
       "      <td>0</td>\n",
       "      <td>[(_, 0.00018199862097389996), ( multiply, 0.00...</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>[0.00018199862097389996, 0.0015578435268253088...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(13, 16)</td>\n",
       "      <td>[NNS, module, function_definition, identifier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>[(two, 0.1395016461610794)]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0.1395016461610794]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(16, 17)</td>\n",
       "      <td>[NNS, module, function_definition, identifier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>numbers</td>\n",
       "      <td>0</td>\n",
       "      <td>[(_, 0.00018957824795506895), ( multiply, 0.00...</td>\n",
       "      <td>[4, 1, 0, 3, 2]</td>\n",
       "      <td>[0.00018957824795506895, 0.0004100390360690653...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(17, 24)</td>\n",
       "      <td>[NNS, module, function_definition, identifier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(</td>\n",
       "      <td>0</td>\n",
       "      <td>[(numbers, 0.05542754754424095), (def, 0.40192...</td>\n",
       "      <td>[5, 0]</td>\n",
       "      <td>[0.05542754754424095, 0.4019215404987335]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(24, 25)</td>\n",
       "      <td>[module, function_definition, parameters, (]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[((, 0.002531559206545353), ( multiply, 0.0245...</td>\n",
       "      <td>[6, 1, 0, 3, 4]</td>\n",
       "      <td>[0.002531559206545353, 0.024547705426812172, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(25, 26)</td>\n",
       "      <td>[DT, module, function_definition, parameters, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>[(a, 0.03127935156226158), ((, 0.2816878855228...</td>\n",
       "      <td>[7, 6]</td>\n",
       "      <td>[0.03127935156226158, 0.2816878855228424]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(26, 27)</td>\n",
       "      <td>[module, function_definition, parameters, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>[(,, 0.00025553975137881935), (a, 0.0063189524...</td>\n",
       "      <td>[8, 7, 0, 1, 5, 3, 4, 2, 6]</td>\n",
       "      <td>[0.00025553975137881935, 0.006318952422589064,...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(27, 28)</td>\n",
       "      <td>[NN, module, function_definition, parameters, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>):</td>\n",
       "      <td>0</td>\n",
       "      <td>[(b, 0.0015836571110412478), (def, 0.045113172...</td>\n",
       "      <td>[9, 0, 8]</td>\n",
       "      <td>[0.0015836571110412478, 0.04511317238211632, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(28, 30)</td>\n",
       "      <td>[module, function_definition, :]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>[():, 0.5840400457382202)]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[0.5840400457382202]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(30, 38)</td>\n",
       "      <td>[module, function_definition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>return</td>\n",
       "      <td>0</td>\n",
       "      <td>[(\\n       , 0.046589091420173645), ():, 0.068...</td>\n",
       "      <td>[11, 10, 0, 9]</td>\n",
       "      <td>[0.046589091420173645, 0.06804584711790085, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(38, 45)</td>\n",
       "      <td>[module, function_definition, return]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>pow</td>\n",
       "      <td>0</td>\n",
       "      <td>[( return, 6.815839151386172e-05), ( multiply,...</td>\n",
       "      <td>[12, 1, 0, 7, 11, 6, 8, 5, 9, 10, 3, 4, 2]</td>\n",
       "      <td>[6.815839151386172e-05, 0.0015082163736224174,...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(45, 49)</td>\n",
       "      <td>[NN, module, function_definition, block, retur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>(</td>\n",
       "      <td>0</td>\n",
       "      <td>[( pow, 0.22912755608558655)]</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[0.22912755608558655]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(49, 50)</td>\n",
       "      <td>[module, function_definition, block, return_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>[((, 0.0022315604146569967), ( pow, 0.03127949...</td>\n",
       "      <td>[14, 13, 7, 1]</td>\n",
       "      <td>[0.0022315604146569967, 0.03127949312329292, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(50, 51)</td>\n",
       "      <td>[DT, module, function_definition, block, retur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>[(a, 0.018692484125494957), ((, 0.296647161245...</td>\n",
       "      <td>[15, 14]</td>\n",
       "      <td>[0.018692484125494957, 0.29664716124534607]</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(51, 52)</td>\n",
       "      <td>[module, function_definition, block, return_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>[(,, 0.00035618594847619534), (a, 0.0054568531...</td>\n",
       "      <td>[16, 15, 0, 1, 10, 9]</td>\n",
       "      <td>[0.00035618594847619534, 0.005456853192299604,...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(52, 53)</td>\n",
       "      <td>[NN, module, function_definition, block, retur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>)</td>\n",
       "      <td>0</td>\n",
       "      <td>[(b, 0.016638170927762985), (,, 0.078013807535...</td>\n",
       "      <td>[17, 16, 13, 10]</td>\n",
       "      <td>[0.016638170927762985, 0.07801380753517151, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(53, 54)</td>\n",
       "      <td>[module, function_definition, block, return_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>[(), 0.10227975994348526), ( multiply, 0.13196...</td>\n",
       "      <td>[18, 1, 0]</td>\n",
       "      <td>[0.10227975994348526, 0.13196834921836853, 0.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>src</td>\n",
       "      <td>(54, 58)</td>\n",
       "      <td>[module]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rational_pos goal_token  from_seq_id  \\\n",
       "0              0        def            0   \n",
       "1              1   multiply            0   \n",
       "2              2          _            0   \n",
       "3              3        two            0   \n",
       "4              4          _            0   \n",
       "5              5    numbers            0   \n",
       "6              6          (            0   \n",
       "7              7          a            0   \n",
       "8              8          ,            0   \n",
       "9              9          b            0   \n",
       "10            10         ):            0   \n",
       "11            11  \\n                   0   \n",
       "12            12     return            0   \n",
       "13            13        pow            0   \n",
       "14            14          (            0   \n",
       "15            15          a            0   \n",
       "16            16          ,            0   \n",
       "17            17          b            0   \n",
       "18            18          )            0   \n",
       "19            19      \\n               0   \n",
       "\n",
       "                                         typesets_tgt  \\\n",
       "0                                                None   \n",
       "1                      [(def, 9.548327398078982e-06)]   \n",
       "2                  [( multiply, 0.18308576941490173)]   \n",
       "3   [(_, 0.00018199862097389996), ( multiply, 0.00...   \n",
       "4                         [(two, 0.1395016461610794)]   \n",
       "5   [(_, 0.00018957824795506895), ( multiply, 0.00...   \n",
       "6   [(numbers, 0.05542754754424095), (def, 0.40192...   \n",
       "7   [((, 0.002531559206545353), ( multiply, 0.0245...   \n",
       "8   [(a, 0.03127935156226158), ((, 0.2816878855228...   \n",
       "9   [(,, 0.00025553975137881935), (a, 0.0063189524...   \n",
       "10  [(b, 0.0015836571110412478), (def, 0.045113172...   \n",
       "11                         [():, 0.5840400457382202)]   \n",
       "12  [(\\n       , 0.046589091420173645), ():, 0.068...   \n",
       "13  [( return, 6.815839151386172e-05), ( multiply,...   \n",
       "14                      [( pow, 0.22912755608558655)]   \n",
       "15  [((, 0.0022315604146569967), ( pow, 0.03127949...   \n",
       "16  [(a, 0.018692484125494957), ((, 0.296647161245...   \n",
       "17  [(,, 0.00035618594847619534), (a, 0.0054568531...   \n",
       "18  [(b, 0.016638170927762985), (,, 0.078013807535...   \n",
       "19  [(), 0.10227975994348526), ( multiply, 0.13196...   \n",
       "\n",
       "                             rationale_pos_tgt  \\\n",
       "0                                         None   \n",
       "1                                          [0]   \n",
       "2                                          [1]   \n",
       "3                                    [2, 1, 0]   \n",
       "4                                          [3]   \n",
       "5                              [4, 1, 0, 3, 2]   \n",
       "6                                       [5, 0]   \n",
       "7                              [6, 1, 0, 3, 4]   \n",
       "8                                       [7, 6]   \n",
       "9                  [8, 7, 0, 1, 5, 3, 4, 2, 6]   \n",
       "10                                   [9, 0, 8]   \n",
       "11                                        [10]   \n",
       "12                              [11, 10, 0, 9]   \n",
       "13  [12, 1, 0, 7, 11, 6, 8, 5, 9, 10, 3, 4, 2]   \n",
       "14                                        [13]   \n",
       "15                              [14, 13, 7, 1]   \n",
       "16                                    [15, 14]   \n",
       "17                       [16, 15, 0, 1, 10, 9]   \n",
       "18                            [17, 16, 13, 10]   \n",
       "19                                  [18, 1, 0]   \n",
       "\n",
       "                                   rationale_prob_tgt  exp token_type  \\\n",
       "0                                                None    0        src   \n",
       "1                             [9.548327398078982e-06]    0        src   \n",
       "2                               [0.18308576941490173]    0        src   \n",
       "3   [0.00018199862097389996, 0.0015578435268253088...    0        src   \n",
       "4                                [0.1395016461610794]    0        src   \n",
       "5   [0.00018957824795506895, 0.0004100390360690653...    0        src   \n",
       "6           [0.05542754754424095, 0.4019215404987335]    0        src   \n",
       "7   [0.002531559206545353, 0.024547705426812172, 0...    0        src   \n",
       "8           [0.03127935156226158, 0.2816878855228424]    0        src   \n",
       "9   [0.00025553975137881935, 0.006318952422589064,...    0        src   \n",
       "10  [0.0015836571110412478, 0.04511317238211632, 0...    0        src   \n",
       "11                               [0.5840400457382202]    0        src   \n",
       "12  [0.046589091420173645, 0.06804584711790085, 0....    0        src   \n",
       "13  [6.815839151386172e-05, 0.0015082163736224174,...    0        src   \n",
       "14                              [0.22912755608558655]    0        src   \n",
       "15  [0.0022315604146569967, 0.03127949312329292, 0...    0        src   \n",
       "16        [0.018692484125494957, 0.29664716124534607]    0        src   \n",
       "17  [0.00035618594847619534, 0.005456853192299604,...    0        src   \n",
       "18  [0.016638170927762985, 0.07801380753517151, 0....    0        src   \n",
       "19  [0.10227975994348526, 0.13196834921836853, 0.1...    0        src   \n",
       "\n",
       "        span                                               tags  \n",
       "0     (0, 3)                 [module, function_definition, def]  \n",
       "1    (3, 12)                      [module, function_definition]  \n",
       "2   (12, 13)     [NNS, module, function_definition, identifier]  \n",
       "3   (13, 16)     [NNS, module, function_definition, identifier]  \n",
       "4   (16, 17)     [NNS, module, function_definition, identifier]  \n",
       "5   (17, 24)     [NNS, module, function_definition, identifier]  \n",
       "6   (24, 25)       [module, function_definition, parameters, (]  \n",
       "7   (25, 26)  [DT, module, function_definition, parameters, ...  \n",
       "8   (26, 27)       [module, function_definition, parameters, ,]  \n",
       "9   (27, 28)  [NN, module, function_definition, parameters, ...  \n",
       "10  (28, 30)                   [module, function_definition, :]  \n",
       "11  (30, 38)                      [module, function_definition]  \n",
       "12  (38, 45)              [module, function_definition, return]  \n",
       "13  (45, 49)  [NN, module, function_definition, block, retur...  \n",
       "14  (49, 50)  [module, function_definition, block, return_st...  \n",
       "15  (50, 51)  [DT, module, function_definition, block, retur...  \n",
       "16  (51, 52)  [module, function_definition, block, return_st...  \n",
       "17  (52, 53)  [NN, module, function_definition, block, retur...  \n",
       "18  (53, 54)  [module, function_definition, block, return_st...  \n",
       "19  (54, 58)                                           [module]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_results[0][0][90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' multiply'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_results[0][0]['goal_token'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['module', 'function_definition', ':']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_results[0][0]['tags'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Aggregrating rationals for exp: 0**********\n"
     ]
    }
   ],
   "source": [
    "###AGGREGATE RATIONALS - AST\n",
    "local_ast_aggregated_results = aggregate_rationals(tagged_results, node_types, pos_types, len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###AGGREGATE RATIONALS - TAXONOMY\n",
    "local_taxonomy_aggregated_results = map_local_results_to_taxonomy(pl_taxonomy_python(), nl_pos_taxonomy() ,local_ast_aggregated_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize - AST Aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1[ Py]', '2[ht]', '3[on]', '4[ code]', '5[ that]', '6[ Test]', '7[ symlink]', '8[ when]', '9[ the]', '10[ target]', '11[ file]', '12[ is]', '13[ a]', '14[ relative]', '15[ path]', '16[\\n   ]', '17[ Should]', '18[ throw]', '19[ a]', '20[ S]', '21[alt]', '22[Inv]', '23[oc]', '24[ationError]', '25[ :]', '26[ it]', '27[ shouldn]', \"28['t]\", '29[ fix]', '30[ this]', '31[\\n   ]', '32[ (]', '33[alth]', '34[ough]', '35[ it]', '36[ is]', '37[ done]', '38[ for]', '39[ this]', '40[ emulation]', '41[.]', '42[\\n   ]', '43[ If]', '44[ the]', '45[ caller]', '46[ works]', '47[ as]', '48[ with]', '49[ the]', '50[ following]', '51[ exception]', '52[,]', '53[ that]', '54[ might]', '55[\\n   ]', '56[ cause]', '57[ a]', '58[ performance]', '59[ read]', '60[ from]', '61[ the]', '62[ (]', '63[i]', '64[.]', '65[e]', '66[.,]', '67[ with]', '68[ `]', '69[Service]', '70[Exception]', '71[`]', '72[ and]', '73[ supporting]', '74[ the]', '75[ l]', '76[uck]', '77[ process]', '78[.]', '79[\\n\\n   ]', '80[ :]', '81[param]', '82[ block]', '83[_]', '84[point]', '85[_]', '86[on]', '87[_]', '88[error]', '89[:]', '90[ the]', '91[ procurement]', '92[ that]', '93[ is]', '94[ only]', '95[ related]', '96[ to]', '97[ it]', '98[.]', '99[\\n\\n   ]', '100[ \"\"\"]', '101[\\n\\n   ]', '102[ @]', '103[private]', '104[\\n   ]', '105[ def]', '106[ best]', '107[_]', '108[open]', '109[_]', '110[context]', '111[(]', '112[self]', '113[,]', '114[ req]', '115[e]', '116[ctions]', '117[:]', '118[ Iterable]', '119[[]', '120[Name]', '121[]:]', '122[\\n       ]', '123[ self]', '124[.]', '125[usage]', '126[(]', '127[\\n           ]', \"128[ ']\", '129[rame]', '130[.]', '131[once]', '132[ is]', '133[ installed]', '134[ in]', '135[ Python]', '136[.]', '137[ There]', '138[ is]', '139[ no]', '140[-]', '141[op]', '142[timal]', '143[...]', '144[\\n   ]', '145[ \"\"\"]', '146[\\n       ]', '147[ if]', '148[ not]', '149[ hasattr]', '150[(]', '151[self]', '152[.]', '153[collection]', '154[.]', '155[name]', '156[):]', '157[\\n           ]'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'114[ return]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [51], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#local_ast_aggregated_results[<sample_id>][<pos[token]>] -> aggregated rationales\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(local_ast_aggregated_results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;66;03m#target tokens\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlocal_ast_aggregated_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m114[ return]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;66;03m#rationales\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(local_ast_aggregated_results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m114[ return]\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc_|_identation\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrationales\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: '114[ return]'"
     ]
    }
   ],
   "source": [
    "#local_ast_aggregated_results[<sample_id>][<pos[token]>] -> aggregated rationales\n",
    "print(local_ast_aggregated_results[0].keys()) #target tokens\n",
    "print(local_ast_aggregated_results[0]['114[ return]'].keys()) #rationales\n",
    "print(local_ast_aggregated_results[0]['114[ return]']['sc_|_identation']['rationales']) #rationales values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize - Taxonomy Aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1[ base]', '2[64]', '3[\\n]', '4[import]', '5[ pickle]', '6[\\n]', '7[\\n]', '8[from]', '9[ flask]', '10[ import]', '11[ Flask]', '12[,]', '13[ request]', '14[\\n]', '15[app]', '16[ =]', '17[ Flask]', '18[(__]', '19[name]', '20[__)]', '21[\\n]', '22[\\n]', '23[@]', '24[app]', '25[.]', '26[route]', '27[(\"/]', '28[profile]', '29[\")]', '30[\\n]', '31[def]', '32[ profile]', '33[():]', '34[\\n   ]', \"35[ ''']\", '36[\\n   ]', '37[ Get]', '38[ raw]', '39[_]', '40[data]', '41[ from]', '42[ request]', '43[ with]', '44[ utf]', '45[-]', '46[8]', '47[ encoding]', '48[ and]', '49[ decode]', '50[ it]', '51[ with]', '52[ base]', '53[64]', '54[.]', '55[\\n   ]', '56[ De]', '57[serialize]', '58[ the]', '59[ decoded]', '60[ data]', '61[,]', '62[ store]', '63[ it]', '64[ in]', '65[ a]', '66[ variable]', '67[ and]', '68[ return]', '69[ it]', '70[\\n   ]', \"71[ ''']\", '72[\\n   ]', '73[ raw]', '74[_]', '75[data]', '76[ =]', '77[ request]', '78[.]', '79[args]', '80[.]', '81[get]', '82[(\"]', '83[data]', '84[\").]', '85[encode]', \"86[(']\", '87[utf]', '88[-]', '89[8]', \"90[')]\", '91[\\n   ]', '92[ data]', '93[ =]', '94[ base]', '95[64]', '96[.]', '97[decode]', '98[bytes]', '99[(]', '100[raw]', '101[_]', '102[data]', '103[)]', '104[\\n   ]', '105[ obj]', '106[ =]', '107[ pickle]', '108[.]', '109[loads]', '110[(]', '111[data]', '112[)]', '113[\\n   ]', '114[ return]', '115[ obj]', '116[\\n\\n]'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'2[,]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#local_ast_aggregated_results[<sample_id>][<pos[token]>] -> aggregated rationales\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(local_taxonomy_aggregated_results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;66;03m#target tokens\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlocal_taxonomy_aggregated_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2[,]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;66;03m#rationales\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(local_taxonomy_aggregated_results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2[,]\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnl_adverb\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrationales\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: '2[,]'"
     ]
    }
   ],
   "source": [
    "#local_ast_aggregated_results[<sample_id>][<pos[token]>] -> aggregated rationales\n",
    "print(local_taxonomy_aggregated_results[0].keys()) #target tokens\n",
    "print(local_taxonomy_aggregated_results[0]['9[ pow]'].keys()) #rationales\n",
    "print(local_taxonomy_aggregated_results[0]['9[ pow]']['nl_determier']['rationales']) #rationales values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
