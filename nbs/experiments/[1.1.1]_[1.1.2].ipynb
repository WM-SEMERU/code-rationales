{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments [1.1.1] [1.1.2] - Rationales Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_default():\n",
    "    return {\n",
    "        'model': 'codeparrot',\n",
    "        'dataset' : 'DC_SG_BD', #### CHANGE\n",
    "        'modality' : 'nl_sc',\n",
    "        'datasets' : {\n",
    "            'SG_BD' : 'code_completion_random_cut_5k_30_512_tokens', \n",
    "            'DC_SG_BD' : 'code_completion_docstring_random_cut_3.8k_30_150_tokens', \n",
    "            'DC_SG' : 'code_completion_docstring_signature_3.8k_30_150_tokens', \n",
    "            'DC': 'code_completion_docstring_5k_30_150_tokens'\n",
    "        },\n",
    "        'num_experiments' : 30, \n",
    "        'bootstrapping_size': 500,\n",
    "        ######## INPUT \n",
    "        'global_taxonomy_results': '/workspaces/code-rationales/data/global_taxonomy_results/gpt',\n",
    "        'grouping_results': '/workspaces/code-rationales/data/experiments/grouping_results', \n",
    "        ######## OUTPUT\n",
    "        'quantitative_results' : '/workspaces/code-rationales/data/experiments/quantitative_results',\n",
    "    }\n",
    "    \n",
    "params = param_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from statistics import NormalDist\n",
    "\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_rationales.taxonomies import *\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_global_results(experiment_global_result: dict):\n",
    "    flatten_results = { key: [] for key in experiment_global_result.keys() } ## There are 31 fixed categories\n",
    "    for target_key, rationales in experiment_global_result.items():\n",
    "        for rational_key, rational_values in rationales.items():\n",
    "            flatten_results[rational_key] += rational_values\n",
    "    return flatten_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequencies_dataframe(experients_global_results: list):\n",
    "    frequencies_df = pd.DataFrame(columns=experients_global_results[0].keys())\n",
    "    for experiment_global_result in experients_global_results:\n",
    "        rationales_results = flat_global_results(experiment_global_result)\n",
    "        frequencies_df = frequencies_df.append({key: len(value) for key, value in rationales_results.items()}, ignore_index=True)\n",
    "    frequencies_df = frequencies_df.fillna(0)   \n",
    "    return frequencies_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_experiment_path =  lambda results_folder, dataset, exp: results_folder + '/' + dataset + '_exp_' + str(exp) +'.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_groupings(global_results: list, path:str):\n",
    "    with open(path, 'w') as output_file: \n",
    "        json.dump(global_results, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_groupings(path:str):\n",
    "    with open(path, 'r') as output_file:\n",
    "        data = json.load(output_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiments_results(results_folder, name:str):\n",
    "    file_path = params['grouping_results'] + '/' + params['model'] + '/' + params['modality'] + '/' + params['datasets'][params['dataset']] + '_' + name + '.json'\n",
    "    if os.path.isfile(file_path):\n",
    "        return open_groupings(file_path)\n",
    "    experiment_paths = [get_experiment_path(results_folder, params['datasets'][params['dataset']], exp) for exp in range(params['num_experiments'])]\n",
    "    experiment_global_results = []\n",
    "    for experiment_path in experiment_paths:\n",
    "        with open(experiment_path, 'r') as file:\n",
    "            experiment_global_results.append(json.loads(file.read()))\n",
    "    store_groupings(experiment_global_results, file_path)\n",
    "    return experiment_global_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping( np_data, np_func, size ):\n",
    "    \"\"\"Create a bootstrap sample given data and a function\n",
    "    For instance, a bootstrap sample of means, or mediands. \n",
    "    The bootstrap replicates are a long as the original size\n",
    "    we can choose any observation more than once (resampling with replacement:np.random.choice)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Cleaning NaNs\n",
    "    #np_data_clean = np_data[ np.logical_not( np.isnan(np_data) ) ] \n",
    "    \n",
    "    #The size of the bootstrap replicate is as big as size\n",
    "    #Creating the boostrap replicates as long as the orignal data size\n",
    "    #This strategy might work as imputation \n",
    "    bootstrap_repl = [ np_func( np.random.choice( np_data, size=len(np_data) ) ) for i in range( size ) ]\n",
    "    \n",
    "    #logging.info(\"Covariate: \" + cov) #Empirical Mean\n",
    "    #logging.info(\"Empirical Mean: \" + str(np.mean(np_data_clean))) #Empirical Mean\n",
    "    #logging.info(\"Bootstrapped Mean: \" + str( np.mean(bootstrap_repl) ) ) #Bootstrapped Mean\n",
    "    \n",
    "    return np.array( bootstrap_repl )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_intervals_large_samples(data, confidence=0.95):\n",
    "    \"\"\"\n",
    "    @confidence: confidence interval \n",
    "    @return: tuple (lowerbound, uperbound, h-value)\n",
    "    \"\"\"\n",
    "    dist = NormalDist.from_samples( data )\n",
    "    z = NormalDist().inv_cdf((1 + confidence) / 2.)\n",
    "    h = dist.stdev * z / ((len(data) - 1) ** .5)\n",
    "    return dist.mean - h, dist.mean + h, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boostrap_dictionary(dictionary: dict, size):\n",
    "    boostrapped_dict = {}\n",
    "    for key, values in dictionary.items():\n",
    "        if values:\n",
    "            boostrapped_dict[key] = bootstrapping(values, np.mean, size)\n",
    "    return boostrapped_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate statistics and get results DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE GROUP FREQUENCY RESULTS\n",
    "def calculate_results(global_dataframe):\n",
    "    results_df = pd.DataFrame(columns=['type', 'group', 'category', 'mean', 'median', 'std', 'ci'])\n",
    "    for category in global_dataframe.columns:\n",
    "        experiments_values = global_dataframe[category].tolist()\n",
    "        try:\n",
    "            group = [key for key, value in global_groups().items() if category in value][0] ## Mapping from taxonomy groups\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        results_df = results_df.append({\n",
    "            'type': group.split('_')[0], \n",
    "            'group': group, \n",
    "            'category': category, \n",
    "            'median' : np.median(experiments_values),\n",
    "            'mean' : np.mean(experiments_values), \n",
    "            'std' : np.std(experiments_values),\n",
    "            'ci' : confidence_intervals_large_samples(experiments_values)\n",
    "        }, ignore_index=True)\n",
    "    return results_df.sort_values(by='median', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_global_results = get_experiments_results(params['global_taxonomy_results'], 'level_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_frequencies_dataframe = create_frequencies_dataframe(experiments_global_results)\n",
    "global_frequencies_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_frequencies_dataframe_results = calculate_results(global_frequencies_dataframe).sort_values(by=['group','mean'],ascending=[True, False])\n",
    "global_frequencies_dataframe_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_frequencies_dataframe_results.to_csv(params['quantitative_results'] + '/' + params['model'] + '/' + params['modality']  + '/' + params['datasets'][params['dataset']] + '_frequencies' + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
