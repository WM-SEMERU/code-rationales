{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rationalization @ Global Granularity\n",
    "> GPT-2 based global rationalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-07-13 19:41:59.952440: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 19:42:00.176996: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import importlib\n",
    "from matplotlib import colors\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/workspaces/code-rationales/sequential-rationales/huggingface')\n",
    "from rationalization import rationalize_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_default():\n",
    "    return {\n",
    "        'model_name' : '/workspaces/code-rationales/data/codeparrot-small/checkpoints/checkpoint-29000', \n",
    "        'cache_dir': '/workspaces/code-rationales/datax/df_cache_dir',\n",
    "        'dataset' : 'code_completion_random_cut_5k_30_512_tokens',\n",
    "        #'dataset' : 'code_completion_docstring_signature_5k_30_512_tokens',\n",
    "        #'dataset' : 'code_completion_docstring_random_cut_5k_30_512_tokens',\n",
    "        #'dataset' : 'code_completion_docstring_5k_30_512_tokens',\n",
    "        'dataset' : 'code_completion_docstring_signature_5k_30_512_tokens',\n",
    "        'sampling_results': '/workspaces/code-rationales/data/sampling/gpt',\n",
    "        'rational_results': '/workspaces/code-rationales/data/rationales/gpt',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            param_default()['model_name'],\n",
    "            cache_dir=param_default()['cache_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(32768, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(param_default()['model_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Code Generation\n",
    "df_generated_input = pd.read_csv( param_default()['sampling_results'] + '/' + param_default()['dataset'] +'.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
       "       '25', '26', '27', '28', '29'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input.columns[5:] #Tensor Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prompt</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>size</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Generate Pyhton code that Tests checkboxes but...</td>\n",
       "      <td>Tests checkboxes but also acts a regression te...</td>\n",
       "      <td>50</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Generate Pyhton code that \\n        Factory me...</td>\n",
       "      <td>\\n        Factory method to produce an instanc...</td>\n",
       "      <td>45</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 4960, 23616,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Generate Pyhton code that True if this Entry h...</td>\n",
       "      <td>True if this Entry has references from any App...</td>\n",
       "      <td>52</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 715, 340, 64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Generate Pyhton code that Set packet parent.\\n...</td>\n",
       "      <td>Set packet parent.\\n        When packet is an ...</td>\n",
       "      <td>52</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Generate Pyhton code that Remove packet parent...</td>\n",
       "      <td>Remove packet parent.\\n        When packet is ...</td>\n",
       "      <td>52</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "      <td>[6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             prompt  \\\n",
       "0      0  Generate Pyhton code that Tests checkboxes but...   \n",
       "1      1  Generate Pyhton code that \\n        Factory me...   \n",
       "2      2  Generate Pyhton code that True if this Entry h...   \n",
       "3      3  Generate Pyhton code that Set packet parent.\\n...   \n",
       "4      4  Generate Pyhton code that Remove packet parent...   \n",
       "\n",
       "                                        ground_truth  size  \\\n",
       "0  Tests checkboxes but also acts a regression te...    50   \n",
       "1  \\n        Factory method to produce an instanc...    45   \n",
       "2  True if this Entry has references from any App...    52   \n",
       "3  Set packet parent.\\n        When packet is an ...    52   \n",
       "4  Remove packet parent.\\n        When packet is ...    52   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   0  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                   4  ...  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...  ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...  ...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...  ...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...  ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...  ...   \n",
       "\n",
       "                                                  20  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  21  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  22  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  23  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  24  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  25  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  26  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  27  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  28  \\\n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...   \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...   \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...   \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...   \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...   \n",
       "\n",
       "                                                  29  \n",
       "0  [6864, 1611, 517, 265, 1233, 626, 6496, 1104, ...  \n",
       "1  [6864, 1611, 517, 265, 1233, 626, 4960, 23616,...  \n",
       "2  [6864, 1611, 517, 265, 1233, 626, 715, 340, 64...  \n",
       "3  [6864, 1611, 517, 265, 1233, 626, 2494, 3644, ...  \n",
       "4  [6864, 1611, 517, 265, 1233, 626, 5852, 3644, ...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 35)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generate Pyhton code that \\n        Factory method to produce an instance of this class using the default kube config location\\n         and signature is def from_environment(cls):\\n        \"\"\"\\n            As this method move away in Travis casset.mit.utils.py\\n\\n        \"\"\"\\n        return cls(self)\\n\\n\\n@public\\nclass ImportSideCollection(object):\\n\\n    def _getClassProperty(self, m):\\n        uid = m.get(\\'uid\\', None)\\n        if uid is None:\\n            raise ValueError(\\'Missing uid\\')\\n        return t.Func(uid)\\n\\n\\n@public\\nclass ImportShellScriptScriptPath(object):\\n\\n    @PUBLIC\\n    def _getDocumentName(self):\\n        return t.create(\\n            \\'<em><span style=\"kodicon:windowsDescent\">((S chips)\\\\)</span></em>\\',\\n            extension = \\'wsimp\\',\\n        )\\n\\n    @PUBLIC\\n    def _getPluginLabel(self):\\n        plugin_label = t.l xmlns(\"plugin-registry\").top\\n        return plugin_label\\n\\n    @public\\n    def preImportSide(self):\\n        script_id = t.rstring.getBuildStepID().split(\\' \\')[0]\\n        my = \\'RunShellScript(group, *script_id, relative_path=self._getModuleProperty(script_id))[\\'self-url\\']\\n        return gsignals.preImportSideHelper(\\n                m=self.model,\\n                plugin_name=self.name,\\n                context=\"preImportSideHelperContext\",\\n                params=self.possible_parameters,\\n                result=self.result)\\n\\n\\n@public\\nclass ExportHelper(object):\\n    \"\"\"\\n        Creates a shell script for executing imports from Travis:\\n        Support pytest (uqfor --checker-module or openpending)\\n    \"\"\"\\n    def __init__(self, group, script, executable_byte):\\n        self.group, self.script, self.stop_error, self.message, self.parameters, self.return_code, self.options = group, script, (u\\', \\',)\\', u\\'\\n        self.return_code = self.return_code\\n        self.options.indent = 80\\n\\n    @PUBLIC\\n    def get(self, m, rest):\\n        \"\"\"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tst decoding\n",
    "decoded = tokenizer.decode(eval(df_generated_input['0'][1]))\n",
    "decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Statistics\n",
    "np.mean( [len(eval(i)) for i in df_generated_input['0'].values] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO Run the distribution of each experiment. The mean value of tokens or size for each experiment. \n",
    "np.mean( [len(eval(i)) for i in df_generated_input['input_ids'].values] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2368"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_generated_input['0'].values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_SIZE = df_generated_input['size'].max() #Hardocoded!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the model is not fine-tuned or compatible, it will rise an error\n",
    "#This function works for one tensor of source token and one tensor of target tokens\n",
    "def rationalize_model(model, tokenizer, input_ids, verbose=True):\n",
    "    all_rationales, log = rationalize_lm(\n",
    "        model = model,\n",
    "        input_ids = input_ids[:MAX_TOKEN_SIZE],\n",
    "        tokenizer = tokenizer,\n",
    "        verbose = verbose,\n",
    "        max_steps=1024 #Max number of steps for greedy rationalization\n",
    "    )\n",
    "    return all_rationales, log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tst <------- Test Case 2\n",
    "def tst_rationalize_model():\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    #WARNING TIME CONSUMING\n",
    "    all_rationales, log = rationalize_model(\n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "        input_ids=torch.tensor(eval(df_generated_input['0'][0])).to(model.device),\n",
    "        verbose=False\n",
    "    )\n",
    "    pass\n",
    "tst_rationalize_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_rational(\n",
    "    model,\n",
    "    tokenizer, \n",
    "    arr_target_tokens, \n",
    "    seq_id, #mapping sequence id\n",
    "    verbose=True\n",
    "):\n",
    "    arr_log = []\n",
    "    for index, val in enumerate(arr_target_tokens):\n",
    "        all_rationales, log = rationalize_model(\n",
    "            model=model, \n",
    "            tokenizer=tokenizer, \n",
    "            input_ids=val,\n",
    "            verbose=False\n",
    "        )\n",
    "        arr_log.append(log)\n",
    "    arr_code_rationales = [ log['rationalization'] for log in arr_log ] #extracting just rationalizations\n",
    "    arr_from_sentence = [ list(np.full( len(val), seq_id[arr_i] )) #arr_i maps to the real sequence id\n",
    "                            for arr_i, val in enumerate(arr_code_rationales)]\n",
    "    arr_code_rationales = sum( arr_code_rationales, [] ) #flatting\n",
    "    arr_from_sentence = sum( arr_from_sentence, [] ) #flatting\n",
    "    return arr_code_rationales, arr_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tst <------- Test Case 2\n",
    "def tst_run_multiple_rationa():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() #Cleaning Cache\n",
    "    t_dict_generated_input = { exp : [ torch.tensor(eval(s)).to(model.device) for \n",
    "                s in df_generated_input[exp].values ] for exp in df_generated_input.columns[5:]  }\n",
    "    \n",
    "    arr_rations, seq_id = run_multiple_rational(\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        arr_target_tokens =  t_dict_generated_input['0'][:2], \n",
    "        seq_id = list( range(2,4) ),\n",
    "        verbose = False\n",
    "        )\n",
    "    return arr_rations, seq_id\n",
    "tst_arr_rations, seq_id = tst_run_multiple_rationa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_rationales( arr_code_rationales, arr_from_sentence ):\n",
    "    #Creating pandas_1 {p_rationale}\n",
    "    rational = lambda list_log,typeset: [ (dict_tok['added_token_text'],round(dict_tok['true_token_prob'],6)) for dict_tok in list_log if dict_tok['from']==typeset]\n",
    "    log = lambda log_row: [(log_dict['added_token_text'],log_dict['true_token_prob']) for log_dict in log_row] #Typeset\n",
    "\n",
    "    log_position = lambda log_row: [log_dict['added_token_position'] for log_dict in log_row] #Position of the Rationale\n",
    "    log_prediction = lambda log_row: [log_dict['true_token_prob'] for log_dict in log_row] #Rationale Prob\n",
    "\n",
    "    p_rationale = pd.DataFrame()\n",
    "\n",
    "    p_rationale['goal_token'] = [dict_token['goal_word'] for dict_token in arr_code_rationales]\n",
    "    p_rationale['from_seq_id'] = arr_from_sentence\n",
    "\n",
    "    p_rationale['typesets_tgt'] = [ log(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    \n",
    "    p_rationale['rationale_pos_tgt'] = [ log_position(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "    p_rationale['rationale_prob_tgt'] = [ log_prediction(log_row) for log_row in [dict_token['log'] for dict_token in arr_code_rationales]]\n",
    "\n",
    "\n",
    "    return p_rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running Rationalization\n",
    "def run_code_rational( \n",
    "        df_generated_input,\n",
    "        tensor_size, #Control the size of the experiment\n",
    "        experiment = '5',\n",
    "        batch_size = 100, \n",
    "        model = model, \n",
    "        verbose = True \n",
    "    ):\n",
    "\n",
    "    arr_rationals = []\n",
    "    arr_from_seq = []\n",
    "\n",
    "    for i in range( 0 , tensor_size , batch_size ):\n",
    "        print('************************' + str(i) + '************************')\n",
    "        t_generated_input = df_generated_input[experiment].values[i:i+batch_size]\n",
    "        t_generated_input = [ torch.tensor(eval(s)).to(model.device) for s in t_generated_input]\n",
    "\n",
    "        t_arr_rationals,t_arr_from_seq = run_multiple_rational(\n",
    "            model = model,\n",
    "            tokenizer = tokenizer,\n",
    "            arr_target_tokens =  t_generated_input, \n",
    "            seq_id = list(range(i,i+batch_size)),\n",
    "            verbose = verbose\n",
    "        )\n",
    "\n",
    "        arr_rationals = arr_rationals + t_arr_rationals\n",
    "        arr_from_seq = arr_from_seq + t_arr_from_seq\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() #Cleaning Cache\n",
    "\n",
    "    #keys_tensor = list( dict_generated_input.keys() )\n",
    "    #keys_tensor = keys_tensor[:1] #HardCoded Ratios\n",
    "    #dict_arr_rations = { key : for key in keys_tensor}\n",
    "    #torch.cuda.empty_cache() #Cleaning Cache\n",
    "    print(\"Experiment Finished: \" + experiment)\n",
    "    return pandas_rationales( arr_rationals, arr_from_seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************0************************\n",
      "************************1************************\n",
      "************************2************************\n",
      "Experiment Finished: 0\n"
     ]
    }
   ],
   "source": [
    "#tst\n",
    "def tst_run_code_rational_sampling_set(exp='0'):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    tensor_n = 3 #df_generated_input.shape[0]\n",
    "    EXP = exp\n",
    "    BATCH = 1\n",
    "    test_arr_rationals = run_code_rational( \n",
    "            df_generated_input = df_generated_input.sample( n = tensor_n, replace = False, random_state=2),\n",
    "            tensor_size = tensor_n,\n",
    "            experiment = EXP,\n",
    "            batch_size = BATCH, \n",
    "            model = model, \n",
    "            verbose = False \n",
    "        )\n",
    "    return test_arr_rationals\n",
    "df_test_run = tst_run_code_rational_sampling_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>[(def, 4.804769196198322e-05)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[4.804769196198322e-05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>[( training, 0.15646956861019135)]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.15646956861019135]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>iteration</td>\n",
       "      <td>1</td>\n",
       "      <td>[(_, 1.7851834854809567e-05), ( training, 0.00...</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>[1.7851834854809567e-05, 0.0010171481408178806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(</td>\n",
       "      <td>1</td>\n",
       "      <td>[(iteration, 0.037029534578323364), (def, 0.30...</td>\n",
       "      <td>[3, 0, 1]</td>\n",
       "      <td>[0.037029534578323364, 0.3031517267227173, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>self</td>\n",
       "      <td>1</td>\n",
       "      <td>[((, 0.16651831567287445)]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[0.16651831567287445]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>)</td>\n",
       "      <td>1</td>\n",
       "      <td>[(self, 0.03177908435463905), (iteration, 0.06...</td>\n",
       "      <td>[5, 3, 2, 4, 1, 0]</td>\n",
       "      <td>[0.03177908435463905, 0.06415260583162308, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>[(), 0.0008427123539149761), (def, 0.015243726...</td>\n",
       "      <td>[6, 0, 5, 1]</td>\n",
       "      <td>[0.0008427123539149761, 0.015243726782500744, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Result</td>\n",
       "      <td>1</td>\n",
       "      <td>[( -&gt;, 3.162672874168493e-05), ( training, 0.0...</td>\n",
       "      <td>[7, 1, 6, 3, 4, 2, 0, 5]</td>\n",
       "      <td>[3.162672874168493e-05, 0.000254253507591784, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Dict</td>\n",
       "      <td>1</td>\n",
       "      <td>[( Result, 0.0015297869686037302), ( -&gt;, 0.003...</td>\n",
       "      <td>[8, 7, 1, 2, 3, 0, 5, 6, 4]</td>\n",
       "      <td>[0.0015297869686037302, 0.003741607768461108, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>:</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Dict, 0.013612071052193642), ( Result, 0.032...</td>\n",
       "      <td>[9, 8, 1, 0, 7, 6, 5, 2, 4, 3]</td>\n",
       "      <td>[0.013612071052193642, 0.03230997174978256, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>[(:, 0.0006939847953617573), ( Result, 0.00228...</td>\n",
       "      <td>[10, 8, 1, 6, 4, 3, 2, 5, 9, 0, 7]</td>\n",
       "      <td>[0.0006939847953617573, 0.0022824767511337996,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>std</td>\n",
       "      <td>1</td>\n",
       "      <td>[(\\n        , 4.718506534118205e-05), ((, 7.51...</td>\n",
       "      <td>[11, 4, 10, 3, 6, 1, 2, 0, 5, 9, 7, 8]</td>\n",
       "      <td>[4.718506534118205e-05, 7.51987099647522e-05, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>[( std, 0.27051037549972534)]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[0.27051037549972534]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>number</td>\n",
       "      <td>1</td>\n",
       "      <td>[(_, 0.00226293271407485), ( std, 0.0026142790...</td>\n",
       "      <td>[13, 12, 11, 8, 6, 4, 2, 10, 3, 0, 9, 5, 7, 1]</td>\n",
       "      <td>[0.00226293271407485, 0.002614279044792056, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>=</td>\n",
       "      <td>1</td>\n",
       "      <td>[(number, 0.0688244178891182), (:, 0.147053241...</td>\n",
       "      <td>[14, 10, 13]</td>\n",
       "      <td>[0.0688244178891182, 0.14705324172973633, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>[( =, 0.0006023574387654662), ( Result, 0.0009...</td>\n",
       "      <td>[15, 8, 2, 13, 11, 3, 0, 14, 12, 1, 4, 9, 5, 7...</td>\n",
       "      <td>[0.0006023574387654662, 0.0009582255152054131,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>[( 200, 1.1728179742931388e-05), ( std, 0.0001...</td>\n",
       "      <td>[16, 12, 5, 8, 6, 3, 9, 0, 1, 2, 4, 10, 11, 13...</td>\n",
       "      <td>[1.1728179742931388e-05, 0.0001944573741639033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>/</td>\n",
       "      <td>1</td>\n",
       "      <td>[(F, 0.007227318361401558), (\\n        , 0.002...</td>\n",
       "      <td>[17, 11, 1, 12, 14, 7, 15, 16, 3, 8, 13, 5, 6,...</td>\n",
       "      <td>[0.007227318361401558, 0.002875793259590864, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>std</td>\n",
       "      <td>1</td>\n",
       "      <td>[(/, 0.00036426325095817447), ( std, 0.0027216...</td>\n",
       "      <td>[18, 12, 6]</td>\n",
       "      <td>[0.00036426325095817447, 0.002721620025113225,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>[(std, 2.1002222638344392e-05), (\\n        , 9...</td>\n",
       "      <td>[19, 11, 8, 17, 18, 14, 16, 15, 13, 3, 10, 7, ...</td>\n",
       "      <td>[2.1002222638344392e-05, 9.016467811306939e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>se</td>\n",
       "      <td>1</td>\n",
       "      <td>[(\\n        , 0.00014145823661237955), ( std, ...</td>\n",
       "      <td>[20, 12, 11, 1, 14, 16, 17, 18, 19, 9, 4, 15, ...</td>\n",
       "      <td>[0.00014145823661237955, 0.0002828965662047267...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ale</td>\n",
       "      <td>1</td>\n",
       "      <td>[( se, 0.00011466255091363564), (number, 0.004...</td>\n",
       "      <td>[21, 14, 16, 10, 13, 11, 15, 17, 18, 3, 4, 7, ...</td>\n",
       "      <td>[0.00011466255091363564, 0.004199940711259842,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>st</td>\n",
       "      <td>1</td>\n",
       "      <td>[(ale, 0.0005524374428205192), (_, 0.004417745...</td>\n",
       "      <td>[22, 2, 21, 1]</td>\n",
       "      <td>[0.0005524374428205192, 0.004417745862156153, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>[(st, 0.14826393127441406)]</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[0.14826393127441406]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>number</td>\n",
       "      <td>1</td>\n",
       "      <td>[(_, 0.002011603442952037), (number, 0.0125099...</td>\n",
       "      <td>[24, 14, 10]</td>\n",
       "      <td>[0.002011603442952037, 0.012509932741522789, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>=</td>\n",
       "      <td>1</td>\n",
       "      <td>[(number, 0.0730380043387413), ( =, 0.15134024...</td>\n",
       "      <td>[25, 15, 16]</td>\n",
       "      <td>[0.0730380043387413, 0.15134024620056152, 0.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[( =, 0.00861071702092886), (number, 0.0244034...</td>\n",
       "      <td>[26, 25, 8, 1, 20, 15, 12, 16, 11, 2, 13, 23, ...</td>\n",
       "      <td>[0.00861071702092886, 0.024403464049100876, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>[( 1, 0.00028180013759993017), (\\n        , 0....</td>\n",
       "      <td>[27, 20, 15, 25]</td>\n",
       "      <td>[0.00028180013759993017, 0.005441374611109495,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>if</td>\n",
       "      <td>1</td>\n",
       "      <td>[(\\n        , 0.01671646162867546), (std, 0.02...</td>\n",
       "      <td>[28, 19, 21, 11, 15, 10]</td>\n",
       "      <td>[0.01671646162867546, 0.02998759225010872, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>'</td>\n",
       "      <td>1</td>\n",
       "      <td>[( if, 0.02063656970858574), ( 200, 0.04958163...</td>\n",
       "      <td>[29, 16, 13, 24, 19, 23, 26, 25, 9, 2, 27, 5, 0]</td>\n",
       "      <td>[0.02063656970858574, 0.04958163946866989, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>stop</td>\n",
       "      <td>1</td>\n",
       "      <td>[( ', 0.00031656931969337165), (iteration, 0.0...</td>\n",
       "      <td>[30, 3, 0, 23, 29, 6, 20, 5, 24, 4, 10, 13, 14...</td>\n",
       "      <td>[0.00031656931969337165, 0.0012760935351252556...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>'</td>\n",
       "      <td>1</td>\n",
       "      <td>[(stop, 0.00486598489806056), ( ', 0.038165055...</td>\n",
       "      <td>[31, 30, 29]</td>\n",
       "      <td>[0.00486598489806056, 0.038165055215358734, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>[(', 0.008642543107271194), ( if, 0.1184372752...</td>\n",
       "      <td>[32, 29, 9, 5, 31, 7, 16, 2, 10, 21, 13, 17, 4...</td>\n",
       "      <td>[0.008642543107271194, 0.1184372752904892, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "      <td>[( not, 0.040788404643535614), (', 0.254168868...</td>\n",
       "      <td>[33, 32]</td>\n",
       "      <td>[0.040788404643535614, 0.25416886806488037]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>self</td>\n",
       "      <td>1</td>\n",
       "      <td>[( in, 0.045886773616075516), ( not, 0.1666705...</td>\n",
       "      <td>[34, 33]</td>\n",
       "      <td>[0.045886773616075516, 0.16667050123214722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>[( self, 0.8032866716384888)]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[0.8032866716384888]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>params</td>\n",
       "      <td>1</td>\n",
       "      <td>[(., 0.0008252460975199938), ( in, 0.001782352...</td>\n",
       "      <td>[36, 34, 32, 11, 12, 29]</td>\n",
       "      <td>[0.0008252460975199938, 0.0017823525704443455,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>:</td>\n",
       "      <td>1</td>\n",
       "      <td>[(params, 0.024887679144740105), ( in, 0.12292...</td>\n",
       "      <td>[37, 34, 25]</td>\n",
       "      <td>[0.024887679144740105, 0.12292492389678955, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>[(:, 0.19450914859771729)]</td>\n",
       "      <td>[38]</td>\n",
       "      <td>[0.19450914859771729]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>self</td>\n",
       "      <td>1</td>\n",
       "      <td>[(\\n           , 0.0956951379776001), ( self, ...</td>\n",
       "      <td>[39, 35]</td>\n",
       "      <td>[0.0956951379776001, 0.24292844533920288]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>[( self, 0.7851004004478455)]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[0.7851004004478455]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>params</td>\n",
       "      <td>1</td>\n",
       "      <td>[(., 0.000725248537492007), (params, 0.0220922...</td>\n",
       "      <td>[41, 37, 36]</td>\n",
       "      <td>[0.000725248537492007, 0.022092293947935104, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>['</td>\n",
       "      <td>1</td>\n",
       "      <td>[(params, 0.052887916564941406), (:, 0.3485693...</td>\n",
       "      <td>[42, 38]</td>\n",
       "      <td>[0.052887916564941406, 0.3485693037509918]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       goal_token  from_seq_id  \\\n",
       "43       training            1   \n",
       "44              _            1   \n",
       "45      iteration            1   \n",
       "46              (            1   \n",
       "47           self            1   \n",
       "48              )            1   \n",
       "49             ->            1   \n",
       "50         Result            1   \n",
       "51           Dict            1   \n",
       "52              :            1   \n",
       "53     \\n                    1   \n",
       "54            std            1   \n",
       "55              _            1   \n",
       "56         number            1   \n",
       "57              =            1   \n",
       "58            200            1   \n",
       "59              F            1   \n",
       "60              /            1   \n",
       "61            std            1   \n",
       "62     \\n                    1   \n",
       "63             se            1   \n",
       "64            ale            1   \n",
       "65             st            1   \n",
       "66              _            1   \n",
       "67         number            1   \n",
       "68              =            1   \n",
       "69              1            1   \n",
       "70     \\n                    1   \n",
       "71             if            1   \n",
       "72              '            1   \n",
       "73           stop            1   \n",
       "74              '            1   \n",
       "75            not            1   \n",
       "76             in            1   \n",
       "77           self            1   \n",
       "78              .            1   \n",
       "79         params            1   \n",
       "80              :            1   \n",
       "81  \\n                       1   \n",
       "82           self            1   \n",
       "83              .            1   \n",
       "84         params            1   \n",
       "85             ['            1   \n",
       "\n",
       "                                         typesets_tgt  \\\n",
       "43                     [(def, 4.804769196198322e-05)]   \n",
       "44                 [( training, 0.15646956861019135)]   \n",
       "45  [(_, 1.7851834854809567e-05), ( training, 0.00...   \n",
       "46  [(iteration, 0.037029534578323364), (def, 0.30...   \n",
       "47                         [((, 0.16651831567287445)]   \n",
       "48  [(self, 0.03177908435463905), (iteration, 0.06...   \n",
       "49  [(), 0.0008427123539149761), (def, 0.015243726...   \n",
       "50  [( ->, 3.162672874168493e-05), ( training, 0.0...   \n",
       "51  [( Result, 0.0015297869686037302), ( ->, 0.003...   \n",
       "52  [(Dict, 0.013612071052193642), ( Result, 0.032...   \n",
       "53  [(:, 0.0006939847953617573), ( Result, 0.00228...   \n",
       "54  [(\\n        , 4.718506534118205e-05), ((, 7.51...   \n",
       "55                      [( std, 0.27051037549972534)]   \n",
       "56  [(_, 0.00226293271407485), ( std, 0.0026142790...   \n",
       "57  [(number, 0.0688244178891182), (:, 0.147053241...   \n",
       "58  [( =, 0.0006023574387654662), ( Result, 0.0009...   \n",
       "59  [( 200, 1.1728179742931388e-05), ( std, 0.0001...   \n",
       "60  [(F, 0.007227318361401558), (\\n        , 0.002...   \n",
       "61  [(/, 0.00036426325095817447), ( std, 0.0027216...   \n",
       "62  [(std, 2.1002222638344392e-05), (\\n        , 9...   \n",
       "63  [(\\n        , 0.00014145823661237955), ( std, ...   \n",
       "64  [( se, 0.00011466255091363564), (number, 0.004...   \n",
       "65  [(ale, 0.0005524374428205192), (_, 0.004417745...   \n",
       "66                        [(st, 0.14826393127441406)]   \n",
       "67  [(_, 0.002011603442952037), (number, 0.0125099...   \n",
       "68  [(number, 0.0730380043387413), ( =, 0.15134024...   \n",
       "69  [( =, 0.00861071702092886), (number, 0.0244034...   \n",
       "70  [( 1, 0.00028180013759993017), (\\n        , 0....   \n",
       "71  [(\\n        , 0.01671646162867546), (std, 0.02...   \n",
       "72  [( if, 0.02063656970858574), ( 200, 0.04958163...   \n",
       "73  [( ', 0.00031656931969337165), (iteration, 0.0...   \n",
       "74  [(stop, 0.00486598489806056), ( ', 0.038165055...   \n",
       "75  [(', 0.008642543107271194), ( if, 0.1184372752...   \n",
       "76  [( not, 0.040788404643535614), (', 0.254168868...   \n",
       "77  [( in, 0.045886773616075516), ( not, 0.1666705...   \n",
       "78                      [( self, 0.8032866716384888)]   \n",
       "79  [(., 0.0008252460975199938), ( in, 0.001782352...   \n",
       "80  [(params, 0.024887679144740105), ( in, 0.12292...   \n",
       "81                         [(:, 0.19450914859771729)]   \n",
       "82  [(\\n           , 0.0956951379776001), ( self, ...   \n",
       "83                      [( self, 0.7851004004478455)]   \n",
       "84  [(., 0.000725248537492007), (params, 0.0220922...   \n",
       "85  [(params, 0.052887916564941406), (:, 0.3485693...   \n",
       "\n",
       "                                    rationale_pos_tgt  \\\n",
       "43                                                [0]   \n",
       "44                                                [1]   \n",
       "45                                          [2, 1, 0]   \n",
       "46                                          [3, 0, 1]   \n",
       "47                                                [4]   \n",
       "48                                 [5, 3, 2, 4, 1, 0]   \n",
       "49                                       [6, 0, 5, 1]   \n",
       "50                           [7, 1, 6, 3, 4, 2, 0, 5]   \n",
       "51                        [8, 7, 1, 2, 3, 0, 5, 6, 4]   \n",
       "52                     [9, 8, 1, 0, 7, 6, 5, 2, 4, 3]   \n",
       "53                 [10, 8, 1, 6, 4, 3, 2, 5, 9, 0, 7]   \n",
       "54             [11, 4, 10, 3, 6, 1, 2, 0, 5, 9, 7, 8]   \n",
       "55                                               [12]   \n",
       "56     [13, 12, 11, 8, 6, 4, 2, 10, 3, 0, 9, 5, 7, 1]   \n",
       "57                                       [14, 10, 13]   \n",
       "58  [15, 8, 2, 13, 11, 3, 0, 14, 12, 1, 4, 9, 5, 7...   \n",
       "59  [16, 12, 5, 8, 6, 3, 9, 0, 1, 2, 4, 10, 11, 13...   \n",
       "60  [17, 11, 1, 12, 14, 7, 15, 16, 3, 8, 13, 5, 6,...   \n",
       "61                                        [18, 12, 6]   \n",
       "62  [19, 11, 8, 17, 18, 14, 16, 15, 13, 3, 10, 7, ...   \n",
       "63  [20, 12, 11, 1, 14, 16, 17, 18, 19, 9, 4, 15, ...   \n",
       "64  [21, 14, 16, 10, 13, 11, 15, 17, 18, 3, 4, 7, ...   \n",
       "65                                     [22, 2, 21, 1]   \n",
       "66                                               [23]   \n",
       "67                                       [24, 14, 10]   \n",
       "68                                       [25, 15, 16]   \n",
       "69  [26, 25, 8, 1, 20, 15, 12, 16, 11, 2, 13, 23, ...   \n",
       "70                                   [27, 20, 15, 25]   \n",
       "71                           [28, 19, 21, 11, 15, 10]   \n",
       "72   [29, 16, 13, 24, 19, 23, 26, 25, 9, 2, 27, 5, 0]   \n",
       "73  [30, 3, 0, 23, 29, 6, 20, 5, 24, 4, 10, 13, 14...   \n",
       "74                                       [31, 30, 29]   \n",
       "75  [32, 29, 9, 5, 31, 7, 16, 2, 10, 21, 13, 17, 4...   \n",
       "76                                           [33, 32]   \n",
       "77                                           [34, 33]   \n",
       "78                                               [35]   \n",
       "79                           [36, 34, 32, 11, 12, 29]   \n",
       "80                                       [37, 34, 25]   \n",
       "81                                               [38]   \n",
       "82                                           [39, 35]   \n",
       "83                                               [40]   \n",
       "84                                       [41, 37, 36]   \n",
       "85                                           [42, 38]   \n",
       "\n",
       "                                   rationale_prob_tgt  \n",
       "43                            [4.804769196198322e-05]  \n",
       "44                              [0.15646956861019135]  \n",
       "45  [1.7851834854809567e-05, 0.0010171481408178806...  \n",
       "46  [0.037029534578323364, 0.3031517267227173, 0.4...  \n",
       "47                              [0.16651831567287445]  \n",
       "48  [0.03177908435463905, 0.06415260583162308, 0.0...  \n",
       "49  [0.0008427123539149761, 0.015243726782500744, ...  \n",
       "50  [3.162672874168493e-05, 0.000254253507591784, ...  \n",
       "51  [0.0015297869686037302, 0.003741607768461108, ...  \n",
       "52  [0.013612071052193642, 0.03230997174978256, 0....  \n",
       "53  [0.0006939847953617573, 0.0022824767511337996,...  \n",
       "54  [4.718506534118205e-05, 7.51987099647522e-05, ...  \n",
       "55                              [0.27051037549972534]  \n",
       "56  [0.00226293271407485, 0.002614279044792056, 0....  \n",
       "57  [0.0688244178891182, 0.14705324172973633, 0.19...  \n",
       "58  [0.0006023574387654662, 0.0009582255152054131,...  \n",
       "59  [1.1728179742931388e-05, 0.0001944573741639033...  \n",
       "60  [0.007227318361401558, 0.002875793259590864, 0...  \n",
       "61  [0.00036426325095817447, 0.002721620025113225,...  \n",
       "62  [2.1002222638344392e-05, 9.016467811306939e-05...  \n",
       "63  [0.00014145823661237955, 0.0002828965662047267...  \n",
       "64  [0.00011466255091363564, 0.004199940711259842,...  \n",
       "65  [0.0005524374428205192, 0.004417745862156153, ...  \n",
       "66                              [0.14826393127441406]  \n",
       "67  [0.002011603442952037, 0.012509932741522789, 0...  \n",
       "68  [0.0730380043387413, 0.15134024620056152, 0.29...  \n",
       "69  [0.00861071702092886, 0.024403464049100876, 0....  \n",
       "70  [0.00028180013759993017, 0.005441374611109495,...  \n",
       "71  [0.01671646162867546, 0.02998759225010872, 0.0...  \n",
       "72  [0.02063656970858574, 0.04958163946866989, 0.0...  \n",
       "73  [0.00031656931969337165, 0.0012760935351252556...  \n",
       "74  [0.00486598489806056, 0.038165055215358734, 0....  \n",
       "75  [0.008642543107271194, 0.1184372752904892, 0.2...  \n",
       "76        [0.040788404643535614, 0.25416886806488037]  \n",
       "77        [0.045886773616075516, 0.16667050123214722]  \n",
       "78                               [0.8032866716384888]  \n",
       "79  [0.0008252460975199938, 0.0017823525704443455,...  \n",
       "80  [0.024887679144740105, 0.12292492389678955, 0....  \n",
       "81                              [0.19450914859771729]  \n",
       "82          [0.0956951379776001, 0.24292844533920288]  \n",
       "83                               [0.7851004004478455]  \n",
       "84  [0.000725248537492007, 0.022092293947935104, 0...  \n",
       "85         [0.052887916564941406, 0.3485693037509918]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tst\n",
    "df_test_run[ df_test_run['from_seq_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_rational_all_set(exp, tensor_n = 100, BATCH = 10): #When Tensor_n and batch differs then 'from_seq_id' is lost\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    EXP = exp\n",
    "    test_arr_rationals = run_code_rational( \n",
    "            df_generated_input = df_generated_input,\n",
    "            tensor_size = tensor_n,\n",
    "            experiment = EXP,\n",
    "            batch_size = BATCH, \n",
    "            model = model, \n",
    "            verbose = False \n",
    "        )\n",
    "    #Saving process\n",
    "    print('Saving process')\n",
    "    test_arr_rationals.to_csv(param_default()['rational_results'] + '/' + param_default()['dataset'] + '/' + '[t_'+str(tensor_n)+']_[max_tgt_'+str(MAX_TOKEN_SIZE)+']_[exp:' + str(EXP) +']_.csv')\n",
    "    return test_arr_rationals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tst\n",
    "#df_test_run = run_code_rational_all_set(exp='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 0\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 1\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 2\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 3\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 4\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 5\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 6\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 7\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 8\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 9\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 10\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 11\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 12\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 13\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 14\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 15\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 16\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 17\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 18\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 19\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 20\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 21\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 22\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 23\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 24\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 25\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 26\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 27\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 28\n",
      "Saving process\n",
      "************************0************************\n",
      "************************10************************\n",
      "************************20************************\n",
      "************************30************************\n",
      "************************40************************\n",
      "************************50************************\n",
      "************************60************************\n",
      "************************70************************\n",
      "************************80************************\n",
      "************************90************************\n",
      "Experiment Finished: 29\n",
      "Saving process\n"
     ]
    }
   ],
   "source": [
    "for i in df_generated_input.columns[5:]: #Only Generated Sequences \n",
    "    df_test_run = run_code_rational_all_set(exp=i, tensor_n=df_generated_input.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal_token</th>\n",
       "      <th>from_seq_id</th>\n",
       "      <th>typesets_tgt</th>\n",
       "      <th>rationale_pos_tgt</th>\n",
       "      <th>rationale_prob_tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>skip</td>\n",
       "      <td>0</td>\n",
       "      <td>[(def, 0.00029721998726017773)]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.00029721998726017773]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  goal_token  from_seq_id                     typesets_tgt rationale_pos_tgt  \\\n",
       "0       skip            0  [(def, 0.00029721998726017773)]               [0]   \n",
       "\n",
       "         rationale_prob_tgt  \n",
       "0  [0.00029721998726017773]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_run.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running all Experiments\n",
    "def exp_run_all_rationales():\n",
    "    dict_arr_rations = { key : run_code_rational(\n",
    "        df_generated_input = df_generated_input,\n",
    "        experiment = key,\n",
    "        batch_size = 10, \n",
    "        model = model, \n",
    "        verbose = False \n",
    "    ) for key in df_generated_input.columns[5:] }\n",
    "    return dict_arr_rations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_df_rationale = [pandas_rationales(dict_arr_rations[key]) for key in dict_arr_rations.keys()]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27c2fcb21fdb148cd37ecbed2ef65b6b1f3a0948b222c0bcf7dcf1d6a4c7a458"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('shapley-01': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
